/* ******************************************************************** */
/* ******************************************************************** */
/* Functions to create tentative prolongators                           */
/* ******************************************************************** */
/* Author        : Charles Tong                                         */
/* Organization  : Sandia National Laboratories                         */
/* Date          : December, 1999                                       */
/* ******************************************************************** */
/* ******************************************************************** */

#include <assert.h>
#include <stdio.h>
#include <math.h>
#include "ml_aggregate.h"
#include "ml_lapack.h"

#ifdef READ_IN_AGGR
#include "az_aztec.h"
#endif

#define abs(x) (((x) > 0) ? x : (-(x)))

/* ******************************************************************** */
/* variables used for parallel debugging  (Ray)                         */
/* -------------------------------------------------------------------- */

#ifdef PARTEST
extern int **global_mapping = NULL, global_nrows, global_ncoarse;
#endif

/* ******************************************************************** */
/* internal function defined later on in this file                      */
/* -------------------------------------------------------------------- */

extern void ML_CSR_MSR_ML_memorydata_Destroy(void *data);
extern int  ML_Aggregate_Compress_Matrix(ML_Operator *, int *mat_indx, 
                int N_info, int *vinfo, int **new_mat_indx, 
                int *N_neighbors, int **neighbors, int **recv_leng,
                int **send_leng, int **send_list, int **recv_list);
extern int  ML_Aggregate_CoarsenCoupledCore(ML_Aggregate *, ML_Comm *comm,
                ML_Operator *Amatrix, int *amal_mat_indx, int *aggr_count, 
                int **aggr_index2, int N_neighbors, int *neighbors, 
                int *recv_leng,int *send_leng,int *send_list,int *,int **); 
extern int  ML_Aggregate_CoarsenUncoupledCore(ML_Aggregate *, ML_Comm *,
                ML_Operator *, int *mat_indx, int *aggr_count_in, 
                int **aggr_index_in);
extern int  ML_Aggregate_ExchangeData2(char *recvbuf, char *sendbuf, 
                int N_neighbors, int *neighbors, int *recv_leng, 
                int *send_leng, int *recv_list, int Nrows, int msgid, 
                int datatype, ML_Comm *comm);
extern int  ML_Aggregate_ComposeRecvInfo(int nprocs,int mypid,int new_N_send,
                int *new_send_leng, int *new_send_neighbors, int *new_N_rcv, 
                int **new_recv_leng, int **new_recv_neighbors, ML_Comm *);

/* ******************************************************************** */
/* external functions called from this file                             */
/* -------------------------------------------------------------------- */

extern int ML_randomize(int nlist, int *list);

/* ******************************************************************** */
/* local defines                                                        */
/* -------------------------------------------------------------------- */

#define ML_AGGR_READY      -11
#define ML_AGGR_NOTSEL     -12
#define ML_AGGR_SELECTED   -13
#define ML_AGGR_SELECTED2  -14
#define ML_AGGR_BDRY       -15
#define ML_AGGR_MINRANK      1
#define ML_AGGR_MAXLINK      2

/* ******************************************************************** */
/* ******************************************************************** */
/* ******************************************************************** */

/* ******************************************************************** */
/* construct the tentative prolongator (local)                          */
/*  phase 1 : relax on the new seed point as Vanek                      */
/*  phase 2 : assign the rest of the nodes to one of the existing       */
/*            aggregate (attach_scheme), if possible.                   */
/*  phase 3 : see if the un-aggregated nodes have enough neighbors      */
/*            (min_nodes_per_aggregate) to form its own aggregate       */
/* -------------------------------------------------------------------- */

int ML_Aggregate_CoarsenUncoupledCore(ML_Aggregate *ml_ag, ML_Comm *comm,
                      ML_Operator *Amat, int *mat_indx,
                      int *aggr_count_in, int **aggr_index_in)
{
   int     i, j, k, m, kk, inode, jnode, nbytes, length, Nrows;
   int     select_flag, aggr_count, index, mypid, inode2;
   int     *aggr_index, search_flag, *itmp_array = NULL, count;
   int     mincount, *aggr_stat, ordering, maxcount;
   int     *randomVector, *int_buf, aggr_cnt_leng, *aggr_cnt_array;
   int     min_nodes_per_aggregate, max_neigh_selected, attach_scheme;
   ML_Node       *node_head, *node_tail, *new_node;
   ML_SuperNode  *aggr_head, *aggr_curr, *supernode;

   /* ============================================================= */
   /* get the machine information and matrix references             */
   /* ============================================================= */

   mypid                   = comm->ML_mypid;
   min_nodes_per_aggregate = ml_ag->min_nodes_per_aggregate;
   max_neigh_selected      = ml_ag->max_neigh_already_selected;
   ordering                = ml_ag->ordering;
   attach_scheme           = ml_ag->attach_scheme;
   Nrows                   = mat_indx[0] - 1;

   /* ============================================================= */
   /* aggr_stat indicates whether this node has been aggreated, and */
   /* aggr_index stores the aggregate number where this node has    */
   /* been aggregated into.                                         */
   /* ============================================================= */

   nbytes = Nrows * sizeof( int );
   if ( nbytes > 0 ) 
   {
      ML_memory_alloc((void**) &aggr_index, nbytes, "AMA");
      ML_memory_alloc((void**) &aggr_stat,  nbytes, "AMB");
   } else aggr_index = aggr_stat = NULL;

   for ( i = 0; i < Nrows; i++ ) aggr_stat[i] = ML_AGGR_READY;
   for ( i = 0; i < Nrows; i++ ) aggr_index[i] = -1;

   /* ============================================================= */
   /* Set up the data structures for aggregation                    */
   /* ============================================================= */

   aggr_count = 0;
   aggr_head = NULL;
   aggr_cnt_leng = Nrows / 5 + 2;
   nbytes = aggr_cnt_leng * sizeof( int );
   if ( nbytes > 0 ) 
   {
      ML_memory_alloc((void**) &aggr_cnt_array, nbytes, "AME");
      for ( i = 0; i < aggr_cnt_leng; i++ ) aggr_cnt_array[i] = 0;
   } else
      aggr_cnt_array = NULL;

   /* ============================================================= */
   /* Phase 1  :                                                    */
   /*    for all nodes, form a new aggregate with its neighbors     */
   /*    if the number of its neighbors having been aggregated does */
   /*    not exceed a given threshold                               */
   /*    (max_neigh_selected = 0 ===> Vanek's scheme)               */
   /* ============================================================= */

   if ( ordering == 1 )       /* random ordering */
   {
      nbytes = Nrows * sizeof(int);
      ML_memory_alloc((void**) &randomVector, nbytes, "AMF");
      for (i = 0; i < Nrows; i++) randomVector[i] = i;
      ML_randomize(Nrows, randomVector);
   } 
   else if ( ordering == 2 )  /* graph ordering */
   {
      new_node = (ML_Node *) malloc(sizeof(ML_Node));      
      new_node->node_id = 0;
      node_head = new_node;
      node_tail = new_node;
      new_node->next = NULL;
   }
   
   inode2 = 0;
   while ( inode2 < Nrows)
   {
      /*------------------------------------------------------ */
      /* pick the next node to aggregate                       */
      /*------------------------------------------------------ */

      if      ( ordering == 0 ) inode = inode2++;
      else if ( ordering == 1 ) inode = randomVector[inode2++];
      else if ( ordering == 2 ) 
      {
         if ( node_head == NULL ) 
         {
            for ( jnode = 0; jnode < Nrows; jnode++ ) 
            {
               if ( aggr_stat[jnode] == ML_AGGR_READY )
               { 
                  new_node = (ML_Node *) malloc(sizeof(ML_Node));      
                  new_node->node_id = jnode;
                  node_head = new_node;
                  node_tail = new_node;
                  new_node->next = NULL;
                  break;
               }
            }
         }
         if ( node_head == NULL ) break;
         new_node = node_head;
         inode = new_node->node_id;
         node_head = new_node->next;
         free(new_node);
      }

      /*------------------------------------------------------ */
      /* consider further only if the node is in READY mode    */
      /*------------------------------------------------------ */

      if ( aggr_stat[inode] == ML_AGGR_READY ) 
      {
         length = mat_indx[inode+1] - mat_indx[inode] + 1;
         supernode = (ML_SuperNode *) malloc(sizeof(ML_SuperNode));      
         supernode->list = (int*) malloc(length*sizeof(int));

         if ((supernode->list) == NULL) 
         {
            printf("Error:couldn't allocate memory for supernode! %d\n",
                            length);
            exit(1);
         }

         supernode->maxlength = length;
         supernode->length = 1;
         supernode->list[0] = inode;
         select_flag = 1;

         /*--------------------------------------------------- */
         /* count the no. of neighbors having been aggregated  */
         /*--------------------------------------------------- */

         count = 0;
         for (jnode=mat_indx[inode];jnode<mat_indx[inode+1];jnode++) 
         {
            index = mat_indx[jnode];
            if ( index < Nrows ) 
            {
               if ( aggr_stat[index] == ML_AGGR_READY || 
                    aggr_stat[index] == ML_AGGR_NOTSEL ) 
                  supernode->list[supernode->length++] = index;
               else if ( aggr_stat[index] != ML_AGGR_BDRY ) count++;
            }
         }

         /*--------------------------------------------------- */
         /* if there are too many neighbors aggregated or the  */
         /* number of nodes in the new aggregate is too few,   */
         /* don't do this one                                  */
         /*--------------------------------------------------- */

         if ( count > max_neigh_selected ) select_flag = 0;

         if (select_flag != 1 || 
             supernode->length < min_nodes_per_aggregate) 
         {
            aggr_stat[inode] = ML_AGGR_NOTSEL;
            free( supernode->list );
            free( supernode );
            if ( ordering == 2 ) /* if graph ordering */
            {
               for (jnode=mat_indx[inode];jnode<mat_indx[inode+1];jnode++) 
               {
                  index = mat_indx[jnode];
                  if ( aggr_stat[index] == ML_AGGR_READY )
                  { 
                     new_node = (ML_Node *) malloc(sizeof(ML_Node));      
                     new_node->node_id = index;
                     new_node->next = NULL;
                     if ( node_head == NULL )
                     {
                        node_head = new_node;
                        node_tail = new_node;
                     } else {
                        node_tail->next = new_node;
                        node_tail = new_node;
                     }
                  } 
               } 
            } 
         } 
         else 
         {
            for ( j = 0; j < supernode->length; j++ ) 
            {
               jnode = supernode->list[j];
               aggr_stat[jnode] = ML_AGGR_SELECTED;
               aggr_index[jnode] = aggr_count;
               if ( ordering == 2 ) /* if graph ordering */
               {
                  for (kk=mat_indx[jnode];kk<mat_indx[jnode+1];kk++) 
                  {
                     if ( aggr_stat[mat_indx[kk]] == ML_AGGR_READY )
                     { 
                        new_node = (ML_Node *) malloc(sizeof(ML_Node));      
                        new_node->node_id = mat_indx[kk];
                        new_node->next = NULL;
                        if ( node_head == NULL )
                        {
                           node_head = new_node;
                           node_tail = new_node;
                        } else {
                           node_tail->next = new_node;
                           node_tail = new_node;
                        }
                     }
                  } 
               } 
            }
            supernode->next = NULL;
            supernode->index = aggr_count;
            if ( aggr_count == 0 ) 
            {
               aggr_head = supernode;
               aggr_curr = supernode;
            } 
            else 
            {
               aggr_curr->next = supernode;
               aggr_curr = supernode;
            } 
            aggr_cnt_array[aggr_count++] = supernode->length;
            if ( aggr_count >= aggr_cnt_leng ) 
            {
               itmp_array = aggr_cnt_array;
               aggr_cnt_leng = aggr_cnt_leng * 6 / 5 + 1;
               nbytes = aggr_cnt_leng * sizeof( int );
               ML_memory_alloc((void**) &aggr_cnt_array,nbytes,"AMG");
               for ( k = 0; k < aggr_count; k++ )
                  aggr_cnt_array[k] = itmp_array[k];
               ML_memory_free((void**) &itmp_array);
            }
         }
      }
   }
   if ( ordering == 1 ) ML_memory_free((void**) &randomVector);
   else if ( ordering == 2 ) 
   {
      while ( node_head != NULL )
      {
         new_node = node_head;
         node_head = new_node->next;
         free( new_node );
      }
   }

   m = 0;
   for ( i = 0; i < Nrows; i++ ) 
      if ( aggr_stat[i] == ML_AGGR_READY ) m++;
   k = ML_Comm_GsumInt( comm, m);
   if ( k > 0 && mypid == 0 )
      printf("Aggregation(UC) : Phase 1 (WARNING) - %d READY nodes left\n",k);
   m = 0;
   for ( i = 0; i < Nrows; i++ ) 
      if ( aggr_stat[i] == ML_AGGR_SELECTED ) m++;
   k = ML_Comm_GsumInt( comm, m);
   m = ML_Comm_GsumInt( comm, Nrows);
   j = ML_Comm_GsumInt( comm, aggr_count );
#ifdef AGG_OUTPUT
   if ( mypid == 0 ) {
      printf("Aggregation(UC) : Phase 1 - nodes aggregated = %d (%d)\n",k,m);
      printf("Aggregation(UC) : Phase 1 - total aggregates = %d \n",j);
   }
#endif 

   /* ============================================================= */
   /* Phase 2 : aggregate the rest of the nodes into one of the     */
   /*           existing LOCAL aggregates. (attach_scheme)          */
   /* ============================================================= */

   count = 0;
   for ( inode = 0; inode < Nrows; inode++ ) 
   {
      /* ---------------------------------------------------------- */
      /* for all nodes that have not been aggregated                */
      /* ---------------------------------------------------------- */

      if ( aggr_stat[inode] == ML_AGGR_NOTSEL || 
           aggr_stat[inode] == ML_AGGR_READY ) 
      {
         if ( attach_scheme == ML_AGGR_MINRANK ) 
         {
            /* ---------------------------------------------------- */
            /* search for a neighboring aggregate that has the      */
            /* fewest number of nodes                               */
            /* ---------------------------------------------------- */

            search_flag = 0;
            mincount = 100000;
            for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; 
                 jnode++) 
            {
               index = mat_indx[jnode];
               if ( index < Nrows ) 
               {
                  if ( aggr_stat[index] == ML_AGGR_SELECTED ) 
                  {
                     search_flag = 1;
                     m = aggr_index[index];
                     if ( aggr_cnt_array[m] < mincount ) 
                     {
                        mincount = aggr_cnt_array[m];
                        k = index;
                     }
                  }
               }
            }
            if ( search_flag == 1 ) 
            {
               index = k;
               m = aggr_index[index];
            }

         } 
         else if ( attach_scheme == ML_AGGR_MAXLINK ) 
         {
            /* ---------------------------------------------------- */
            /* search for a neighboring aggregate that has the most */
            /* connection to my node                                */
            /* ---------------------------------------------------- */

            search_flag = 0;
            length = mat_indx[inode+1] - mat_indx[inode];
            nbytes = length * sizeof( int );
            if ( nbytes > 0 )
               ML_memory_alloc((void**) &int_buf, nbytes, "AGR");
            length = 0; 
            for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; 
                 jnode++) 
            {
               index = mat_indx[jnode];
               if ( aggr_index[index] >= 0 ) 
                  int_buf[length++] = aggr_index[index];
            }
            ML_sort(length, int_buf);
            m = -1;
            maxcount = 0;
            if ( length > 0 ) {k = int_buf[0]; j = 1; m = k;}
            for ( jnode = 1; jnode < length; jnode++ ) 
            {
               if ( int_buf[jnode] == k ) j++;
               else 
               {
                  if ( j > maxcount ) 
                  {
                     maxcount = j;
                     m = k;
                  }
                  k = int_buf[jnode];
                  j = 1;
               }
            }
            if ( m >= 0 ) search_flag = 1;
            if ( nbytes > 0 ) ML_memory_free((void**) &int_buf);
         } else {
            printf("ML_Aggregate_CoarsenUncoupled error : invalid scheme.\n");
            exit(1);
         }

         /* ------------------------------------------------------- */
         /* if found, add the node to the existing aggregate        */
         /* ------------------------------------------------------- */

         if ( search_flag == 1 ) 
         { 
            aggr_cnt_array[m]++;
            aggr_index[inode] = m;
            aggr_stat[inode] = ML_AGGR_SELECTED2;
            count++;
         } 
      }
   }
   for ( i = 0; i < Nrows; i++ ) 
      if (aggr_stat[i] == ML_AGGR_SELECTED2) aggr_stat[i] = ML_AGGR_SELECTED;

   m = 0;
   for ( i = 0; i < Nrows; i++ ) 
      if ( aggr_stat[i] == ML_AGGR_SELECTED ) m++;
   k = ML_Comm_GsumInt( comm, m);
   m = ML_Comm_GsumInt( comm, Nrows);
   j = ML_Comm_GsumInt( comm, aggr_count );

#ifdef AGG_OUTPUT
   if ( mypid == 0 ) {
      printf("Aggregation(UC) : Phase 2 - nodes aggregated = %d (%d)\n",k,m);
      printf("Aggregation(UC) : Phase 2 - total aggregates = %d \n",j);
   }
#endif

   /* ============================================================= */
   /* Phase 3 : for the un-aggregated nodes, form a new aggregate   */
   /* ============================================================= */

   for ( inode = 0; inode < Nrows; inode++ ) 
   {
      if (aggr_stat[inode] == ML_AGGR_READY || 
          aggr_stat[inode] == ML_AGGR_NOTSEL ) 
      {
         count = 1;
         for (jnode = mat_indx[inode]; jnode < mat_indx[inode+1]; jnode++) 
         {
            index = mat_indx[jnode];
            if ( index < Nrows && aggr_stat[index] != ML_AGGR_SELECTED ) 
               count++;
         }
         length = mat_indx[inode+1] - mat_indx[inode];

         /* ------------------------------------------------------- */
         /* if enough neighbors have not been aggregated, form one  */
         /* ------------------------------------------------------- */

         supernode = (ML_SuperNode *) malloc(sizeof(ML_SuperNode));      
         supernode->list = (int*) malloc(count*sizeof(int));
         if ((supernode->list) == NULL) 
         {
            printf("ML_Aggregate_Coarsen - couldn't allocate memory.\n");
            exit(1);
         }

         supernode->maxlength = count;
         supernode->length = 1;
         supernode->list[0] = inode;

         for (jnode = mat_indx[inode]; jnode < mat_indx[inode+1]; jnode++) 
         {
            index = mat_indx[jnode];
            if ( index < Nrows&& aggr_stat[index] != ML_AGGR_SELECTED && 
                 aggr_stat[index] != ML_AGGR_BDRY ) 
               supernode->list[supernode->length++] = index;
         }
         for ( j = 0; j < supernode->length; j++ ) 
         {
            jnode = supernode->list[j];
            aggr_stat[jnode] = ML_AGGR_SELECTED;
            aggr_index[jnode] = aggr_count;
         }
         supernode->next = NULL;
         supernode->index = aggr_count;
         if ( aggr_count == 0 ) 
         {
            aggr_head = supernode;
            aggr_curr = supernode;
         } 
         else 
         {
            aggr_curr->next = supernode;
            aggr_curr = supernode;
         } 
         aggr_cnt_array[aggr_count++] = supernode->length;
         if ( aggr_count >= aggr_cnt_leng ) 
         {
            itmp_array = aggr_cnt_array;
            aggr_cnt_leng = aggr_cnt_leng * 6 / 5 + 1;
            nbytes = aggr_cnt_leng * sizeof( int );
            ML_memory_alloc((void**) &aggr_cnt_array, nbytes, "AGL");
            for ( k = 0; k < aggr_count; k++ )
               aggr_cnt_array[k] = itmp_array[k];
            ML_memory_free((void**) &itmp_array);
         }
      }
   }

   m = 0;
   for ( i = 0; i < Nrows; i++ ) 
      if ( aggr_stat[i] == ML_AGGR_SELECTED ) m++;
   k = ML_Comm_GsumInt( comm, m);
   m = ML_Comm_GsumInt( comm, Nrows);
   j = ML_Comm_GsumInt( comm, aggr_count );

#ifdef AGG_OUTPUT
   if ( mypid == 0 ) 
   {
      printf("Aggregation(UC) : Phase 3 - nodes aggregated = %d (%d)\n",k,m);
      printf("Aggregation(UC) : Phase 3 - total aggregates = %d \n",j);
   }
#endif

   /* ============================================================= */
   /* check for error                                               */
   /* ============================================================= */

   m = 0;
   for ( i = 0; i < Nrows; i++ ) 
      if (aggr_stat[i] != ML_AGGR_SELECTED && aggr_stat[i] != ML_AGGR_BDRY) m++;
   k = ML_Comm_GsumInt( comm, m);
   if ( k > 0 && mypid == 0 ) 
   {
      printf("Aggregation (UC) error : not all nodes processed.\n");
      exit(1);
   }

   /* ------------------------------------------------------------- */
   /* clean up                                                      */
   /* ------------------------------------------------------------- */

   ML_memory_free((void**) &aggr_stat);
   ML_memory_free((void**) &aggr_cnt_array);
   aggr_curr = aggr_head;
   while ( aggr_curr != NULL ) 
   {
      supernode = aggr_curr;
      aggr_curr = aggr_curr->next;
      if ( supernode->maxlength > 0 ) free( supernode->list );
      free( supernode );
   }
   (*aggr_count_in) = aggr_count;
   (*aggr_index_in) = aggr_index;

   return aggr_count;
}

/* ******************************************************************** */
/* ******************************************************************** */
/* construct the tentative prolongator (local)                          */
/* This function assumes that the block information are stored in the   */
/* ML_Aggregate structure.                                              */ 
/*  phase 1 : relax on the new seed point as Vanek                      */
/*  phase 2 : assign the rest of the nodes to one of the existing       */
/*            aggregate (attach_scheme), if possible.                   */
/*  phase 3 : see if the un-aggregated nodes have enough neighbors      */
/*            (min_nodes_per_aggregate) to form its own aggregate       */
/* -------------------------------------------------------------------- */

int ML_Aggregate_CoarsenUncoupledVBlock(ML_Aggregate *ml_ag, 
           ML_Operator *Amatrix, ML_Operator **Pmatrix, ML_Comm *comm)
{
   int     mypid, Nrows, nvblocks, *vblock_info, *vblock_info2;
   int     i, j, k, m, nullspace_dim, *col_ind, aggr_count, nvblockflag;
   int     nbytes, Ncoarse, *mat_indx=NULL,*aggr_index,nz_cnt;
   int     *new_ia = NULL, *new_ja = NULL, maxnnz_per_row=500;
   int     *amal_mat_indx=NULL, amal_count, **rows_in_aggs = NULL;
   int     lwork, *agg_sizes = NULL, row, level, new_cnt, max_agg_size;
   int     zerodiag_cnt, offset, jnode, *agg_sizes_cum=NULL, index, info;
   double  epsilon, *col_val, *tmp_vect = NULL;
   double  dcompare1, dcompare2, *new_val=NULL, *diagonal=NULL;
   double  *nullspace_vect=NULL, *new_null=NULL, *work=NULL, *qr_tmp=NULL;
   char    *col_entered;
   struct  ML_CSR_MSRdata *csr_data;
   ML_Aggregate_Comm *aggr_comm;
   ML_GetrowFunc     *getrow_obj;
   int               (*getrowfunc)(void *,int,int*,int,int*,double*,int*);

   /* ============================================================= */
   /* get the machine information and matrix references             */
   /* ============================================================= */

   mypid          = comm->ML_mypid;
   epsilon        = ml_ag->threshold;
   nullspace_dim  = ml_ag->nullspace_dim;
   nullspace_vect = ml_ag->nullspace_vect;
   Nrows          = Amatrix->outvec_leng;
   nvblocks       = ml_ag->nvblocks;
   vblock_info    = ml_ag->vblock_info;

   /* ============================================================= */
   /* check that this function is called properly.                  */
   /* ============================================================= */

/*
   diff_level = ml_ag->begin_level - ml_ag->cur_level;
   if ( diff_level < 0 ) diff_level = - diff_level;
   if ( diff_level > 0 )
   { 
      printf("ML_Aggregate_CoarsenUncoupledVBlock should be called only at");
      printf("          the fineset level.\n");
      exit(1);
   }
*/

#ifdef AGG_OUTPUT
   if ( mypid == 0 )
   {
      printf("ML_Aggregate_CoarsenUncoupledVBlock : current level = %d\n", 
                           ml_ag->cur_level);
      printf("ML_Aggregate_CoarsenUncoupledVBlock : current eps = %e\n",
                           epsilon);
   }
#endif
   epsilon = epsilon * epsilon;

   /* ============================================================= */
   /* generate MSR matrix from incoming A matrix                    */
   /* ============================================================= */

   /* ------------------------------------------------------------- */
   /* first find out whether the getrow function is available       */
   /* ------------------------------------------------------------- */

   getrow_obj = Amatrix->getrow;
   if (getrow_obj->ML_id == ML_EXTERNAL) getrowfunc=getrow_obj->external;
   else                                  getrowfunc=getrow_obj->internal;
   if ( getrowfunc == NULL ) 
   {
      printf("ML_Aggregate_CoarsenUncoupledVBlock ERROR : no getrow.\n");
      exit(-1);
   }

   /* ------------------------------------------------------------- */
   /* allocate initial temporary storage space for getrow           */
   /* also allocate space for storing the diagonal (if epsilon>0)   */
   /* ------------------------------------------------------------- */

   col_ind = (int *)    malloc( maxnnz_per_row * sizeof(int) );
   col_val = (double *) malloc( maxnnz_per_row * sizeof(double) );
   if ( Nrows > 0 ) diagonal = (double *) malloc(Nrows * sizeof(double));
   else             diagonal = NULL;

   /* ------------------------------------------------------------- */
   /* find out about how much memory to allocate for the matrix     */
   /* ------------------------------------------------------------- */

   nz_cnt = zerodiag_cnt = 0;
   for ( i = 0; i < Nrows; i++ ) 
   {
      diagonal[i] = 0.0;
      while (getrowfunc(Amatrix->data,1,&i,maxnnz_per_row,col_ind, 
                        col_val,&m) == 0 ) 
      {
         free(col_ind);
         free(col_val);
         maxnnz_per_row = maxnnz_per_row * 2 + 1; 
         col_ind = (int *)    malloc(maxnnz_per_row*sizeof(int));
         col_val = (double *) malloc(maxnnz_per_row*sizeof(double));
      }
      for ( j = 0; j < m; j++ ) 
      {
         if ( col_ind[j] == i ) diagonal[i] = col_val[j];
         /*if (abs(col_val[j]) > diagonal[i]) 
              diagonal[i] = abs(col_val[j]);*/
      }
      nz_cnt += m;
      if ( diagonal[i] == 0.0 ) {nz_cnt++; zerodiag_cnt++;}
   }
   if ( zerodiag_cnt > 0 ) 
      printf("Aggregation Coarsening : %d zero diag\n", zerodiag_cnt);
   if ( epsilon == 0.0 && diagonal != NULL ) 
   {
      free(diagonal);
      diagonal = NULL;
   }

   /* ------------------------------------------------------------- */
   /* allocate memory for the entire matrix (only the column indices*/
   /* are needed since the matrix will be pruned here               */
   /* ------------------------------------------------------------- */

   nbytes = (nz_cnt + 1) * sizeof( int );
   ML_memory_alloc((void**) &mat_indx, nbytes, "AVA");
   k = ML_Comm_GsumInt( comm, Nrows);
   m = ML_Comm_GsumInt( comm, nz_cnt);

#ifdef AGG_OUTPUT
   if ( mypid == 0 ) 
      printf("Aggregation(UVB) : Total nonzeros = %d (Nrows=%d)\n",m,k);
#endif   
   if ( ml_ag->operator_complexity == 0.0 )
   {
      ml_ag->fine_complexity = 1.0 * m;
      ml_ag->operator_complexity = 1.0 * m;
   }
   else ml_ag->operator_complexity += 1.0 * m;

   nz_cnt = Nrows + 1;
   mat_indx[0] = nz_cnt; 

   /* ------------------------------------------------------------- */
   /* extract the matrix using the getrow function                  */
   /* (pruning is done at this stage)                               */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < Nrows; i++ ) 
   {
      getrowfunc(Amatrix->data,1,&i,maxnnz_per_row,col_ind,col_val, &m);
      if ( m > maxnnz_per_row ) printf("Aggregation WARNING (1)\n");

      for (j = 0; j < m; j++) 
      {
         jnode = col_ind[j];
	 if ( jnode != i && jnode < Nrows && epsilon > 0.0 ) 
         {
            dcompare1 = col_val[j] * col_val[j];
            if ( dcompare1 > 0.0 )
            {
	       dcompare2 = diagonal[i] * diagonal[jnode];
	       if ( dcompare1 < 0 ) dcompare1 = - dcompare1;
	       if ( dcompare2 < 0 ) dcompare2 = - dcompare2;
	       if ( dcompare1 >= epsilon * dcompare2 ) 
	          mat_indx[nz_cnt++] = col_ind[j];
            }
         } 
         else if ( jnode != i && jnode < Nrows && col_val[j] != 0.0)
            mat_indx[nz_cnt++] = col_ind[j];
      }
      mat_indx[i+1] = nz_cnt;
   }
   free(col_ind);
   free(col_val);
   if ( diagonal != NULL ) free(diagonal);

   /* ============================================================= */
   /* Construct the matrix that relates to the nodes by combining   */
   /* the rows of the matrix corresponding to different PDE's at    */
   /* the same node.                                                */
   /* ============================================================= */

   nvblockflag = 0;
   if ( nvblocks == 0 )
   {
      nvblocks = Nrows;
      nbytes   = nvblocks * sizeof(int);
      ML_memory_alloc((void**) &vblock_info,nbytes,"AVE");
      for ( i = 0; i < nvblocks; i++ ) vblock_info[i] = 1;
      nvblockflag = 1;
   }    
   nbytes = (nz_cnt + 1) * sizeof( int ); /* probably excessive */
   if (nbytes > 0) ML_memory_alloc((void**) &amal_mat_indx,nbytes,"AVB");
   nbytes = nvblocks * sizeof(int);
   if (nbytes > 0) ML_memory_alloc((void**) &vblock_info2,nbytes,"AVC");
   vblock_info2[0] = vblock_info[0]; 
   for ( i = 1; i < nvblocks; i++ )
      vblock_info2[i] = vblock_info2[i-1] + vblock_info[i];

   amal_count = nvblocks + 1;
   amal_mat_indx[0] = amal_count; 
   row = 0;
   col_entered = (char *) malloc(sizeof(char)*(1+ nvblocks) );
   if (col_entered == NULL) {
      printf("Not enough space in ML_aggregate\n");
      exit(1);
   }
   for ( i = 0; i < nvblocks; i++) col_entered[i] = 'F';

   for ( i = 0; i < nvblocks; i++) {
      col_entered[i] = 'T';
      for ( j = 0; j < vblock_info[i]; j++) {
         for ( k = mat_indx[row]; k < mat_indx[row+1]; k++) {
            if ( mat_indx[k] < vblock_info2[0] ) index = 0;
            else
            {
               index=ML_sorted_search(mat_indx[k],nvblocks,vblock_info2);
               if ( index < 0 ) index = - index;
               else             index++;
            }
            if ( index < 0 || index >= nvblocks )
               printf("ERROR : in almalgamation %d => %d(%d).\n",mat_indx[k],
                       index,nvblocks);
            if (col_entered[index] == 'F') {
               amal_mat_indx[ amal_count++] = index;
               col_entered[index] = 'T';
            }
         }
         row++;
      }
      amal_mat_indx[i+1] = amal_count;
      col_entered[i] = 'F';
      for ( j = amal_mat_indx[i]; j < amal_mat_indx[i+1]; j++)
         col_entered[ amal_mat_indx[j]] = 'F';
   }
   free(col_entered);

#ifdef AGG_OUTPUT
   if ( mypid == 0 ) 
      printf("Aggregation(UVB) : Amalgamated matrix done \n");
#endif

   /* ============================================================= */
   /* perform coarsening                                            */
   /* ============================================================= */

   ML_Aggregate_CoarsenUncoupledCore(ml_ag,comm,Amatrix,amal_mat_indx,
                                     &aggr_count, &aggr_index); 

   /* ============================================================= */
   /* Form tentative prolongator                                    */
   /* ============================================================= */

   Ncoarse = aggr_count * nullspace_dim;
   level   = ml_ag->cur_level;
   nbytes  = Nrows * sizeof( int );
   ML_memory_alloc((void**) &(ml_ag->aggr_info[level]), nbytes, "AVC");
   new_cnt = aggr_count;
   for ( i = 0; i < nvblocks; i++ ) 
   {
      if ( i == 0 ) offset = 0;
      else          offset = vblock_info2[i-1]; 
      if ( aggr_index[i] >= 0 )
      {
         for ( j = 0; j < vblock_info[i]; j++ ) 
            ml_ag->aggr_info[level][offset+j] = aggr_index[i];
      }
      else
      {
         for ( j = 0; j < vblock_info[i]; j++ ) 
            ml_ag->aggr_info[level][offset+j] = new_cnt;
         new_cnt++;
      }
   }
   /*ml_ag->aggr_count[level] = aggr_count; */
   ml_ag->aggr_count[level] = new_cnt; /* for relaxing boundary points */

   /* ------------------------------------------------------------- */
   /* set up the space for storing the new operator and null space  */
   /* ------------------------------------------------------------- */

   nbytes = ( Nrows + 1 ) * sizeof(int); 
   ML_memory_alloc((void**)&(new_ia), nbytes, "AVM");
   nbytes = Nrows * nullspace_dim * sizeof(int);  
   ML_memory_alloc((void**)&(new_ja), nbytes, "AVN");
   nbytes = Nrows * nullspace_dim * sizeof(double); 
   ML_memory_alloc((void**)&(new_val), nbytes, "AVO");
   nbytes = Ncoarse * nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&(new_null),nbytes,"AVX");
   for (i = 0; i < Ncoarse*nullspace_dim; i++) new_null[i] = 0.0;

   /* ------------------------------------------------------------- */
   /* initialize the row pointer for the CSR prolongation operator  */
   /* (each roll will have at most nullspace_dim nonzero entries)   */
   /* ------------------------------------------------------------- */

   for (i = 0; i <= Nrows; i++) new_ia[i] = i * nullspace_dim;

   /* ------------------------------------------------------------- */
   /* temporary variables for use in subsequent processing          */
   /* ------------------------------------------------------------- */

   nbytes = aggr_count * sizeof(int);
   ML_memory_alloc((void**)&agg_sizes,     nbytes,"AVI");
   ML_memory_alloc((void**)&agg_sizes_cum, nbytes, "AVJ");

   /* ------------------------------------------------------------- */
   /* fill the temporary variables and also find the maximum        */
   /* aggregate size for allocation of qr_tmp                       */
   /* ------------------------------------------------------------- */

   for (i = 0; i < nvblocks; i++) 
   {
      if (aggr_index[i] >= 0 && aggr_index[i] < aggr_count) 
         agg_sizes[aggr_index[i]] += vblock_info[i];
      else if (aggr_index[i] != -1) 
      {
         printf("%d : CoarsenUncoupled - wrong index %d(%d)\n",mypid,
                      aggr_index[i], aggr_count);
         exit(1);
      }
   }
   max_agg_size = agg_sizes[0];
   if ( aggr_count > 0 ) agg_sizes_cum[0] = 0;
   for (i = 0; i < aggr_count-1; i++)
   {
      agg_sizes_cum[i+1] = agg_sizes_cum[i] + agg_sizes[i];
      if (agg_sizes[i+1] > max_agg_size) max_agg_size = agg_sizes[i+1];
   }
   ML_memory_free((void**)&agg_sizes_cum);

   /* ------------------------------------------------------------- */
   /* generate an array to store which aggregate has which rows.Then*/
   /* loop through the rows of A checking which aggregate each row  */
   /* is in, and adding it to the appropriate spot in rows_in_aggs  */
   /* ------------------------------------------------------------- */

   ML_memory_alloc((void**)&rows_in_aggs,aggr_count*sizeof(int*),"MLt");
   for (i = 0; i < aggr_count; i++) 
      rows_in_aggs[i] = (int *) malloc(agg_sizes[i]*sizeof(int));
   if (rows_in_aggs[aggr_count-1] == NULL) 
   {
      printf("Error: couldn't allocate memory in CoarsenUncoupledVB\n");
      exit(1);
   }
   for (i = 0; i < aggr_count; i++) agg_sizes[i] = 0;
   for (i = 0; i < nvblocks; i++) 
   {
      if ( aggr_index[i] >= 0 )
      {
         for (j = 0; j < vblock_info[i]; j++)
         {
            index = agg_sizes[aggr_index[i]]++; 
            if ( i == 0 ) offset = 0;
            else          offset = vblock_info2[i-1]; 
            rows_in_aggs[aggr_index[i]][index] = offset + j;
         }
      }
   }

   /* ------------------------------------------------------------- */
   /* allocate work arrays for QR factorization                     */
   /* work and lwork are needed for lapack's QR routine.  These     */
   /* settings seemed easiest since I don't quite understand        */
   /* what they do, but may want to do something better here later  */
   /* ------------------------------------------------------------- */

   nbytes = max_agg_size * nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&qr_tmp, nbytes, "AVU");
   nbytes = nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&tmp_vect, nbytes, "AVT");

   lwork  = nullspace_dim;
   nbytes = nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&work, nbytes, "AVK");

   for (i = 0; i < aggr_count; i++) 
   {
      /* set up the matrix we want to decompose into Q and R: */

      if (nullspace_vect == NULL) 
      {
         for (j = 0; j < agg_sizes[i]; j++)
            for (k = 0; k < nullspace_dim; k++)
            {
               row = rows_in_aggs[i][j];
               if ( row < vblock_info2[0] ) index = 0;
               else
               {
                  index = ML_sorted_search(row,nvblocks,vblock_info2);
                  if ( index < 0 ) index = - index;
                  else             index++;
               }
               if ( index == 0 ) offset = row; 
               else              offset = row-vblock_info2[index-1];
               if ( offset == k ) qr_tmp[k*agg_sizes[i] + j] = 1.0;
               else               qr_tmp[k*agg_sizes[i] + j] = 0.0;
            } 
      }
      else 
      {
         for (k = 0; k < nullspace_dim; k++)
            for (j = 0; j < agg_sizes[i]; j++)
               qr_tmp[k*agg_sizes[i] + j] = 
                  nullspace_vect[ k*Nrows + rows_in_aggs[i][j] ];
      }

      /* now calculate QR using an LAPACK routine */

      MLFORTRAN(dgeqrf)(&(agg_sizes[i]), &nullspace_dim, qr_tmp, 
                        &(agg_sizes[i]), tmp_vect, work, &lwork, &info);
      if (info != 0)
         pr_error("Error in CoarsenUncoupled : dgeqrf returned a non-zero\n");

      if (work[0] > lwork) 
      {
         lwork=(int) work[0]; 
         ML_memory_free((void**) &work);
         ML_memory_alloc((void**) &work, sizeof(double)*lwork, "AGk");
      }
      else lwork=work[0];
		 
      /* the upper triangle of qr_tmp is now R, so copy that into the 
         new nullspace */

      for (j = 0; j < nullspace_dim; j++)
         for (k = j; k < nullspace_dim; k++)
            new_null[i*nullspace_dim+j+k*Ncoarse] = qr_tmp[j+agg_sizes[i]*k];
		 
      /* to get this block of P, need to run qr_tmp through another LAPACK 
         function: */

      MLFORTRAN(dorgqr)(&(agg_sizes[i]), &nullspace_dim, &nullspace_dim, 
              qr_tmp, &(agg_sizes[i]), tmp_vect, work, &lwork, &info);
      if (info != 0)
         pr_error("Error in CoarsenUncoupled: dorgqr returned a non-zero\n");

      if (work[0] > lwork) 
      {
         lwork=(int) work[0]; 
         ML_memory_free((void**) &work);
         ML_memory_alloc((void**) &work, sizeof(double)*lwork, "AVM");
      }
      else lwork=work[0];
		 
      /* now copy Q over into the appropriate part of P: */
      /* The rows of P get calculated out of order, so I assume the Q is 
         totally dense and use what I know of how big each Q will be to 
         determine where in ia, ja, etc each nonzero in Q belongs.  If I 
         did not assume this, I would have to keep all of P in memory in 
         order to determine where each entry should go */

      for (j = 0; j < agg_sizes[i]; j++)
      {
         for (k = 0; k < nullspace_dim; k++) 
         {
            index = new_ia[rows_in_aggs[i][j]] + k;
            new_ja [index] = i * nullspace_dim + k;
            new_val[index] = qr_tmp[ k*agg_sizes[i] + j ];
         }
      }
   }
	 
   ML_Aggregate_Set_NullSpace(ml_ag, nullspace_dim, nullspace_dim, 
                              new_null, Ncoarse);
   ML_memory_free( (void **) &new_null);

   /* ------------------------------------------------------------- */
   /* compress the prolongation operator                            */
   /* ------------------------------------------------------------- */

   k     = new_ia[0];
   index = k;
   for (i = 0; i < Nrows; i++)
   {
      for (j = k; j < new_ia[i+1]; j++ )
      {
         if ( new_val[j] != 0.0 )
         {
            new_val[index]  = new_val[j];  
            new_ja[index++] = new_ja[j];  
         }
      }
      if ( index == new_ia[i] ) 
      {
         new_val[index] = new_val[k]; new_ja[index++] = new_ja[k];
      }
      k = new_ia[i+1];
      new_ia[i+1] = index;
   }
   ML_memory_alloc((void**) &csr_data, sizeof(struct ML_CSR_MSRdata), "AVP");
   csr_data->rowptr  = new_ia;
   csr_data->columns = new_ja;
   csr_data->values  = new_val;
   (*Pmatrix) = ML_Operator_Create();
   ML_Operator_Set_ApplyFuncData( *Pmatrix, Ncoarse, Nrows, ML_EMPTY,
                                  csr_data, Nrows, NULL, 0);
   (*Pmatrix)->data_destroy = ML_CSR_MSR_ML_memorydata_Destroy;
   ML_memory_alloc((void**) &aggr_comm, sizeof(ML_Aggregate_Comm), "AVQ");
   aggr_comm->comm = comm;
   aggr_comm->N_send_neighbors = 0;
   aggr_comm->N_recv_neighbors = 0;
   aggr_comm->send_neighbors = NULL;
   aggr_comm->recv_neighbors = NULL;
   aggr_comm->send_leng = NULL;
   aggr_comm->recv_leng = NULL;
   aggr_comm->send_list = NULL;
   aggr_comm->local_nrows = Ncoarse;
   
   ML_CommInfoOP_Generate( &((*Pmatrix)->getrow->pre_comm), 
                           ML_Aggregate_ExchangeBdry, aggr_comm, 
                           comm, Ncoarse, m);
   ML_Operator_Set_Getrow((*Pmatrix), ML_EXTERNAL, Nrows, CSR_getrows);
   ML_Operator_Set_ApplyFunc((*Pmatrix), ML_INTERNAL, CSR_matvec);

   /* ============================================================= */
   /* clean up                                                      */
   /* ============================================================= */

   ML_memory_free((void**) &vblock_info2);
   ML_memory_free((void**) &mat_indx);
   ML_memory_free((void**) &amal_mat_indx);
   ML_memory_free((void**) &aggr_index);
   ML_memory_free((void**)&agg_sizes);
   for (i = 0; i < aggr_count; i++) free(rows_in_aggs[i]);
   ML_memory_free((void**)&rows_in_aggs);
   ML_memory_free((void**)&qr_tmp);
   ML_memory_free((void**)&tmp_vect);
   ML_memory_free((void**)&work);
   ML_memory_free((void**)&aggr_comm);
   if ( nvblocks == 1 ) ML_memory_free((void**)&vblock_info);

   return Ncoarse;
}

/* ******************************************************************** */
/* ******************************************************************** */
/* ML_Aggregate_CoarsenCoupledVBlock subroutine.                        */
/* -------------------------------------------------------------------- */
/* -------------------------------------------------------------------- */

int ML_Aggregate_CoarsenCoupledVBlock( ML_Aggregate *ml_ag,
       ML_Operator *Amatrix, ML_Operator **Pmatrix, ML_Comm *comm)
{
   int     i, j, k, m, jj, jnode, index, index3, index4, offset, count; 
   int     max_count, nz_cnt, nbytes, length, level, diff_level;
   int     Nrows, exp_Nrows, *mat_indx=NULL, *amal_mat_indx, nvblocks;
   int     maxnnz_per_row=500, *vblock_info, *col_ind;
   int     N_neighbors, *neighbors, *recv_leng, *send_leng, *send_list;
   int     total_recv_leng, total_send_leng, msgtype, mypid, new_N_send;
   int     *new_send_neighbors, *new_send_list, *new_send_leng;
   int     new_N_recv, *new_recv_leng, *new_recv_neighbors, *int_buf;
   int     *int_buf2, *recv_list, nprocs;
   int     aggr_count, *aggr_index, *aggr_index2;
   int     *aggr_cnt_array, max_agg_size, **rows_in_aggs;
   int     Ncoarse, exp_Ncoarse, *new_ia, *new_ja, new_Nrows;
   int     num_PDE_eqns, nullspace_dim, lwork, info;
   double  *col_val, *diagonal=NULL, dcompare1, dcompare2, *new_val=NULL;
   double  epsilon, *dble_buf=NULL, *nullspace_vect=NULL, *qr_tmp=NULL;
   double  *tmp_vect=NULL, *work=NULL, *new_null=NULL, *comm_val=NULL;
   double  *dble_buf2;
   int     (*getrowfunc)(void *,int,int*,int,int*,double*,int*);
   struct ML_CSR_MSRdata *csr_data;
   ML_Aggregate_Comm     *aggr_comm;
   ML_GetrowFunc         *getrow_obj;
   ML_CommInfoOP         *getrow_comm;

   /* ============================================================= */
   /* get machine and matrix information                            */
   /* ============================================================= */

   mypid          = comm->ML_mypid;
   nprocs         = comm->ML_nprocs;
   nullspace_dim  = ml_ag->nullspace_dim;
   nullspace_vect = ml_ag->nullspace_vect;
   Nrows          = Amatrix->outvec_leng;

   /* ============================================================= */
   /* initialize and update the threshold                           */
   /* ============================================================= */

   diff_level = ml_ag->begin_level - ml_ag->cur_level;
   if ( diff_level == 0 ) ml_ag->curr_threshold = ml_ag->threshold;
   epsilon = ml_ag->curr_threshold;
   ml_ag->curr_threshold *= 0.5;

#ifdef AGG_OUTPUT
   if ( mypid == 0 )
   {
      printf("ML_Aggregate_CoarsenCoupledVBlock : current level = %d\n",
                           ml_ag->cur_level);
      printf("ML_Aggregate_CoarsenCoupledVBlock : current eps = %e\n",
                           epsilon);
   }
#endif
   epsilon = epsilon * epsilon;

   /* ============================================================= */
   /* fetch the getrow function for the incoming matrix             */
   /* ============================================================= */

   getrow_obj = Amatrix->getrow;
   if (getrow_obj->ML_id == ML_EXTERNAL) getrowfunc = getrow_obj->external;
   else                                  getrowfunc = getrow_obj->internal;
   if ( getrowfunc == NULL )
   {
      printf("ML_Aggregate_CoarsenCoupledVBlock ERROR : null getrowfunc.\n");
      exit(-1);
   }

   /* ============================================================= */
   /* allocate initial temporary storage space for getrow           */
   /* also allocate space for storing the diagonal                  */
   /* ============================================================= */

   nbytes = maxnnz_per_row * sizeof( int );
   ML_memory_alloc((void**) &col_ind, nbytes, "AGA");
   nbytes = maxnnz_per_row * sizeof( double );
   ML_memory_alloc((void**) &col_val, nbytes, "AGB");
   if ( Nrows > 0 )
   {
      nbytes = Nrows * sizeof( double );
      ML_memory_alloc((void**) &diagonal, nbytes, "AGC");
   }
   else diagonal = NULL;

   /* ============================================================= */
   /* fill in the diagonal array, also find out about the size of   */
   /* the incoming matrix (for allocation purpose)                  */
   /* ============================================================= */

   exp_Nrows = Nrows - 1;
   count = 0;
   for ( i = 0; i < Nrows; i++ )
   {
      diagonal[i]     = 0.0;
      while (getrowfunc(Amatrix->data,1,&i,maxnnz_per_row,col_ind,
                        col_val, &m) == 0 )
      {
         ML_memory_free((void**) &col_ind);
         ML_memory_free((void**) &col_val);
         maxnnz_per_row = maxnnz_per_row * 2 + 1;
         nbytes = maxnnz_per_row * sizeof( int );
         ML_memory_alloc((void**) &col_ind, nbytes, "AGD");
         nbytes = maxnnz_per_row * sizeof( double );
         ML_memory_alloc((void**) &col_val,  nbytes, "AGE");
      }
      for ( j = 0; j < m; j++ )
      {
         if ( col_ind[j] > exp_Nrows ) exp_Nrows = col_ind[j];
         if ( col_ind[j] == i )        diagonal[i] = col_val[j];
      }
      count += m;
      if ( diagonal[i] == 0.0 )
      {
         printf("%d : CoarsenCoupledVBlock WARNING - diag %d is 0.\n",mypid,i);
         count++;
      }
   }
   exp_Nrows++;

   /* ============================================================= */
   /* build the diagonals of the expanded rows if epsilon != 0      */
   /* (diagonal elements are needed for pruning weak edges)         */
   /* ============================================================= */

   if ( epsilon == 0.0 && diagonal != NULL )
   {
      ML_memory_free((void**) &diagonal);
      diagonal = NULL;
   }

   if ( epsilon != 0.0 && exp_Nrows > 0 )
   {
      dble_buf = diagonal;
      nbytes = exp_Nrows * sizeof(double);
      ML_memory_alloc((void**) &diagonal, nbytes, "AGF");
      for ( i = 0; i < Nrows; i++ ) diagonal[i] = dble_buf[i];
      for ( i = Nrows; i < exp_Nrows; i++ ) diagonal[i] = 0.0;
      ML_memory_free((void**) &dble_buf);
      getrow_comm = getrow_obj->pre_comm;
      if ( getrow_comm != NULL )
         ML_exchange_bdry(diagonal,getrow_comm,Nrows,comm,ML_OVERWRITE);
   }

   /* ============================================================= */
   /* allocate temporary storage space for getrow                   */
   /* ============================================================= */

printf("%d : CHECK 0\n", mypid);
   nbytes = (count + 1) * sizeof( int );
   ML_memory_alloc((void**) &mat_indx, nbytes, "AGI");
   k = ML_Comm_GsumInt( comm, Nrows);
   m = ML_Comm_GsumInt( comm, count);
   nbytes = maxnnz_per_row * sizeof(int);
   ML_memory_alloc((void**) &col_ind, nbytes, "AGJ");
   nbytes = maxnnz_per_row * sizeof(double);
   ML_memory_alloc((void**) &col_val, nbytes, "AGK");

   k = ML_Comm_GsumInt( comm, Nrows);
   m = ML_Comm_GsumInt( comm, count);
#ifdef AGG_OUTPUT
   if ( mypid == 0 )
      printf("Aggregation(CVB) : Total nnz = %d (Nrows=%d)\n",m,k);
#endif
   if ( ml_ag->operator_complexity == 0.0 )
   {
      ml_ag->fine_complexity = 1.0 * m;
      ml_ag->operator_complexity = 1.0 * m;
   }
   else
   {
      ml_ag->operator_complexity += 1.0 * m;
   }

   /* ============================================================= */
   /* extract and prune the matrix using the getrow function        */
   /* ============================================================= */

printf("%d : CHECK 1\n", mypid);
   nz_cnt = Nrows + 1;
   mat_indx[0] = nz_cnt;
   for ( i = 0; i < Nrows; i++ )
   {
      getrowfunc(Amatrix->data,1,&i,maxnnz_per_row,col_ind,col_val,&m);
      for (j = 0; j < m; j++)
      {
         jnode = col_ind[j];
         if ( jnode != i && epsilon > 0.0 )
         {
            dcompare1 = col_val[j] * col_val[j];
            if ( dcompare1 > 0.0 )
            {
               dcompare2 = abs((diagonal[i] * diagonal[jnode]));
               if ( dcompare1 >= epsilon * dcompare2 )
                  mat_indx[nz_cnt++] = col_ind[j];
            }
         }
         else if ( jnode != i && col_val[j] != 0.0 )
         {
            mat_indx[nz_cnt++] = col_ind[j];
         }
      }
      mat_indx[i+1] = nz_cnt;
      ML_sort(mat_indx[i+1]-mat_indx[i], mat_indx+mat_indx[i]);
   }
   if ( col_ind  != NULL ) ML_memory_free((void**) &col_ind);
   if ( col_val  != NULL ) ML_memory_free((void**) &col_val);
   if ( diagonal != NULL ) ML_memory_free((void**) &diagonal);

   /* ============================================================= */
   /* get the off-processor variable block information              */
   /* ==> nvblocks, vblock_info (of length exp_Nrows)               */
   /* ============================================================= */

printf("%d : CHECK 2\n", mypid);
   nvblocks = exp_Nrows;
   nbytes   = nvblocks * sizeof(int);
   ML_memory_alloc((void**) &vblock_info, nbytes, "AVE");
   if ( ml_ag->nvblocks == 0 )
   {
      for ( i = 0; i < exp_Nrows; i++ ) vblock_info[i] = i;
   } 
   else
   {
      nbytes = exp_Nrows * sizeof(double);
      dble_buf = (double *) malloc(nbytes);
      count = 0;
      for ( i = 0; i < ml_ag->nvblocks; i++ )
      {
         for ( j = 0; j < ml_ag->vblock_info[i]; j++ )
         {
            vblock_info[count] = i;
            dble_buf[count++] = mypid * 10000 + i;
         }
      }
      getrow_comm = getrow_obj->pre_comm;
      if ( getrow_comm != NULL )
         ML_exchange_bdry(dble_buf,getrow_comm,Nrows,comm,ML_OVERWRITE);
      count = ml_ag->nvblocks - 1;
      for ( i = Nrows; i < exp_Nrows; i++ )
      {
         if ( dble_buf[i] != dble_buf[i-1] ) count++;
         vblock_info[i] = count;
      }
      count++;
      free( dble_buf );
   }

   /* ============================================================= */
   /* compress the matrix using vblock information                  */
   /* ============================================================= */

printf("%d : CHECK 3\n", mypid);
   ML_Aggregate_Compress_Matrix(Amatrix, mat_indx, nvblocks, vblock_info, 
                &amal_mat_indx, &N_neighbors, &neighbors, &recv_leng,
                &send_leng, &send_list, &recv_list);

   /* ============================================================= */
   /* perform coarsening on the compressed matrix                   */
   /* ============================================================= */

printf("%d : CHECK 4\n", mypid);
   ML_Aggregate_CoarsenCoupledCore(ml_ag,comm,Amatrix,amal_mat_indx,
       &aggr_count, &aggr_index2, N_neighbors, neighbors, recv_leng,
       send_leng, send_list, recv_list, &aggr_cnt_array);

   /* ============================================================= */
   /* decode aggr_index2 to recover the block information           */
   /* after this, nodes that are aggregated locally are given a     */
   /* non-negative integer, and nodes that are not aggregated       */
   /* locally are given a negative number with PID on it.           */
   /* ============================================================= */

printf("%d : CHECK 5\n", mypid);
   nbytes = exp_Nrows * sizeof(int);
   ML_memory_alloc((void**) &aggr_index, nbytes, "AVF");
   for ( i = 0; i < exp_Nrows; i++ )
   {
      aggr_index[i] = aggr_index2[vblock_info[i]];
   }   
   free( aggr_index2 );
   aggr_index2 = NULL;
for (i=0; i<exp_Nrows; i++)
   printf("%d : aggr_index[%4d] = %d\n", mypid, i, aggr_index[i]);

   /* ============================================================= */
   /* Form tentative prolongator                                    */
   /* ============================================================= */

   Ncoarse = aggr_count;

   /* ------------------------------------------------------------- */
   /* construct send information for restriction                    */
   /* ------------------------------------------------------------- */

   nbytes = N_neighbors * sizeof(int);
   if ( nbytes > 0 )
   {
      ML_memory_alloc((void**) &new_send_leng, nbytes, "AGi");
      ML_memory_alloc((void**) &new_send_neighbors, nbytes, "AGj");
   }
   else new_send_leng = new_send_neighbors = NULL;
   for (i = 0; i < N_neighbors; i++) new_send_leng[i] = 0;
   for (i = 0; i < N_neighbors; i++) new_send_neighbors[i] = neighbors[i];
   for (i = 0; i < Nrows; i++ )
   {
      if ( aggr_index[i] < 0 )
      {
         index = - aggr_index[i] - 100;
         for ( j = 0; j < N_neighbors; j++ )
            if ( neighbors[j] == index ) break;
         new_send_leng[j]++;
      }
   }
   new_N_send = 0;
   for ( i = 0; i < N_neighbors; i++ )
   {
      if ( new_send_leng[i] > 0 ) 
      {
         new_send_neighbors[new_N_send] = neighbors[i];
         new_send_leng[new_N_send++] = new_send_leng[i];
      }
   }
   total_send_leng = 0;
   for ( i = 0; i < new_N_send; i++ )
      total_send_leng += new_send_leng[i];
   nbytes = total_send_leng * sizeof(int); 
   if ( nbytes > 0 )
        ML_memory_alloc((void**) &new_send_list, nbytes, "AGk");
   else new_send_list = NULL;
   if (new_N_send > 0) int_buf = (int *) malloc(new_N_send * sizeof(int));
   if ( new_N_send > 0 ) int_buf[0] = 0;
   for (i=1; i < new_N_send; i++) int_buf[i]=int_buf[i-1]+new_send_leng[i-1];
   for (i = 0; i < Nrows; i++ )
   {
      if ( aggr_index[i] < 0 )
      {
         index = - aggr_index[i] - 100;
         new_send_list[int_buf[index]++] = i;
      }
   }
   if ( new_N_send > 0 ) free( int_buf );
   
   /* ------------------------------------------------------------- */
   /* communicate this new send information to other processors     */
   /* ------------------------------------------------------------- */

   ML_Aggregate_ComposeRecvInfo(nprocs,mypid,new_N_send,new_send_leng,
      new_send_neighbors,&new_N_recv, &new_recv_leng, &new_recv_neighbors,
      comm);

   /* ------------------------------------------------------------- */
   /* get communication information for the original matrix A       */
   /* ------------------------------------------------------------- */

   N_neighbors = getrow_obj->pre_comm->N_neighbors;
   nbytes = N_neighbors * sizeof( int );
   if ( nbytes > 0 )
   {
      ML_memory_alloc((void**) &neighbors,  nbytes, "AGL");
      ML_memory_alloc((void**) &recv_leng,  nbytes, "AGM");
      ML_memory_alloc((void**) &send_leng,  nbytes, "AGN");
   }
   else
   {
      neighbors = recv_leng = send_leng = NULL;
   }
   for ( i = 0; i < N_neighbors; i++ )
   {
      neighbors[i] = getrow_obj->pre_comm->neighbors[i].ML_id;
      recv_leng[i] = getrow_obj->pre_comm->neighbors[i].N_rcv;
      send_leng[i] = getrow_obj->pre_comm->neighbors[i].N_send;
   }
   total_recv_leng = total_send_leng = 0;
   for ( i = 0; i < N_neighbors; i++ )
   {
      total_recv_leng += recv_leng[i];
      total_send_leng += send_leng[i];
   }
   total_send_leng = 0;
   for ( i = 0; i < N_neighbors; i++ ) total_send_leng += send_leng[i];
   nbytes = total_send_leng * sizeof( int );
   if ( nbytes > 0 ) ML_memory_alloc((void**) &send_list,nbytes,"AGO");
   else              send_list = NULL;
   count = 0;
   for ( i = 0; i < N_neighbors; i++ )
   {
      for (j = 0; j < send_leng[i]; j++)
         send_list[count++] =
            getrow_obj->pre_comm->neighbors[i].send_list[j];
   }
   total_recv_leng = 0;
   for ( i = 0; i < N_neighbors; i++ ) total_recv_leng += recv_leng[i];
   nbytes = total_recv_leng * sizeof( int );
   if ( nbytes > 0 ) ML_memory_alloc((void**) &recv_list,nbytes,"AGP");
   else              recv_list = NULL;
   count = 0;
   for ( i = 0; i < N_neighbors; i++ )
   {
      for (j = 0; j < recv_leng[i]; j++)
         recv_list[count++] =
            getrow_obj->pre_comm->neighbors[i].rcv_list[j];
   }

   /* ------------------------------------------------------------- */
   /* now aggr_index tells how the nodes are aggregated (nonnegative*/
   /* for local aggregates and negative otherwise).  The next task  */
   /* consists of processing this information.                      */ 
   /* ------------------------------------------------------------- */
   /* send the remote node index back to remote processors, with    */
   /* added information on which remote nodes have been aggregated  */
   /* by the local aggregates (and also the aggregate numbers).     */
   /* ------------------------------------------------------------- */

   nbytes = total_send_leng * sizeof(int);
   if ( nbytes > 0 ) ML_memory_alloc((void**) &int_buf, nbytes, "AGg");
   else              int_buf = NULL;
   nbytes = total_recv_leng * sizeof(int);
   if ( nbytes > 0 ) ML_memory_alloc((void**) &int_buf2, nbytes, "AGh");
   else              int_buf2 = NULL;

   offset = 0;
   for ( i = 0; i < N_neighbors; i++ )
   {
      for ( j = 0; j < recv_leng[i]; j++ )
      {
         if ( aggr_index[recv_list[offset+j]] < 0 ) int_buf2[offset+j] = -1;
         else int_buf2[offset+j] = aggr_index[recv_list[offset+j]];
      }
      offset += recv_leng[i];
   }
   msgtype = 15963;
   ML_Aggregate_ExchangeData2((char*) int_buf, (char*) int_buf2,
      N_neighbors, neighbors, send_leng, recv_leng, NULL, Nrows, msgtype, 
      ML_INT, comm);

   if ( int_buf2 != NULL ) ML_memory_free((void**) &int_buf2);

   /* ------------------------------------------------------------- */
   /* if int_buf[i] > 0, this means that aggr_index[send_list[i]]   */
   /* has been aggregated by a remote processor.  The next step     */
   /* uses this information to update aggr_index and Ncoarse        */
   /* ------------------------------------------------------------- */

   offset = 0;
   m      = 0; /* store the local index offset for remote processors */
   new_N_recv = 0;
   nbytes = N_neighbors * sizeof(int);
   if ( nbytes > 0 )
   {
      ML_memory_alloc((void**) &new_recv_leng, nbytes, "AGi");
      ML_memory_alloc((void**) &new_recv_neighbors, nbytes, "AGj");
   }
   else
   {
      new_recv_leng = new_recv_neighbors = NULL;
   }
   for ( i = 0; i < N_neighbors; i++ )
   {
      /* ---------------------------------------------------------- */
      /* find out how large an array to allocate for int_buf2,      */
      /* which is used to count the number of distinct aggregates   */
      /* remote processor neighbor[i] used on my local nodes        */
      /* ---------------------------------------------------------- */

      max_count = -1;
      for ( j = 0; j < send_leng[i]; j++ )
      {
         index = int_buf[offset+j];
         max_count = (index > max_count ) ? index : max_count;
      }
      nbytes = ( max_count + 2 ) * sizeof(int);
      if (nbytes > 0) ML_memory_alloc((void **) &int_buf2, nbytes, "AGk");

      /* ---------------------------------------------------------- */
      /* see how many distinct remote aggregates are referenced by  */
      /* local fine nodes in aggregation in neighbor[i]             */
      /* ---------------------------------------------------------- */

      for ( j = 0; j <= max_count; j++ ) int_buf2[j] = 0;
      for ( j = 0; j < send_leng[i]; j++ )
      {
         index = int_buf[offset+j];
         if ( index >= 0 ) int_buf2[index]++;
         if (index >= 0 && index > max_count)
            {printf("int_buf2 error : maxcount\n");exit(1);}
      }
      count = 0;
      for ( j = 0; j <= max_count; j++ )
      {
         if (int_buf2[j] > 0)
         {
            count++; int_buf2[j] = 1;
         }
      }
      for ( j = max_count; j > 0; j-- ) int_buf2[j] = int_buf2[j-1];
      int_buf2[0] = 0;
      for ( j = 0; j < max_count; j++ ) int_buf2[j+1] += int_buf2[j];

      /* ---------------------------------------------------------- */
      /* receive information for interpolation                      */
      /* ---------------------------------------------------------- */

      if ( count > 0 )
      {
         new_recv_leng[new_N_recv] = count * nullspace_dim;
         new_recv_neighbors[new_N_recv] = neighbors[i];
         new_N_recv++;
      }

      /* ---------------------------------------------------------- */
      /* now assign local aggregate indices to local nodes that are */
      /* aggregated by remote processors                            */
      /* ---------------------------------------------------------- */

      for ( j = 0; j < send_leng[i]; j++ )
      {
         index = send_list[offset+j];

         /* ------------------------------------------------------- */
         /* The first condition indicates that the local node has   */
         /* been registered to have been aggregated by remote       */
         /* aggregates.  The second condition is needed in case     */
         /* the local node is linked to more than 1 remote          */
         /* processor (but only to one aggregate though)            */
         /* int_buf2 contains local indices of remote aggregates    */
         /* ------------------------------------------------------- */

         if ( aggr_index[index] <= -100 && int_buf[offset+j] >= 0 )
         {
            k = int_buf[offset+j];
            aggr_index[index] = int_buf2[k] + Ncoarse + m;
         }
      }
      if (nbytes > 0) ML_memory_free((void **) &int_buf2);
      m += count;
      offset += send_leng[i];
   }
   exp_Ncoarse = Ncoarse + m;

   if ( int_buf  != NULL ) ML_memory_free((void**) &int_buf);

printf("%d : (C) Ncoarse = %d\n", mypid, Ncoarse);
fflush(stdout);
while (1) {}
   /* ============================================================= */
   /* compare aggr_index and vblock_info to ensure proper alignment */
   /* of dofs per block in processors                               */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < Nrows; i++ )
   {
      if ( aggr_index[i] >= Ncoarse )
      index = i - 1;
      while ( vblock_info[i] == vblock_info[index] )
         aggr_index[index--] = aggr_index[i];
      index = i + 1;
      while ( vblock_info[i] == vblock_info[index] )
         aggr_index[index++] = aggr_index[i];
   }

   /* ============================================================= */
   /* check and copy aggr_index to ml_ag (for block smoothing)      */
   /* ------------------------------------------------------------- */

   level = ml_ag->cur_level;
   nbytes = Nrows * sizeof( int );
   ML_memory_alloc((void**) &(ml_ag->aggr_info[level]), nbytes, "AGl");
   count = aggr_count;
   for ( i = 0; i < Nrows; i++ )
   {
      ml_ag->aggr_info[level][i] = aggr_index[i];
      if (aggr_index[i] >= count) count = aggr_index[i] + 1;
   }
   ml_ag->aggr_count[level] = count; /* for relaxing boundary points */

   /* ============================================================= */
   /* find out how many local coarse aggregates are needed by       */
   /* remote processors for interpolation (to construct the         */
   /* communicator - send info - for P)                             */
   /* ------------------------------------------------------------- */

   new_N_send = 0;
   if ( N_neighbors > 0 )
   {
      nbytes = N_neighbors * sizeof(int);
      ML_memory_alloc((void**) &int_buf, nbytes, "AGm");
      nbytes = Ncoarse * sizeof(int);
      ML_memory_alloc((void**) &int_buf2, nbytes, "AGn");
      for ( i = 0; i < N_neighbors; i++ ) int_buf[i] = 0;

      /* ---------------------------------------------------------- */
      /* count which remote fine nodes belong to local aggregates   */
      /* in order to generate the communication pattern for         */
      /* the interpolation operator.                                */
      /* ---------------------------------------------------------- */

      offset = Nrows;
      for ( i = 0; i < N_neighbors; i++ )
      {
         for ( j = 0; j < Ncoarse; j++ ) int_buf2[j] = 0;
         for ( j = 0; j < recv_leng[i]; j++ )
         {
            index = aggr_index[offset++];
            if ( index >= 0 ) int_buf2[index]++;
         }
         count = 0;
         for ( j = 0; j < Ncoarse; j++ ) if ( int_buf2[j] > 0 ) count++;
         int_buf[i] = count * nullspace_dim;
         if ( int_buf[i] > 0 ) new_N_send++;
      }

      /* ---------------------------------------------------------- */
      /* now the number of neighbors for P has been found, the next */
      /* step is to find the send_list and send_leng for the matvec */
      /* function for interpolation                                 */
      /* ---------------------------------------------------------- */

      nbytes = new_N_send * sizeof(int);
      if ( nbytes > 0 )
      {
         ML_memory_alloc((void**) &new_send_leng, nbytes, "AGo");
         ML_memory_alloc((void**) &new_send_neighbors, nbytes, "AGp");
         new_N_send = 0;
         for ( i = 0; i < N_neighbors; i++ )
         {
            if ( int_buf[i] > 0 )
            {
               new_send_leng[new_N_send] = int_buf[i];
               new_send_neighbors[new_N_send] = neighbors[i];
               new_N_send++;
            }
         }
         count = 0;
         for ( i = 0; i < new_N_send; i++ ) count += new_send_leng[i];
         nbytes = count * sizeof(int);
         ML_memory_alloc((void**) &new_send_list, nbytes, "AGq");
         offset = Nrows;
         m = count;
         count = 0;
         for ( i = 0; i < N_neighbors; i++ )
         {
            for ( j = 0; j < Ncoarse; j++ ) int_buf2[j] = 0;
            for ( j = 0; j < recv_leng[i]; j++ )
            {
               index = aggr_index[offset++];
               if ( index >= 0 ) int_buf2[index]++;
            }
            for ( j = 0; j < Ncoarse; j++ )
            {
               if ( int_buf2[j] > 0 )
               {
                  for ( jj = 0; jj < nullspace_dim; jj++ )
                     new_send_list[count++] = j * nullspace_dim + jj;
               }
            }
         }
         if ( m != count )
         {
            printf("ML_Aggregate_CoupledVBlock : internal error (1).\n");
            exit(-1);
         }
      }
      else
      {
         new_send_leng = NULL;
         new_send_neighbors = NULL;
         new_send_list = NULL;
      } 
      ML_memory_free((void**) &int_buf);
      ML_memory_free((void**) &int_buf2);
   }
   else
   {
      new_send_leng = NULL;
      new_send_neighbors = NULL;
      new_send_list = NULL;
   }

   /* ============================================================= */
   /* set up the new operator                                       */
   /* ------------------------------------------------------------- */

   new_Nrows = Nrows;
   for ( i = 0; i < new_Nrows; i++ )
   {
      if ( aggr_index[i] >= exp_Ncoarse )
         printf("WARNING : index out of bound %d = %d(%d)\n",i,aggr_index[i],
                exp_Ncoarse);
   }
   nbytes = ( new_Nrows + 1 ) * sizeof(int);
   ML_memory_alloc((void**)&(new_ia), nbytes, "AIA");
   nbytes = new_Nrows * nullspace_dim * sizeof(int);
   ML_memory_alloc((void**)&(new_ja), nbytes, "AJA");
   nbytes = new_Nrows * nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&(new_val), nbytes, "AVA");
   for ( i = 0; i < new_Nrows*nullspace_dim; i++ ) new_val[i] = 0.0;

   /* ------------------------------------------------------------- */
   /* set up the space for storing the new null space               */
   /* ------------------------------------------------------------- */

   nbytes = Ncoarse * nullspace_dim * nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&(new_null),nbytes,"AGr");
   for (i = 0; i < Ncoarse*nullspace_dim*nullspace_dim; i++)
      new_null[i] = 0.0;

   /* ------------------------------------------------------------- */
   /* initialize the row pointer for the CSR prolongation operator  */
   /* (each row will have at most nullspace_dim nonzero entries)    */
   /* ------------------------------------------------------------- */

   for (i = 0; i <= Nrows; i++) new_ia[i] = i * nullspace_dim;

   /* ------------------------------------------------------------- */
   /* generate an array to store which aggregate has which rows.Then*/
   /* loop through the rows of A checking which aggregate each row  */
   /* is in, and adding it to the appropriate spot in rows_in_aggs  */
   /* ------------------------------------------------------------- */

printf("%d : (C) aggr_count = %d\n", mypid, aggr_count);
   ML_memory_alloc((void**)&rows_in_aggs,aggr_count*sizeof(int*),"MLs");
   for (i = 0; i < aggr_count; i++)
   {
      rows_in_aggs[i] = (int *) malloc(aggr_cnt_array[i]*sizeof(int));
      aggr_cnt_array[i] = 0;
      if (rows_in_aggs[i] == NULL)
      {
         printf("ERROR: couldn't allocate memory in CoarsenCoupled\n");
         printf("       requested = %d\n",aggr_cnt_array[i]*sizeof(int));
         exit(1);
      }
   }
   for (i = 0; i < exp_Nrows; i++)
   {
      if ( aggr_index[i] >= 0 && aggr_index[i] < aggr_count)
      {
         index = aggr_cnt_array[aggr_index[i]]++;
         rows_in_aggs[aggr_index[i]][index] = i;
      }
   }

   /* ------------------------------------------------------------- */
   /* allocate work arrays for QR factorization                     */
   /* work and lwork are needed for lapack's QR routine.  These     */
   /* settings seemed easiest since I don't quite understand        */
   /* what they do, but may want to do something better here later  */
   /* ------------------------------------------------------------- */

   nbytes = total_recv_leng * nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&comm_val, nbytes, "AGt");
   for (i = 0; i < total_recv_leng*nullspace_dim; i++) comm_val[i] = 0.0;
   max_agg_size = 0;
   for (i = 0; i < aggr_count; i++)
   {
      if (aggr_cnt_array[i] > max_agg_size) max_agg_size = aggr_cnt_array[i];
   }
   nbytes = max_agg_size * nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&qr_tmp, nbytes, "AGu");
   nbytes = nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&tmp_vect, nbytes, "AGv");

   lwork  = nullspace_dim;
   nbytes = nullspace_dim * sizeof(double);
   ML_memory_alloc((void**)&work, nbytes, "AGw");

   /* ------------------------------------------------------------- */
   /* ship the null space information to other processors           */
   /* ------------------------------------------------------------- */

   if (nullspace_vect != NULL)
   {
      nbytes = total_send_leng * nullspace_dim * sizeof(double);
      ML_memory_alloc((void**) &dble_buf, nbytes,"AG1");
      nbytes = total_recv_leng * nullspace_dim * sizeof(double);
      ML_memory_alloc((void**) &dble_buf2, nbytes,"AG2");
      length = total_send_leng * nullspace_dim;
      for ( i = 0; i < total_send_leng; i++ )
      {
         index = send_list[i];
         for ( j = 0; j < nullspace_dim; j++ )
            dble_buf[i*nullspace_dim+j] = nullspace_vect[j*Nrows+index];
      }
      msgtype = 12093;
      length = sizeof(double) * nullspace_dim;
      ML_Aggregate_ExchangeData2((char*)dble_buf2,(char*) dble_buf,
            N_neighbors, neighbors, recv_leng, send_leng, recv_list, 
            Nrows, msgtype,length,comm);
      ML_memory_free((void**) &dble_buf);
   }

   /* ------------------------------------------------------------- */
   /* perform block QR decomposition                                */
   /* ------------------------------------------------------------- */

   for (i = 0; i < aggr_count; i++)
   {
      /* ---------------------------------------------------------- */
      /* set up the matrix we want to decompose into Q and R:       */
      /* ---------------------------------------------------------- */

      length = aggr_cnt_array[i];
      if (nullspace_vect == NULL)
      {
         for (j = 0; j < length; j++)
         {
            index = rows_in_aggs[i][j];
            for (k = 0; k < nullspace_dim; k++)
            {
               if (index % num_PDE_eqns == k) qr_tmp[k*length+j] = 1.0;
               else                           qr_tmp[k*length+j] = 0.0;
            }
         }
      }
      else
      {
         for (k = 0; k < nullspace_dim; k++)
         {
            for (j = 0; j < length; j++)
            {
               index = rows_in_aggs[i][j];
               if (index < Nrows)
               {
                  qr_tmp[k*length+j] = nullspace_vect[k*Nrows+index];
               }
               else
               {
                  qr_tmp[k*length+j] =
                        dble_buf2[(index-Nrows)*nullspace_dim+k];
               }
            }
         }
      }

      /* ---------------------------------------------------------- */
      /* now calculate QR using an LAPACK routine                   */
      /* ---------------------------------------------------------- */

      MLFORTRAN(dgeqrf)(&(aggr_cnt_array[i]), &nullspace_dim, qr_tmp,
                        &(aggr_cnt_array[i]), tmp_vect, work, &lwork, &info);
      if (info != 0)
         pr_error("Error in CoarsenCoupled : dgeqrf returned a non-zero\n");

      if (work[0] > lwork)
      {
         lwork=(int) work[0];
         ML_memory_free((void**) &work);
         ML_memory_alloc((void**) &work, sizeof(double)*lwork, "AGx");
      }
      else lwork=work[0];

      /* ---------------------------------------------------------- */
      /* the upper triangle of qr_tmp is now R, so copy that into   */
      /* the new nullspace                                          */
      /* ---------------------------------------------------------- */

      for (j = 0; j < nullspace_dim; j++)
         for (k = j; k < nullspace_dim; k++)
            new_null[i*nullspace_dim+j+k*Ncoarse*nullspace_dim] =
               qr_tmp[j+aggr_cnt_array[i]*k];

      /* ---------------------------------------------------------- */
      /* to get this block of P, need to run qr_tmp through another */
      /* LAPACK function:                                           */
      /* ---------------------------------------------------------- */

      if ( aggr_cnt_array[i] < nullspace_dim )
         printf("ERROR : performing QR on a MxN matrix where M<N.\n");
      MLFORTRAN(dorgqr)(&(aggr_cnt_array[i]), &nullspace_dim, &nullspace_dim,
              qr_tmp, &(aggr_cnt_array[i]), tmp_vect, work, &lwork, &info);
      if (info != 0)
         pr_error("Error in CoarsenCoupled: dorgqr returned a non-zero\n");

      if (work[0] > lwork)
      {
         lwork=(int) work[0];
         ML_memory_free((void**) &work);
         ML_memory_alloc((void**) &work, sizeof(double)*lwork, "AGy");
      }
      else lwork=work[0];

      /* ---------------------------------------------------------- */
      /* now copy Q over into the appropriate part of P:            */
      /* The rows of P get calculated out of order, so I assume the */
      /* Q is totally dense and use what I know of how big each Q   */
      /* will be to determine where in ia, ja, etc each nonzero in  */
      /* Q belongs.  If I did not assume this, I would have to keep */
      /* all of P in memory in order to determine where each entry  */
      /* should go                                                  */
      /* ---------------------------------------------------------- */

      for (j = 0; j < aggr_cnt_array[i]; j++)
      {
         index = rows_in_aggs[i][j];
         if ( index < Nrows )
         {
            index3 = new_ia[index];
            for (k = 0; k < nullspace_dim; k++)
            {
               new_ja [index3+k] = i * nullspace_dim + k;
               new_val[index3+k] = qr_tmp[ k*aggr_cnt_array[i]+j];
            }
         }
         else
         {
            index3 = (index - Nrows) * nullspace_dim;
            for (k = 0; k < nullspace_dim; k++)
               comm_val[index3+k] = qr_tmp[ k*aggr_cnt_array[i]+j];
         }
      }
   }

   ML_Aggregate_Set_NullSpace(ml_ag, num_PDE_eqns, nullspace_dim,
                              new_null, Ncoarse*nullspace_dim);
   ML_memory_free( (void **) &new_null);
   if (nullspace_vect != NULL) ML_memory_free( (void **) &dble_buf2);

   /* ------------------------------------------------------------- */
   /* send the P rows back to its parent processor                  */
   /* ------------------------------------------------------------- */

   nbytes = total_send_leng * nullspace_dim * sizeof(double);
   ML_memory_alloc((void**) &dble_buf, nbytes,"AGz");
   msgtype = 24945;
   length = sizeof(double) * nullspace_dim;
   ML_Aggregate_ExchangeData2((char*)dble_buf,(char*) comm_val,
         N_neighbors, neighbors, send_leng, recv_leng, NULL, 
         Nrows, msgtype,length,comm);
   for ( i = 0; i < total_send_leng; i++ )
   {
      index = send_list[i];
      if ( aggr_index[index] >= aggr_count )
      {
         dcompare1 = 0.0;
         for ( j = 0; j < nullspace_dim; j++ )
         {
            index4 = i * nullspace_dim + j;
            dcompare1 += dble_buf[index4];
         }
         if ( dcompare1 != 0.0 )
         {
            index4 = i * nullspace_dim;
            k      = index * nullspace_dim;
            for ( j = 0; j < nullspace_dim; j++ )
            {
               new_val[k+j] = dble_buf[index4+j];
               new_ja[k+j]  = aggr_index[index]*nullspace_dim+j;
            }
         }
      }
   }
   ML_memory_free( (void **) &comm_val);
   ML_memory_free( (void **) &dble_buf);

   /* ------------------------------------------------------------- */
   /* check P (row sum = 1)                                         */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < Nrows; i++ )
   {
      dcompare1 = 0.0;
      for (j = new_ia[i]; j < new_ia[i+1]; j++)
      {
         dcompare1 += new_val[j];
      }
      if ( dcompare1 == 0.0 )
         printf("%d : CoarsenCoupled WARNING : rowsum(P(%d)) = 0 (%d)\n",
                 mypid, i, aggr_index[i]);
   }

   /* ------------------------------------------------------------- */
   /* set up the csr_data data structure                            */
   /* ------------------------------------------------------------- */

   ML_memory_alloc((void**) &csr_data, sizeof(struct ML_CSR_MSRdata),"CSR");
   csr_data->rowptr  = new_ia;
   csr_data->columns = new_ja;
   csr_data->values  = new_val;
   (*Pmatrix) = ML_Operator_Create();
   ML_Operator_Set_ApplyFuncData( *Pmatrix, nullspace_dim*Ncoarse, Nrows,
                                  ML_EMPTY, csr_data, Nrows, NULL, 0);
   (*Pmatrix)->data_destroy = ML_CSR_MSR_ML_memorydata_Destroy;
   ML_memory_alloc((void**) &aggr_comm, sizeof(ML_Aggregate_Comm),"ACO");
   aggr_comm->comm = comm;
   aggr_comm->N_send_neighbors = new_N_send;
   aggr_comm->N_recv_neighbors = new_N_recv;
   aggr_comm->send_neighbors = new_send_neighbors;
   aggr_comm->recv_neighbors = new_recv_neighbors;
   aggr_comm->send_leng = new_send_leng;
   aggr_comm->recv_leng = new_recv_leng;
   aggr_comm->send_list = new_send_list;
   aggr_comm->local_nrows = Ncoarse * nullspace_dim;

   m = exp_Ncoarse - Ncoarse;
   ML_CommInfoOP_Generate( &((*Pmatrix)->getrow->pre_comm),
                           ML_Aggregate_ExchangeBdry, aggr_comm,
                           comm, Ncoarse*nullspace_dim, m*nullspace_dim);
   ML_Operator_Set_Getrow((*Pmatrix), ML_EXTERNAL, Nrows, CSR_getrows);
   ML_Operator_Set_ApplyFunc((*Pmatrix), ML_INTERNAL, CSR_matvec);
   (*Pmatrix)->max_nz_per_row = 1;

   /* ------------------------------------------------------------- */
   /* clean up                                                      */
   /* ------------------------------------------------------------- */

   ML_memory_free((void**) &comm_val);
   ML_memory_free((void**) &mat_indx);
   ML_memory_free((void**) &neighbors);
   ML_memory_free((void**) &recv_leng);
   ML_memory_free((void**) &send_leng);
   ML_memory_free((void**) &send_list);
   ML_memory_free((void**) &aggr_index);
   free(aggr_cnt_array);
   for (i = 0; i < aggr_count; i++) free(rows_in_aggs[i]);
   ML_memory_free((void**)&rows_in_aggs);
   ML_memory_free((void**)&qr_tmp);
   ML_memory_free((void**)&tmp_vect);
   ML_memory_free((void**)&work);
   if ( new_N_send > 0 )
   {
      ML_memory_free((void**) &new_send_leng);
      ML_memory_free((void**) &new_send_list);
      ML_memory_free((void**) &new_send_neighbors);
   }
   if ( N_neighbors > 0 )
   {
      ML_memory_free((void**) &new_recv_leng);
      ML_memory_free((void**) &new_recv_neighbors);
   }
   ML_memory_free((void**) &aggr_comm);
   free( aggr_index2 );
   return Ncoarse*nullspace_dim;
}

/* ******************************************************************** */
/* Compress a matrix into a block matrix                                */
/* -------------------------------------------------------------------- */

int ML_Aggregate_Compress_Matrix(ML_Operator *Amatrix, int *mat_indx, 
                int N_info, int *vinfo, int **new_mat_indx, 
                int *N_neighbors, int **neighbors, int **recv_leng,
                int **send_leng, int **send_list, int **recv_list)
{
   int   i, j, k, Nrows, nz_cnt, nbytes, *amal_mat_indx, LN_neighbors;
   int   *Lneighbors, *Lsend_leng, *Lrecv_leng, *Lsend_list, *Lrecv_list;
   int   *Aneighbors, *Asend_leng, *Arecv_leng, *Asend_list, *Arecv_list;
   int   AN_neighbors, total_send_leng, count, label, lcount, nvblk_local;
   int   nvblocks, *vblock_info, *vblock_info2, row, amal_count, index;
   int   total_recv_leng;
   char  *col_entered;
   int   (*getrowfunc)(void *,int,int*,int,int*,double*,int*);
   ML_GetrowFunc *getrow_obj;

   /* ------------------------------------------------------------- */
   /* retrieve matrix parameters                                    */
   /* ------------------------------------------------------------- */
 
   Nrows = mat_indx[0] - 1;
   nz_cnt = mat_indx[Nrows];
   getrow_obj = Amatrix->getrow;
   if (getrow_obj->ML_id == ML_EXTERNAL) getrowfunc = getrow_obj->external;
   else                                  getrowfunc = getrow_obj->internal;
   if ( getrowfunc == NULL )
   {
      printf("ML_Aggregate_Compress_Matrix ERROR : null getrowfunc.\n");
      exit(-1);
   }

   /* ------------------------------------------------------------- */
   /* retrieve communication information                            */
   /* ------------------------------------------------------------- */

   AN_neighbors = getrow_obj->pre_comm->N_neighbors;
   nbytes = AN_neighbors * sizeof( int );
   if ( nbytes > 0 )
   {
      Aneighbors = (int *) malloc( nbytes );
      Arecv_leng = (int *) malloc( nbytes );
      Asend_leng = (int *) malloc( nbytes );
   }
   else
   {
      Aneighbors = Arecv_leng = Asend_leng = NULL;
   }
   for ( i = 0; i < AN_neighbors; i++ )
   {
      Aneighbors[i] = getrow_obj->pre_comm->neighbors[i].ML_id;
      Arecv_leng[i] = getrow_obj->pre_comm->neighbors[i].N_rcv;
      Asend_leng[i] = getrow_obj->pre_comm->neighbors[i].N_send;
   }
   total_send_leng = 0;
   for ( i = 0; i < AN_neighbors; i++ ) total_send_leng += Asend_leng[i];
   nbytes = total_send_leng * sizeof( int );
   if ( nbytes > 0 ) Asend_list = (int *) malloc( nbytes );
   else              Asend_list = NULL;
   count = 0;
   for ( i = 0; i < AN_neighbors; i++ )
   {
      for (j = 0; j < Asend_leng[i]; j++)
         Asend_list[count++] =
            getrow_obj->pre_comm->neighbors[i].send_list[j];
   }
   total_recv_leng = 0;
   for ( i = 0; i < AN_neighbors; i++ ) total_recv_leng += Arecv_leng[i];
   nbytes = total_recv_leng * sizeof( int );
   if ( nbytes > 0 ) Arecv_list = (int *) malloc( nbytes );
   else              Arecv_list = NULL;
   count = 0;
   for ( i = 0; i < AN_neighbors; i++ )
   {
      for (j = 0; j < Arecv_leng[i]; j++)
         Arecv_list[count++] =
            getrow_obj->pre_comm->neighbors[i].rcv_list[j];
   }

   /* ------------------------------------------------------------- */
   /* reformat communication information                            */
   /* ------------------------------------------------------------- */

   LN_neighbors = AN_neighbors;
   nbytes = LN_neighbors * sizeof( int );
   if ( nbytes > 0 )
   {
      Lneighbors = (int *) malloc( nbytes );
      Lsend_leng = (int *) malloc( nbytes );
      Lrecv_leng = (int *) malloc( nbytes );
   }
   else
   {
      Lneighbors = Lrecv_leng = Lsend_leng = NULL;
   }
   for ( i = 0; i < LN_neighbors; i++ ) Lneighbors[i] = Aneighbors[i];

   /* -------   send stuff ---------------------------------------- */

   count = 0;
   for ( i = 0; i < LN_neighbors; i++ )
   {
      lcount = 0;
      if ( Asend_leng[i] > 0 ) 
      {
         label = vinfo[Asend_list[count++]];
         lcount++;
      }
      for ( j = 1; j < Asend_leng[i]; j++ )
      {
         index = Asend_list[count++]; 
         if ( vinfo[index] != label )
         {
            lcount++; label = vinfo[index];
         }
      }
      Lsend_leng[i] = lcount;
   }
   for ( i = 0; i < LN_neighbors; i++ ) count += Lsend_leng[i];
   nbytes = count * sizeof( int );
   if ( nbytes > 0 ) Lsend_list = (int *) malloc( nbytes );

   count = lcount = 0;
   for ( i = 0; i < LN_neighbors; i++ )
   {
      if ( Asend_leng[i] > 0 ) 
      {
         label = vinfo[Asend_list[count++]];
         Lsend_list[lcount++] = label;
      }
      for ( j = 1; j < Asend_leng[i]; j++ )
      {
         index = Asend_list[count++]; 
         if ( vinfo[index] != label ) 
         { 
            label = vinfo[index];
            Lsend_list[lcount++] = label;
         }
      }
   }
   
   /* -------   recv stuff ---------------------------------------- */

   count = Nrows;
   for ( i = 0; i < AN_neighbors; i++ )
   {
      lcount = 0;
      if ( Arecv_leng[i] > 0 ) 
      {
         label = vinfo[count++];
         lcount++;
      }
      for ( j = 1; j < Arecv_leng[i]; j++ )
      {
         if ( vinfo[count] != label )
         {
            lcount++; label = vinfo[count];
         }
         count++;
      }
      Lrecv_leng[i] = lcount;
   }
   for ( i = 0; i < LN_neighbors; i++ ) count += Lrecv_leng[i];
   nbytes = count * sizeof( int );
   if ( nbytes > 0 ) Lrecv_list = (int *) malloc( nbytes );

   count = lcount = 0;
   for ( i = 0; i < LN_neighbors; i++ )
   {
      if ( Arecv_leng[i] > 0 ) 
      {
         label = vinfo[Arecv_list[count++]];
         Lrecv_list[lcount++] = label;
      }
      for ( j = 1; j < Arecv_leng[i]; j++ )
      {
         index = Arecv_list[count++]; 
         if ( vinfo[index] != label ) 
         { 
            label = vinfo[index];
            Lrecv_list[lcount++] = label;
         }
      }
   }

   /* ------------------------------------------------------------- */
   /* allocate storage for block matrix                             */
   /* ------------------------------------------------------------- */

   nbytes = (nz_cnt + 1) * sizeof( int ); /* probably excessive */
   if (nbytes > 0) ML_memory_alloc((void**) &amal_mat_indx,nbytes,"AVB");

   /* ------------------------------------------------------------- */
   /* reformat block information                                    */
   /* ------------------------------------------------------------- */

   nvblocks = vinfo[N_info-1] + 1;
   vblock_info = (int *) malloc(nvblocks * sizeof(int));
   for ( i = 0; i < nvblocks; i++ ) vblock_info[i] = 0;
   for ( i = 0; i < N_info; i++ ) vblock_info[vinfo[i]]++; 
  
   /* ------------------------------------------------------------- */
   /* allocate temporary storage for block information              */
   /* ------------------------------------------------------------- */

   vblock_info2 = (int *) malloc(nvblocks * sizeof(int));
   vblock_info2[0] = vblock_info[0];
   for ( i = 1; i < nvblocks; i++ )
      vblock_info2[i] = vblock_info2[i-1] + vblock_info[i];
   for ( i = nvblocks-1; i >= 0; i-- )
      if ( vblock_info2[i] == Nrows ) {nvblk_local = i + 1; break;}

   /* ------------------------------------------------------------- */
   /* start compressing                                             */
   /* ------------------------------------------------------------- */

   amal_count = nvblk_local + 1;
   amal_mat_indx[0] = amal_count;
   row = 0;
   col_entered = (char *) malloc(sizeof(char)*(1+ nvblocks) );
   if (col_entered == NULL) {
      printf("Not enough space in ML_aggregate\n");
      exit(1);
   }
   for ( i = 0; i < nvblocks; i++) col_entered[i] = 'F';

   for ( i = 0; i < nvblk_local; i++) {
      col_entered[i] = 'T';
      for ( j = 0; j < vblock_info[i]; j++) 
      {
         for ( k = mat_indx[row]; k < mat_indx[row+1]; k++) 
         {
            if ( mat_indx[k] < vblock_info2[0] ) index = 0;
            else
            {
               index=ML_sorted_search(mat_indx[k],nvblocks,vblock_info2);
               if ( index < 0 ) index = - index;
               else             index++;
            }
            if ( index < 0 || index >= nvblocks )
               printf("ERROR : in almalgamation %d => %d(%d).\n",mat_indx[k],
                       index,nvblocks);
            if (col_entered[index] == 'F') {
               amal_mat_indx[ amal_count++] = index;
               col_entered[index] = 'T';
            }
         }
         row++;
      }
      amal_mat_indx[i+1] = amal_count;
      col_entered[i] = 'F';
      for ( j = amal_mat_indx[i]; j < amal_mat_indx[i+1]; j++)
         col_entered[ amal_mat_indx[j]] = 'F';
   }

   /* ------------------------------------------------------------- */
   /* shuffle pointers                                              */
   /* ------------------------------------------------------------- */

   (*new_mat_indx) = amal_mat_indx;
   (*N_neighbors) = LN_neighbors;
   (*neighbors) = Lneighbors;
   (*send_list) = Lsend_list;
   (*recv_list) = Lrecv_list;
   (*send_leng) = Lsend_leng;
   (*recv_leng) = Lrecv_leng;

   /* ------------------------------------------------------------- */
   /* clean up                                                      */
   /* ------------------------------------------------------------- */

   free(col_entered);
   free(vblock_info);
   free(vblock_info2);
   free(Aneighbors);
   free(Asend_leng);
   free(Arecv_leng);
   free(Asend_list);
   free(Arecv_list);

   return 0;
}

/* ******************************************************************** */
/* Coarsening with coupling according to Tuminaro                       */
/* -------------------------------------------------------------------- */
/* This algorithm goes as follow :                                      */
/*                                                                      */
/* 1) At the beginning of the aggregation phase, each processor picks a */
/*    point on the interprocessor boundary. Each processor then computes*/
/*    the graph distance between every other interprocessor boundary    */
/*    point and this first point. I was thinking that when computing    */
/*    these distances we only consider the graph corresponding to the   */
/*    interprocessor points.  We would need to handle the case where    */
/*    the interprocessor boundary is not completely connected. I've     */
/*    attached some matlab code that will hopefully make this clearer.  */
/* 2) When we create aggregates on the interprocessor boundary, we take */
/*    the point with the smallest distance among all valid points and   */
/*    we use this point to build the next aggregate.                    */
/* 3) When finished with the interprocessor boundary, we do the same    */
/*    thing in the interior. That is, we pick a point in the interior   */
/*    and then compute a graph distance between it and every other      */
/*    interior point.  We might want to choose this first point to be   */
/*    close to the already computed aggregates on the interprocessor    */
/*    boundary ... if this is not hard.                                 */
/* 4) When creating interior aggregates, we take the point with the     */
/*    smallest distance among valid points.                             */
/* -------------------------------------------------------------------- */

int ML_Aggregate_CoarsenCoupledCore(ML_Aggregate *ml_ag, ML_Comm *comm,
       ML_Operator *Amatrix, int *mat_indx, int *aggr_count_out, 
       int **aggr_index_out, int N_neighbors, int *neighbors, int *recv_leng,
       int *send_leng, int *send_list, int *recv_list, int **cnt_array)
{
   int     i, j, k, m, inode, jnode, nbytes, length, Nrows;
   int     select_flag, aggr_count, index, mypid, inode2, *order_array;
   int     *aggr_index, *itmp_array = NULL, count, *order_array2;
   int     *aggr_stat, *com_buf, *com_buf2, aggr_cnt_leng, *aggr_cnt_array;
   int     seed_node, *node_type, *node_dist, node_left, *dist_array;
   int     exp_Nrows, *trackbc, max_dist, *sendlist_proc, total_send_leng;
   int     mdiff, msgtype, loop_flag, old_aggr_count, procnum, index2, count3;
   int     max_length=0, mincount, maxcount, *int_array, *int_array2;
   int     attach_scheme, min_agg_size, total_recv_leng;
   double  *dble_array;
   ML_Node       *node_head, *node_tail, *new_node;
   ML_SuperNode  *supernode;
   int           (*getrowfunc)(void *,int,int*,int,int*,double*,int*);
   ML_GetrowFunc *getrow_obj;

   /* ============================================================= */
   /* get the machine information and matrix references             */
   /* ============================================================= */

   mypid = comm->ML_mypid;
   Nrows = mat_indx[0] - 1;
   exp_Nrows = Nrows;
   for ( i = 0; i < N_neighbors; i++ ) exp_Nrows += recv_leng[i];
   attach_scheme = ml_ag->attach_scheme;
   getrow_obj = Amatrix->getrow;
   if (getrow_obj->ML_id == ML_EXTERNAL) getrowfunc=getrow_obj->external;
   else                                  getrowfunc=getrow_obj->internal;

   /* ============================================================= */
   /* construct an array indicating boundary or interior nodes      */
   /* ============================================================= */

   node_type = (int *) malloc( Nrows * sizeof(int) );
   for ( i = 0; i < Nrows; i++ ) node_type[i] = 0; /* all interior */
   for ( i = 0; i < Nrows; i++ ) 
   {
      for ( j = mat_indx[i]; j < mat_indx[i+1]; j++ ) 
         if ( mat_indx[j] >= Nrows ) {node_type[i] = 1; break;}
   }

   /* ============================================================= */
   /* construct an array indicating isolated nodes                  */
   /* ============================================================= */

   trackbc = (int *) malloc( Nrows * sizeof(int) );
   for ( i = 0; i < Nrows; i++ ) 
   {
      length = mat_indx[i+1] - mat_indx[i];
      if ( length == 0 ) trackbc[i] = 1; else trackbc[i] = 0;
      if ( length+1 > max_length ) max_length = length + 1;
   }

   /* ============================================================= */
   /* Pick a seed node in each processor and compute node distances */
   /* from seed point to every other node. The outer loop is here   */
   /* to deal with unconnected regions.                             */
   /* ============================================================= */

   node_dist = (int *) malloc( Nrows * sizeof(int) );
   for ( i = 0; i < Nrows; i++ ) node_dist[i] = -1;
   node_left = Nrows - 1;

   while ( node_left > 0 )
   {
      /* ---------------------------------------------------------- */
      /* pick a seed node (if boundary and has not been visited)    */
      /* ---------------------------------------------------------- */

      seed_node = -1;
      for ( inode = 0; inode < Nrows; inode++ ) 
      { 
         if ( node_type[inode] == 1 && node_dist[inode] == -1 ) 
         {
            seed_node = inode; 
            break;
         } 
      } 
      if ( seed_node == -1 )
      {
         for ( inode = 0; inode < Nrows; inode++ ) 
            if ( node_dist[inode] == -1 ) { seed_node = inode; break; } 
      } 

      /* ---------------------------------------------------------- */
      /* initialize search queue                                    */
      /* ---------------------------------------------------------- */

      node_head = NULL;
      new_node = (ML_Node *) malloc(sizeof(ML_Node));      
      new_node->node_id = seed_node;
      node_head = new_node;
      node_tail = new_node;
      new_node->next = NULL;
      node_dist[seed_node] = 0; 
   
      /* ---------------------------------------------------------- */
      /* process the subgraph                                       */
      /* ---------------------------------------------------------- */

      while ( node_head != NULL )
      {
         new_node = node_head;
         inode = new_node->node_id;
         node_head = new_node->next;
         free(new_node);
         for ( j = mat_indx[inode]; j < mat_indx[inode+1]; j++ ) 
         {
            jnode = mat_indx[j];
            if ( jnode < Nrows && node_dist[jnode] == -1 ) 
            {
               node_dist[jnode] = node_dist[inode] + 1;
               new_node = (ML_Node *) malloc(sizeof(ML_Node));
               new_node->node_id = jnode;
               new_node->next = NULL;
               if ( node_head == NULL ) {node_head = node_tail = new_node;}
               else { node_tail->next = new_node; node_tail = new_node; }
            }      
         }
      }

      node_left = 0;
      for ( j = 0; j < Nrows; j++ )
         if ( node_dist[j] == -1 ) node_left++;
   }

   /* ============================================================= */
   /* based on the node_dist information, build an reorder array    */
   /* ============================================================= */

   max_dist = 0;
   for (i = 0; i < Nrows; i++) 
      if ( node_dist[i] > max_dist ) max_dist = node_dist[i];
   max_dist++;
   dist_array = (int *) malloc( max_dist * sizeof(int) );
   for (i = 0; i < max_dist; i++) dist_array[i] = 0;
   for (i = 0; i < Nrows; i++) dist_array[node_dist[i]]++;
   k = dist_array[0];
   dist_array[0] = 0;
   for (i = 1; i < max_dist; i++) 
   {
      j = dist_array[i]; 
      dist_array[i] = k;
      k += j;
   }
   order_array = (int *) malloc( Nrows * sizeof(int) );
   for (i = 0; i < Nrows; i++) 
      order_array[i] = dist_array[node_dist[i]]++;
   free( dist_array );
   order_array2 = (int *) malloc( Nrows * sizeof(int) );
   for (i = 0; i < Nrows; i++) order_array2[i] = i; 
   ML_az_sort(order_array, Nrows, order_array2, NULL);
   free( order_array );
   order_array = order_array2;

   /* ============================================================= */
   /* prepare for aggregation                                       */
   /* ============================================================= */

   /* ------------------------------------------------------------- */
   /* sendlist_proc is used to find out, in the aggregation process,*/
   /* which processor holds neighbors of my local nodes             */
   /* ------------------------------------------------------------- */

   sendlist_proc = (int *) malloc( (N_neighbors + 1) * sizeof(int) );
   sendlist_proc[0] = 0;
   for ( i = 1; i <= N_neighbors; i++ )
      sendlist_proc[i] = sendlist_proc[i-1] + recv_leng[i-1];

   /* ------------------------------------------------------------- */
   /* set up bookkeeping arrays for aggregation                     */
   /* ------------------------------------------------------------- */

   aggr_count = 0;
   aggr_cnt_leng = Nrows / 5 + 2;
   if ( aggr_cnt_leng > 0 )
      aggr_cnt_array = (int * ) malloc(aggr_cnt_leng * sizeof(int));
   else
      aggr_cnt_array = NULL;

   for ( i = 0; i < aggr_cnt_leng; i++ ) aggr_cnt_array[i] = 0;

   /* ------------------------------------------------------------- */
   /* Construct an initial status array to store whether the nodes  */
   /* have been aggregated. aggr_index stores the aggregate number  */
   /* where this node has been aggregated into.                     */
   /* ------------------------------------------------------------- */

   if ( exp_Nrows > 0 )
   {
      aggr_index = (int *) malloc( exp_Nrows * sizeof(int) );
      aggr_stat  = (int *) malloc( exp_Nrows * sizeof(int) );
   } else aggr_index = aggr_stat = NULL;

   for ( i = 0; i < Nrows; i++ )
   {
      if (trackbc[i] == 1) aggr_stat[i] = ML_AGGR_BDRY;
      else                 aggr_stat[i] = ML_AGGR_READY;
   }
   free( trackbc );
   for ( i = 0; i < exp_Nrows; i++ ) aggr_index[i] = -1;
   for ( i = Nrows; i < exp_Nrows; i++ ) aggr_stat[i] = 0;

   /* ------------------------------------------------------------- */
   /* allocate communication buffers for exchanging status info     */
   /* between processors during the aggregation step                */
   /* ------------------------------------------------------------- */

   total_send_leng = 0;
   for ( i = 0; i < N_neighbors; i++ ) total_send_leng += send_leng[i];
   nbytes = total_send_leng * sizeof(int);
   if ( nbytes > 0 ) com_buf = (int *) malloc( nbytes );
   else              com_buf = NULL;
   total_recv_leng = 0;
   for ( i = 0; i < N_neighbors; i++ ) total_recv_leng += recv_leng[i];
   nbytes = total_recv_leng * sizeof(int);
   if ( nbytes > 0 ) com_buf2 = (int *) malloc( nbytes );
   else              com_buf2 = NULL;

   /* ------------------------------------------------------------- */
   /* label all nodes that have to wait for its neighbors           */
   /* (If any of my neighbors reside in processors with processor   */
   /*  ID lower than my processor ID, then my node has to wait)     */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      if (node_type[inode] == 1) /* label for border nodes only */
      {
         for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; jnode++)
         {
            index = mat_indx[jnode];
            mdiff = index - Nrows;

            /* ---------------------------------------------------- */
            /* search for the processor the node is coming from     */
            /* ---------------------------------------------------- */

            for ( k = 0; k <= N_neighbors; k++ )
               if ( mdiff < sendlist_proc[k] ) break;

            /* ---------------------------------------------------- */
            /* if the processor number < mypid, tag it with the     */
            /* neighbor processor with the smallest rank            */
            /* ---------------------------------------------------- */

            if ( k != 0 && neighbors[k-1] < mypid )
            {
               if ( aggr_stat[inode] < 0 )
                  aggr_stat[inode] = neighbors[k-1];
               else if ( neighbors[k-1] < aggr_stat[inode] )
                  aggr_stat[inode] = neighbors[k-1];
            }
         }
      }
   }

   /* ------------------------------------------------------------- */
   /* send my status information to remote processors               */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < total_send_leng; i++ )
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 13445;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
      N_neighbors, neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
      ML_INT, comm);

   /* ============================================================= */
   /* Phase 1 :                                                     */
   /*    This consists of two parts - aggregate border nodes first  */
   /*    followed by aggregating interior nodes.  This goes on      */
   /*    until all nodes are either selected or not selected.       */
   /* ============================================================= */

   loop_flag = 1;
   supernode = (ML_SuperNode *) malloc(sizeof(ML_SuperNode));
   supernode->list = (int*) malloc(max_length*sizeof(int));
   supernode->maxlength = max_length;

   while ( loop_flag != 0 )
   {
      /* ========================================================== */
      /* aggregate processor boundary nodes first                   */
      /* ---------------------------------------------------------- */

      old_aggr_count = aggr_count;

      for ( inode2 = 0; inode2 < Nrows; inode2++ )
      {
         inode = order_array[inode2];

         /* ------------------------------------------------------- */
         /* if it is a READY and boundary node, do the following    */
         /* ------------------------------------------------------- */

         if (node_type[inode] == 1 && aggr_stat[inode] == ML_AGGR_READY)
         {        
            length = mat_indx[inode+1] - mat_indx[inode] + 1;

            /* ---------------------------------------------------- */
            /* first put the nodes in the supernode list            */
            /* ---------------------------------------------------- */

            supernode->length = 1;
            supernode->list[0] = inode;
            select_flag = 1;

            /* ---------------------------------------------------- */
            /* examine all of its neighbors                         */
            /* if my node is eligible to aggregate, select_flag     */
            /* will remain at 1 at the end.                         */
            /* ---------------------------------------------------- */

            for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; jnode++)
            {
               index = mat_indx[jnode];

               /* ------------------------------------------------- */
               /* if any neighobr of mine has been selected, my node*/
               /* is not to be used as seed node for aggregation.   */
               /* If my off-processor neighbors are all in processor*/
               /* with lower rank, set my status to be NOT_SEL,     */
               /* otherwise, set my status to be the processor      */
               /* closest to my processor rank.                     */
               /* ------------------------------------------------- */
               
               if ( aggr_stat[index] == ML_AGGR_SELECTED )
               {
                  select_flag = 0;
                  procnum = mypid;
                  for (j = mat_indx[inode]; j< mat_indx[inode+1];j++)
                  {
                     index2 = mat_indx[j];
                     if ( index2 >= Nrows)
                     {
                        m = mat_indx[j] - Nrows;
                        count = 0;
                        for (k = 0; k < N_neighbors; k++ )
                        {
                           if ( m < (count+recv_leng[k]) ) break;
                           count += recv_leng[k];
                        }
                        if (neighbors[k] > procnum)
                           procnum = neighbors[k];
                     }
                  }
                  if (procnum==mypid) aggr_stat[inode] = ML_AGGR_NOTSEL;
                  else                aggr_stat[inode] = procnum;
               }

               /* ------------------------------------------------- */
               /* if my neighbor is a NONSEL or READY, and it lives */
               /* in my processor, aggregate it                     */
               /* ------------------------------------------------- */

               else if ((aggr_stat[index] == ML_AGGR_NOTSEL ||
                    aggr_stat[index] == ML_AGGR_READY) && index < Nrows)
               {
                  supernode->list[supernode->length++] = index;
               }

               /* ------------------------------------------------- */
               /* if my neighbor is a NONSEL or WAIT, and it lives  */
               /* on another processor, aggregate it.               */
               /* ------------------------------------------------- */

               else if (aggr_stat[index] >= mypid && index >= Nrows)
               {
                  supernode->list[supernode->length++] = index;
               }
               else select_flag = 0;

               if ( select_flag != 1 ) break;
            }

            /* ---------------------------------------------------- */
            /* if select_flag == 1, aggregation is successful       */
            /* ---------------------------------------------------- */

            if ( select_flag == 1 )
            {
               /* ------------------------------------------------- */
               /* label the aggregate members SELECTED, and assign  */
               /* an aggregate number for the node (aggr_index)     */
               /* ------------------------------------------------- */

#ifdef AGG_OUTPUT2
   printf("(1a) %4d : AGGREGATE %4d has ", mypid, aggr_count);
#endif
               for ( j = 0; j < supernode->length; j++ )
               {
                  jnode = supernode->list[j];
#ifdef AGG_OUTPUT2
   printf("%4d ", jnode);
#endif
                  if ( jnode < exp_Nrows )
                  {
                     aggr_stat[jnode] = ML_AGGR_SELECTED;
                     aggr_index[jnode] = aggr_count;
                  }
                  if ( jnode < Nrows )
                  {
                     for (k=mat_indx[jnode]; k<mat_indx[jnode+1]; k++)
                        if (aggr_stat[mat_indx[k]] == ML_AGGR_READY)
                           aggr_stat[mat_indx[k]] = ML_AGGR_NOTSEL;
                  }
               }
#ifdef AGG_OUTPUT2
   printf("\n");
#endif

               /* ------------------------------------------------- */
               /* stretch aggr_cnt_array, if needed                 */ 
               /* ------------------------------------------------- */

               aggr_cnt_array[aggr_count++] = supernode->length;
               if ( aggr_count >= aggr_cnt_leng )
               {
                  itmp_array = aggr_cnt_array;
                  aggr_cnt_leng = aggr_cnt_leng * 6 / 5 + 1;
                  nbytes = aggr_cnt_leng * sizeof( int );
                  aggr_cnt_array = (int *) malloc(nbytes);
                  for ( k = 0; k < aggr_count; k++ )
                     aggr_cnt_array[k] = itmp_array[k];
                  free( itmp_array );
               }
            }

         }
      }

      /* ---------------------------------------------------------- */
      /* communicate remote node info back to remote processors     */
      /* (tell remote processor that some of their nodes have been  */
      /*  aggregated by this processor)                             */
      /* ---------------------------------------------------------- */

      msgtype = 33945 + loop_flag;
      ML_Aggregate_ExchangeData2((char*)com_buf2,(char*)&aggr_stat[Nrows],
         N_neighbors,neighbors,send_leng,recv_leng,NULL,Nrows,msgtype,
         ML_INT,comm);

      /* ---------------------------------------------------------- */
      /* after my processor obtains information from other          */
      /* processors about my nodes being selected, update my local  */
      /* node status array aggr_stat (mark ML_AGGR_SELECTED for the */
      /* local nodes that have been aggregated by remote processors)*/
      /* ---------------------------------------------------------- */

      count = 0;
      for ( i = 0; i < N_neighbors; i++ )
      {
         for ( j = 0; j < send_leng[i]; j++ )
         {
            inode = send_list[count];
            if ( com_buf2[count] == ML_AGGR_SELECTED &&
                 aggr_stat[inode] != ML_AGGR_SELECTED )
            {
               aggr_stat[inode]  = ML_AGGR_SELECTED;
               aggr_index[inode] = - 100 - neighbors[i];
            }
            count++;
         }
      }

      /* ---------------------------------------------------------- */
      /* now my aggr_stat contains latest information about the     */
      /* status of the nodes I own.  Next, send this updated info   */
      /* to other processors                                        */
      /* ---------------------------------------------------------- */

      for ( i = 0; i < total_send_leng; i++ )
      {
         com_buf[i] = aggr_stat[send_list[i]];
      }
      msgtype = 13945 + loop_flag;
      ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*)com_buf,
         N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,
         msgtype,ML_INT,comm);

      /* ---------------------------------------------------------- */
      /* update my waiting nodes' status                            */
      /* ---------------------------------------------------------- */

      for ( inode = 0; inode < Nrows; inode++ )
      {
         if ( aggr_stat[inode] >= 0 )
         {
            procnum = 100000;
            for (jnode=mat_indx[inode];jnode<mat_indx[inode+1];jnode++)
            {
               index = mat_indx[jnode];
               mdiff = index - Nrows;

               if ( mdiff >= 0 )
               {
                  for ( k = 0; k <= N_neighbors; k++ )
                     if ( mdiff < sendlist_proc[k] ) break;

                  if ( aggr_stat[index] == ML_AGGR_READY )
                     procnum = neighbors[k-1];
                  else if (aggr_stat[index] >= 0 &&
                           aggr_stat[index] < mypid)
                  {
                     if ( neighbors[k-1] < procnum )
                        procnum = neighbors[k-1];
                  }
               }
            }
            if ( procnum == 100000 ) aggr_stat[inode] = ML_AGGR_READY;
            else                     aggr_stat[inode] = procnum;
         }
      }

      /* ---------------------------------------------------------- */
      /* now my aggr_stat contains latest information about the     */
      /* status of the nodes I own.  Next, send this updated info   */
      /* to other processors                                        */
      /* ---------------------------------------------------------- */

      for ( i = 0; i < total_send_leng; i++ )
      {
         com_buf[i] = aggr_stat[send_list[i]];
      }
      msgtype = 13965 + loop_flag;
      ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*)com_buf,
         N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,
         msgtype, ML_INT,comm);

#ifdef AGG_OUTPUT
      /* ---------------------------------------------------------- */
      /* output information about aggregation progress              */
      /* ---------------------------------------------------------- */

      m = 0;
      for (i = 0; i < Nrows; i++) 
         if (aggr_stat[i] == ML_AGGR_SELECTED) m++;
      k = ML_Comm_GsumInt( comm, m);
      m = ML_Comm_GsumInt( comm, Nrows);
      j = ML_Comm_GsumInt( comm, aggr_count );
      count = 0;
      for (i = 0; i < Nrows; i++) if (aggr_stat[i] >= 0) count++;
      i = ML_Comm_GsumInt( comm, count );
      if ( mypid == 0 )
      {
         printf("Aggregation(CC) : Phase 1a - Iteration        = %d\n",loop_flag);
         printf("Aggregation(CC) : Phase 1a - nodes aggregated = %d (%d)\n",k,m);
         printf("Aggregation(CC) : Phase 1a - nodes waiting    = %d (%d)\n",i,m);
         printf("Aggregation(CC) : Phase 1a - total aggregates = %d \n",j);
      }
#endif

      /* ---------------------------------------------------------- */
      /* check to see if further loop is needed                     */
      /* ---------------------------------------------------------- */

      count = 0;
      for (i = 0; i < Nrows; i++) if ( aggr_stat[i] >= 0 ) count++;
      count3 = ML_Comm_GsumInt( comm, count);
      if ( count3 == 0 ) loop_flag = 0;
      else
      {
         k = aggr_count - old_aggr_count;
         m = ML_Comm_GsumInt( comm, k);
         if ( m == 0 ) loop_flag = 0;
         else          loop_flag++;
      }
   }

   /* ------------------------------------------------------------- */
   /* turn the waiting nodes into READY nodes                       */
   /* ------------------------------------------------------------- */

   for (i = 0; i < Nrows; i++) 
      if (aggr_stat[i] >= 0) aggr_stat[i] = ML_AGGR_READY;

   /* ============================================================= */
   /* Phase 1b :                                                    */
   /*    for all internal nodes (external degree=0), see if the     */
   /*    node or its neighbors have been aggregated.  If so, go to  */
   /*    another node. If not, aggregate the node and its neighbors */
   /*    if there are strongly coupled.                             */
   /* ------------------------------------------------------------- */

   for ( inode2 = 0; inode2 < Nrows; inode2++ )
   {
      inode = order_array[inode2];

      /* ---------------------------------------------------------- */
      /* choose the ready nodes only (condition of Phase 1)         */
      /* ---------------------------------------------------------- */

      if (aggr_stat[inode] == ML_AGGR_READY && node_type[inode] == 0)
      {
         length = mat_indx[inode+1] - mat_indx[inode];
         supernode->length = 1;
         supernode->list[0] = inode;
         select_flag = 1;

         /* ------------------------------------------------------- */
         /* examine all of its neighbors                            */
         /* ------------------------------------------------------- */

         for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; jnode++)
         {
            index = mat_indx[jnode];

            /* ---------------------------------------------------- */
            /* if my neighbor is a READY or NOTSEL, see if this     */
            /* neighbor has already been included in the list.  If  */
            /* no, include it.                                      */
            /* ---------------------------------------------------- */

            if ( aggr_stat[index] == ML_AGGR_READY ||
                 aggr_stat[index] == ML_AGGR_NOTSEL )
            {
               supernode->list[supernode->length++] = index;
            }

            /* ---------------------------------------------------- */
            /* if my neighbor was SELECTED by previous aggregate    */ 
            /* ---------------------------------------------------- */

            if ( aggr_stat[index] == ML_AGGR_SELECTED )
            {
               select_flag = 0;
               aggr_stat[inode] = ML_AGGR_NOTSEL;
            }

            if ( select_flag != 1 ) break;
         }

         /* ------------------------------------------------------- */
         /* if select_flag == 1, aggregation is successful          */
         /* ------------------------------------------------------- */

         if ( select_flag == 1 )
         {
#ifdef AGG_OUTPUT2
   printf("(1b) %4d : AGGREGATE %4d has ", mypid, aggr_count);
#endif
            for ( j = 0; j < supernode->length; j++ )
            {
               jnode = supernode->list[j];
#ifdef AGG_OUTPUT2
   printf("%4d ", jnode);
#endif
               if ( jnode < exp_Nrows )
               {
                  aggr_stat[jnode] = ML_AGGR_SELECTED;
                  aggr_index[jnode] = aggr_count;
               }
            }
#ifdef AGG_OUTPUT2
   printf("\n");
#endif
            aggr_cnt_array[aggr_count++] = supernode->length;
            if ( aggr_count >= aggr_cnt_leng )
            {
               itmp_array = aggr_cnt_array;
               aggr_cnt_leng = aggr_cnt_leng * 6 / 5 + 1;
               nbytes = aggr_cnt_leng * sizeof( int );
               aggr_cnt_array = (int *) malloc( nbytes );
               for ( k = 0; k < aggr_count; k++ )
                  aggr_cnt_array[k] = itmp_array[k];
               free( itmp_array );
            }
         }
      }
   }
   free( supernode->list );
   free( supernode );

   /* ------------------------------------------------------------- */
   /* send my aggr_stat information to other processors             */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < total_send_leng; i++ )
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 38945 + loop_flag;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
       N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,
       msgtype, ML_INT,comm);

   /* ------------------------------------------------------------- */
   /* now my aggr_stat contains latest information about the status */
   /* of the nodes I own.  Next, send this updated info to other    */
   /* processors                                                    */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < total_send_leng; i++ )
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 23965 + loop_flag;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
      N_neighbors, neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
      ML_INT, comm);

#ifdef AGG_OUTPUT
   /* ------------------------------------------------------------- */
   /* output information about aggregation progress                 */
   /* ------------------------------------------------------------- */

   m = 0;
   for (i = 0; i < Nrows; i++) if (aggr_stat[i] == ML_AGGR_SELECTED) m++;
   k = ML_Comm_GsumInt( comm, m);
   m = ML_Comm_GsumInt( comm, Nrows);
   j = ML_Comm_GsumInt( comm, aggr_count );
   if ( mypid == 0 )
   {
      printf("Aggregation(CC) : Phase 1b - nodes aggregated = %d (%d)\n",k,m);
      printf("Aggregation(CC) : Phase 1b - total aggregates = %d \n",j);
   }
#endif

   /* ------------------------------------------------------------- */
   /* clean up                                                      */
   /* ------------------------------------------------------------- */

   if ( com_buf  != NULL ) free( com_buf );
   if ( com_buf2 != NULL ) free( com_buf2 );

   /* ------------------------------------------------------------- */
   /* at the end of Phase 1, all border nodes that have not been    */
   /* aggregated will be considered as NOTSEL.                      */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      if ( aggr_stat[inode] >= 0 ) aggr_stat[inode] = ML_AGGR_NOTSEL;
   }
   for (i = 0; i < Nrows; i++)
   {
      if (aggr_index[i] >= aggr_count)
      {
         printf("WARNING (P1) : index out of range (%d,%d,%d,%d)\n",
                 mypid,i,aggr_index[i], aggr_count);
         break;
      }
   }
#ifdef ML_MPI
   MPI_Barrier(MPI_COMM_WORLD);
#endif

   /* ============================================================= */
   /* Phase 2 :                                                     */
   /*    This phase consists of forming aggregates where possible   */
   /*    if the aggregate size is large enough.  This phase is      */
   /*    different from phase 1 in that the seed node does not have */
   /*    to be next to no selected nodes.  This phase consists of   */ 
   /*    two parts - aggregate border nodes first followed by       */
   /*    the interior nodes.  This goes on until all nodes are      */
   /*    either selected or not selected.                           */
   /* ============================================================= */

   min_agg_size = 10000;
   for ( i = 0; i < aggr_count; i++ )
      if ( aggr_cnt_array[i] < min_agg_size ) 
         min_agg_size = aggr_cnt_array[i];

   /* ------------------------------------------------------------- */
   /* allocate communication buffers for exchanging status info     */
   /* between processors during the aggregation step                */
   /* ------------------------------------------------------------- */

   if (total_send_leng>total_recv_leng) nbytes=total_send_leng*sizeof(int);
   else                                 nbytes=total_recv_leng*sizeof(int);
   if ( nbytes > 0 ) 
   {
      com_buf  = (int *) malloc( nbytes );
      com_buf2 = (int *) malloc( nbytes );
   }
   else com_buf = com_buf2 = NULL;

   /* ------------------------------------------------------------- */
   /* reset the unselected to be READY nodes before proceeding      */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      if ( aggr_stat[inode] != ML_AGGR_SELECTED &&
           aggr_stat[inode] != ML_AGGR_BDRY ) 
         aggr_stat[inode] = ML_AGGR_READY;
   }

   /* ------------------------------------------------------------- */
   /* label all READY nodes that have to wait for its neighbors     */
   /* (If any of my neighbors reside in processors with processor   */
   /*  ID lower than my processor ID, then my node has to wait)     */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      if (aggr_stat[inode] == ML_AGGR_READY && node_type[inode] == 1) 
      {
         for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; jnode++)
         {
            index = mat_indx[jnode];
            mdiff = index - Nrows;

            /* ---------------------------------------------------- */
            /* search for the processor the node is coming from     */
            /* ---------------------------------------------------- */

            for ( k = 0; k <= N_neighbors; k++ )
               if ( mdiff < sendlist_proc[k] ) break;

            /* ---------------------------------------------------- */
            /* if the processor number < mypid, tag it with the     */
            /* neighbor processor with the smallest rank            */
            /* ---------------------------------------------------- */

            if ( k != 0 && neighbors[k-1] < mypid )
            {
               if ( aggr_stat[inode] == ML_AGGR_READY )
                  aggr_stat[inode] = neighbors[k-1];
               else if ( neighbors[k-1] < aggr_stat[inode] )
                  aggr_stat[inode] = neighbors[k-1];
            }
         }
      }
   }

   /* ------------------------------------------------------------- */
   /* send my status information to remote processors               */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < total_send_leng; i++ )
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 76442;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
      N_neighbors, neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
      ML_INT, comm);

   /* ------------------------------------------------------------- */
   /* begin phase 2a                                                */
   /* ------------------------------------------------------------- */

   loop_flag = 1;
   supernode = (ML_SuperNode *) malloc(sizeof(ML_SuperNode));
   supernode->list = (int*) malloc(max_length*sizeof(int));
   supernode->maxlength = max_length;

   while ( loop_flag != 0 )
   {
      /* ========================================================== */
      /* aggregate processor boundary nodes first                   */
      /* ---------------------------------------------------------- */

      old_aggr_count = aggr_count;

      for ( inode2 = 0; inode2 < Nrows; inode2++ )
      {
         inode = order_array[inode2];

         /* ------------------------------------------------------- */
         /* if it is a READY and boundary node, do the following    */
         /* ------------------------------------------------------- */

         if (node_type[inode] == 1 && 
             aggr_stat[inode] == ML_AGGR_READY)
         {        
            /* ---------------------------------------------------- */
            /* first put the nodes in the supernode list            */
            /* ---------------------------------------------------- */

            supernode->length = 1;
            supernode->list[0] = inode;

            /* ---------------------------------------------------- */
            /* examine to see how many of its neighbors are free    */
            /* ---------------------------------------------------- */

            for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; jnode++)
            {
               index = mat_indx[jnode];
               if ((((aggr_stat[index] == ML_AGGR_READY) ||
                    (aggr_stat[index] == ML_AGGR_NOTSEL)) && index < Nrows) ||
                   (aggr_stat[index] >= mypid && index >= Nrows))
               {
                  supernode->list[supernode->length++] = index;
               }
            }

            /* ---------------------------------------------------- */
            /* if number of nodes for an aggregate are too few      */
            /* ---------------------------------------------------- */

            if ( supernode->length < min_agg_size )
            {
               /* ------------------------------------------------- */
               /* If my off-processor neighbors are all in processor*/
               /* with lower rank, set my status to be NOT_SEL,     */
               /* otherwise, set my status to be the processor      */
               /* closest to my processor rank.                     */
               /* ------------------------------------------------- */
               
               procnum = mypid;
               for (j = mat_indx[inode]; j < mat_indx[inode+1]; j++)
               {
                  index = mat_indx[j] - Nrows;
                  if ( index >= 0 )
                  {
                     count = 0;
                     for (k = 0; k < N_neighbors; k++ )
                     {
                        if ( index < (count+recv_leng[k]) ) break;
                        count += recv_leng[k];
                     }
                     if (neighbors[k] > procnum) procnum = neighbors[k];
                  }
               }
               if (procnum==mypid) aggr_stat[inode] = ML_AGGR_NOTSEL;
               else                aggr_stat[inode] = procnum;
            }

            /* ---------------------------------------------------- */
            /* if a good aggregate can be formed                    */
            /* ---------------------------------------------------- */

            else
            {
               /* ------------------------------------------------- */
               /* label the aggregate members SELECTED, and assign  */
               /* an aggregate number for the node (aggr_index)     */
               /* also disable neighbors of selected nodes          */
               /* ------------------------------------------------- */

#ifdef AGG_OUTPUT2
   printf("(2a) %4d : AGGREGATE %4d has ", mypid, aggr_count);
#endif
               for ( j = 0; j < supernode->length; j++ )
               {
                  jnode = supernode->list[j];
                  aggr_stat[jnode] = ML_AGGR_SELECTED;
                  aggr_index[jnode] = aggr_count;
                  if ( jnode < Nrows )
                  {
                     for (k=mat_indx[jnode]; k<mat_indx[jnode+1]; k++)
                        if (aggr_stat[mat_indx[k]] == ML_AGGR_READY)
                           aggr_stat[mat_indx[k]] = ML_AGGR_NOTSEL;
                  }
#ifdef AGG_OUTPUT2
   printf("%4d ", jnode);
#endif
               }
#ifdef AGG_OUTPUT2
   printf("\n");
#endif

               /* ------------------------------------------------- */
               /* stretch aggr_cnt_array, if needed                 */ 
               /* ------------------------------------------------- */

               aggr_cnt_array[aggr_count++] = supernode->length;
               if ( aggr_count >= aggr_cnt_leng )
               {
                  itmp_array = aggr_cnt_array;
                  aggr_cnt_leng = aggr_cnt_leng * 6 / 5 + 1;
                  nbytes = aggr_cnt_leng * sizeof( int );
                  aggr_cnt_array = (int *) malloc(nbytes);
                  for ( k = 0; k < aggr_count; k++ )
                     aggr_cnt_array[k] = itmp_array[k];
                  free( itmp_array );
               }
            }
         }
      }

      /* ---------------------------------------------------------- */
      /* communicate remote node info back to remote processors     */
      /* (tell remote processor that some of their nodes have been  */
      /*  aggregated by this processor)                             */
      /* ---------------------------------------------------------- */

      msgtype = 37935 + loop_flag;
      ML_Aggregate_ExchangeData2((char*)com_buf2,(char*)&aggr_stat[Nrows],
         N_neighbors,neighbors,send_leng,recv_leng,NULL,Nrows,msgtype,
         ML_INT,comm);

      /* ---------------------------------------------------------- */
      /* after my processor obtains information from other          */
      /* processors about my nodes being selected, update my local  */
      /* node status array aggr_stat (mark ML_AGGR_SELECTED for the */
      /* local nodes that have been aggregated by remote processors)*/
      /* ---------------------------------------------------------- */

      count = 0;
      for ( i = 0; i < N_neighbors; i++ )
      {
         for ( j = 0; j < send_leng[i]; j++ )
         {
            inode = send_list[count];
            if ( com_buf2[count] == ML_AGGR_SELECTED &&
                 aggr_stat[inode] != ML_AGGR_SELECTED )
            {
               aggr_stat[inode]  = ML_AGGR_SELECTED;
               aggr_index[inode] = - 100 - neighbors[i];
            }
            count++;
         }
      }

      /* ---------------------------------------------------------- */
      /* now my aggr_stat contains latest information about the     */
      /* status of the nodes I own.  Next, send this updated info   */
      /* to other processors                                        */
      /* ---------------------------------------------------------- */

      for ( i = 0; i < total_send_leng; i++ )
      {
         com_buf[i] = aggr_stat[send_list[i]];
      }
      msgtype = 53941 + loop_flag;
      ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*)com_buf,
         N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
         ML_INT,comm);

      /* ---------------------------------------------------------- */
      /* update my waiting nodes' status                            */
      /* ---------------------------------------------------------- */

      for ( inode = 0; inode < Nrows; inode++ )
      {
         if ( aggr_stat[inode] >= 0 )
         {
            procnum = 100000;
            for (jnode=mat_indx[inode];jnode<mat_indx[inode+1];jnode++)
            {
               index = mat_indx[jnode];
               mdiff = index - Nrows;
               if ( mdiff >= 0 )
               {
                  for ( k = 0; k <= N_neighbors; k++ )
                     if ( mdiff < sendlist_proc[k] ) break;

                  if ( aggr_stat[index] == ML_AGGR_READY )
                     procnum = neighbors[k-1];
                  else if (aggr_stat[index] >= 0 &&
                           aggr_stat[index] < mypid)
                  {
                     if ( neighbors[k-1] < procnum )
                        procnum = neighbors[k-1];
                  }
               }
            }
            if ( procnum == 100000 ) aggr_stat[inode] = ML_AGGR_READY;
            else                     aggr_stat[inode] = procnum;
         }
      }

      /* ---------------------------------------------------------- */
      /* now my aggr_stat contains latest information about the     */
      /* status of the nodes I own.  Next, send this updated info   */
      /* to other processors                                        */
      /* ---------------------------------------------------------- */

      for ( i = 0; i < total_send_leng; i++ )
      {
         com_buf[i] = aggr_stat[send_list[i]];
      }
      msgtype = 13965 + loop_flag;
      ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*)com_buf,
         N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
         ML_INT,comm);

#ifdef AGG_OUTPUT
      /* ---------------------------------------------------------- */
      /* output information about aggregation progress              */
      /* ---------------------------------------------------------- */

      m = 0;
      for (i = 0; i < Nrows; i++) 
         if (aggr_stat[i] == ML_AGGR_SELECTED) m++;
      k = ML_Comm_GsumInt( comm, m);
      m = ML_Comm_GsumInt( comm, Nrows);
      j = ML_Comm_GsumInt( comm, aggr_count );
      count = 0;
      for (i = 0; i < Nrows; i++) if (aggr_stat[i] >= 0) count++;
      i = ML_Comm_GsumInt( comm, count );
      if ( mypid == 0 )
      {
         printf("Aggregation(CC) : Phase 2a - Iteration        = %d\n",loop_flag);
         printf("Aggregation(CC) : Phase 2a - nodes aggregated = %d (%d)\n",k,m);
         printf("Aggregation(CC) : Phase 2a - nodes waiting    = %d (%d)\n",i,m);
         printf("Aggregation(CC) : Phase 2a - total aggregates = %d \n",j);
      }
#endif

      /* ---------------------------------------------------------- */
      /* check to see if further loop is needed                     */
      /* ---------------------------------------------------------- */

      m = 0;
      for (i = 0; i < Nrows; i++) if ( aggr_stat[i] >= 0 ) m++;
      count = ML_Comm_GsumInt( comm, m);
      if ( count == 0 ) loop_flag = 0;
      else
      {
         m = aggr_count - old_aggr_count;
         count = ML_Comm_GsumInt( comm, m);
         if ( count == 0 ) loop_flag = 0;
         else              loop_flag++;
      }
   }

   /* ------------------------------------------------------------- */
   /* turn the waiting nodes into READY nodes                       */
   /* ------------------------------------------------------------- */

   for (i = 0; i < Nrows; i++) 
      if (aggr_stat[i] >= 0) aggr_stat[i] = ML_AGGR_READY;

   /* ============================================================= */
   /* Phase 2b :                                                    */
   /*    for all internal nodes (external degree=0), see if the     */
   /*    node or its neighbors have been aggregated.  If so, go to  */
   /*    another node. If not, aggregate the node and its neighbors */
   /*    if there are strongly coupled.                             */
   /* ------------------------------------------------------------- */

   for ( inode2 = 0; inode2 < Nrows; inode2++ )
   {
      inode = order_array[inode2];

      /* ---------------------------------------------------------- */
      /* choose the ready nodes only (condition of Phase 1)         */
      /* ---------------------------------------------------------- */

      if (aggr_stat[inode] == ML_AGGR_READY && node_type[inode] == 0)
      {
         supernode->length = 1;
         supernode->list[0] = inode;

         /* ------------------------------------------------------- */
         /* examine all of its neighbors                            */
         /* ------------------------------------------------------- */

         for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; jnode++)
         {
            index = mat_indx[jnode];

            if ( aggr_stat[index] == ML_AGGR_READY ||
                 aggr_stat[index] == ML_AGGR_NOTSEL )
            {
               supernode->list[supernode->length++] = index;
            }
         }

         /* ------------------------------------------------------- */
         /* if critical mass is there, aggregation is successful    */
         /* ------------------------------------------------------- */

         if ( supernode->length >= min_agg_size )
         {
#ifdef AGG_OUTPUT2
   printf("(2b) %4d : AGGREGATE %4d has ", mypid, aggr_count);
#endif
            for ( j = 0; j < supernode->length; j++ )
            {
               jnode = supernode->list[j];
               aggr_stat[jnode] = ML_AGGR_SELECTED;
               aggr_index[jnode] = aggr_count;
#ifdef AGG_OUTPUT2
   printf("%4d ", jnode);
#endif
            }
#ifdef AGG_OUTPUT2
   printf("\n");
#endif
            aggr_cnt_array[aggr_count++] = supernode->length;
            if ( aggr_count >= aggr_cnt_leng )
            {
               itmp_array = aggr_cnt_array;
               aggr_cnt_leng = aggr_cnt_leng * 6 / 5 + 1;
               nbytes = aggr_cnt_leng * sizeof( int );
               aggr_cnt_array = (int *) malloc( nbytes );
               for ( k = 0; k < aggr_count; k++ )
                  aggr_cnt_array[k] = itmp_array[k];
               free( itmp_array );
            }
         }
      }
   }
   free( supernode->list );
   free( supernode );

   /* ------------------------------------------------------------- */
   /* send my aggr_stat information to other processors             */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < total_send_leng; i++ )
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 38945 + loop_flag;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
       N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
       ML_INT,comm);

   /* ------------------------------------------------------------- */
   /* now my aggr_stat contains latest information about the status */
   /* of the nodes I own.  Next, send this updated info to other    */
   /* processors                                                    */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < total_send_leng; i++ )
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 23965 + loop_flag;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
      N_neighbors, neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
      ML_INT, comm);

#ifdef AGG_OUTPUT
   /* ------------------------------------------------------------- */
   /* output information about aggregation progress                 */
   /* ------------------------------------------------------------- */

   m = 0;
   for (i = 0; i < Nrows; i++) if (aggr_stat[i] == ML_AGGR_SELECTED) m++;
   k = ML_Comm_GsumInt( comm, m);
   m = ML_Comm_GsumInt( comm, Nrows);
   j = ML_Comm_GsumInt( comm, aggr_count );
   if ( mypid == 0 )
   {
      printf("Aggregation(CC) : Phase 2b - nodes aggregated = %d (%d)\n",k,m);
      printf("Aggregation(CC) : Phase 2b - total aggregates = %d \n",j);
   }
#endif

   /* ------------------------------------------------------------- */
   /* clean up                                                      */
   /* ------------------------------------------------------------- */

   if ( com_buf  != NULL ) free( com_buf );
   if ( com_buf2 != NULL ) free( com_buf2 );

   /* ------------------------------------------------------------- */
   /* at the end of Phase 2, all border nodes that have not been    */
   /* aggregated will be considered as NOTSEL.                      */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      if ( aggr_stat[inode] >= 0 ) aggr_stat[inode] = ML_AGGR_NOTSEL;
   }
   for (i = 0; i < Nrows; i++)
   {
      if (aggr_index[i] >= aggr_count)
      {
         printf("WARNING (P2) : index out of range (%d,%d,%d,%d)\n",
                 mypid,i,aggr_index[i], aggr_count);
         break;
      }
   }
#ifdef ML_MPI
   MPI_Barrier(MPI_COMM_WORLD);
#endif

   /* ============================================================= */
   /* Phase 3 :                                                     */
   /*    for all nodes, see if it can be aggregated into one of the */
   /*    existing LOCAL aggregates.                                 */
   /* ============================================================= */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      /* ---------------------------------------------------------- */
      /* if the node in question is either READY or NOTSEL          */
      /* ---------------------------------------------------------- */

      if ( aggr_stat[inode] == ML_AGGR_READY || 
           aggr_stat[inode] == ML_AGGR_NOTSEL ) 
      { 
         select_flag = 0;

         /* ------------------------------------------------------- */
         /* search for a neighboring aggregate that has the fewest  */
         /* number of nodes                                         */
         /* ------------------------------------------------------- */

         if ( attach_scheme == ML_AGGR_MINRANK )
         {
            mincount = 100000;
            for (jnode=mat_indx[inode]; jnode<mat_indx[inode]; jnode++)
            {
               k = mat_indx[jnode];
               if ( k < Nrows )
               {
                  if (aggr_stat[k] == ML_AGGR_SELECTED &&
                      aggr_index[k] >= 0) /* locally aggregated */
                  {
                     select_flag = 1;
                     m = aggr_index[k];
                     if ( aggr_cnt_array[m] < mincount )
                     {
                        mincount = aggr_cnt_array[m];
                        index = k;
                     }
                  }
               }
            }
         }

         /* ------------------------------------------------------- */
         /* search for a neighboring aggregate that has the most    */
         /* connection to my node                                   */
         /* ------------------------------------------------------- */

         else if ( attach_scheme == ML_AGGR_MAXLINK )
         {
            maxcount = 0;
            length = mat_indx[inode+1] - mat_indx[inode];
            if (length>0) int_array  = (int *) malloc(length * sizeof(int));
            if (length>0) int_array2 = (int *) malloc(length * sizeof(int));
            for ( i = 0; i < length; i++ ) int_array2[i] = i;
            length = 0;

            for (jnode=mat_indx[inode]; jnode<mat_indx[inode+1]; jnode++)
            {
               k = mat_indx[jnode];
               if (aggr_index[k] >= 0) 
               {
                  int_array2[length]  = k;
                  int_array[length++] = aggr_index[k];
               }
            }
            if ( length > 0 ) 
            {
               if (length > 1) ML_az_sort(int_array,length,int_array2,NULL);
               index = aggr_index[int_array2[length-1]];
               select_flag = 1;
            }
            length = mat_indx[inode+1] - mat_indx[inode];
            if ( length > 0 ) free( int_array );
            if ( length > 0 ) free( int_array2 );
         }

         /* ------------------------------------------------------- */
         /* if search is unsuccessful, see if it is a boundary node */
         /* If not, look for strong connection                      */
         /* ------------------------------------------------------- */

         if ( select_flag == 0 )
         {
            length = mat_indx[inode+1] - mat_indx[inode];
            if ( length == 0 )
            {
               int_array  = (int *) malloc(max_length * sizeof(int));
               dble_array = (double *) malloc(max_length * sizeof(double));
               getrowfunc(Amatrix->data,1,&inode,max_length,int_array,
                          dble_array, &m);
               count = 0;
               for (j = 0; j < m; j++) 
               {
                  jnode = int_array[j];
                  if ( jnode < Nrows && aggr_index[jnode] >= 0 )
                  {
                     dble_array[count]  = abs(dble_array[j]);
                     int_array[count++] = int_array[j];
                  }
               }
               if (count > 1) ML_split_dsort(dble_array,count,int_array,1);
               if ( count > 0 )
               {
                  index = aggr_index[int_array[0]];
                  select_flag = 1;
                  printf("%4d : (VC) - node %d put into aggregate %d\n",
                         mypid, inode, index);
               }
               free( int_array );
               free( dble_array );
            }
         }

         /* ------------------------------------------------------- */
         /* if search is successful, put thid node in the aggregate */
         /* ------------------------------------------------------- */

         if ( select_flag == 1 )
         {
            aggr_cnt_array[index]++;
            aggr_index[inode] = index;
            aggr_stat[inode] = ML_AGGR_SELECTED2;
         }
      }
   }

   /* ------------------------------------------------------------- */
   /* restore the selected status (modified above to prevent chain) */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
      if ( aggr_stat[inode] == ML_AGGR_SELECTED2 )
         aggr_stat[inode] = ML_AGGR_SELECTED;

   /* ------------------------------------------------------------- */
   /* communicate the information                                   */
   /* ------------------------------------------------------------- */

   nbytes = total_send_leng * sizeof(int);
   if ( nbytes > 0 ) com_buf  = (int *) malloc( nbytes );
   for ( i = 0; i < total_send_leng; i++ ) 
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 48934 + loop_flag;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
        N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,msgtype,
        ML_INT,comm);

   free( com_buf );

#ifdef AGG_OUTPUT

   /* ------------------------------------------------------------- */
   /* output information about aggregation progress                 */
   /* ------------------------------------------------------------- */

   m = 0;
   for (i = 0; i < Nrows; i++) if (aggr_stat[i] == ML_AGGR_SELECTED) m++;
   k = ML_Comm_GsumInt( comm, m);
   m = ML_Comm_GsumInt( comm, Nrows);
   j = ML_Comm_GsumInt( comm, aggr_count );
   if ( mypid == 0 )
   {
      printf("Aggregation(CC) : Phase 3  - nodes aggregated = %d (%d)\n",k,m);
      printf("Aggregation(CC) : Phase 3  - total aggregates = %d \n",j);
   }
#endif

   /* ============================================================= */
   /* Phase 4 :                                                     */
   /*    for all remaining nodes, see if they can be aggregated     */
   /*    into one of the existing remote aggregates.                */
   /* ============================================================= */

   /* ------------------------------------------------------------- */
   /* communicate the index information for this phase              */
   /* ------------------------------------------------------------- */

printf("%d : Phase 4 check 1\n", mypid);
   nbytes = total_send_leng * sizeof(int);
   if ( nbytes > 0 ) com_buf  = (int *) malloc( nbytes );
   nbytes = total_recv_leng * sizeof(int);
   if ( nbytes > 0 ) com_buf2 = (int *) malloc( nbytes );
   for ( i = 0; i < total_send_leng; i++ ) 
   {
      com_buf[i] = aggr_index[send_list[i]];
   }
   msgtype = 49934;
   ML_Aggregate_ExchangeData2((char*)com_buf2,(char*) com_buf,
        N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,
        msgtype,ML_INT,comm);
printf("%d : Phase 4 check 2\n", mypid);

   /* ------------------------------------------------------------- */
   /* reset unselected nodes to be READY                            */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      if ( aggr_stat[inode] != ML_AGGR_SELECTED &&
           aggr_stat[inode] != ML_AGGR_BDRY ) 
         aggr_stat[inode] = ML_AGGR_READY;
   }

   /* ------------------------------------------------------------- */
   /* begin phase 4 aggregation                                     */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      /* ---------------------------------------------------------- */
      /* if the node in question is either READY or NOTSEL          */
      /* ---------------------------------------------------------- */

      if ((aggr_stat[inode] == ML_AGGR_READY || 
          aggr_stat[inode] == ML_AGGR_NOTSEL) && node_type[inode] == 1) 
      { 
         for (jnode=mat_indx[inode]; jnode<mat_indx[inode]; jnode++)
         {
            index = mat_indx[inode];
            if (index >= Nrows && aggr_stat[index]==ML_AGGR_SELECTED &&
                com_buf2[index-Nrows] >= 0)
            {
               mdiff = index - Nrows;
               for ( k = 0; k <= N_neighbors; k++ )
               if ( mdiff < sendlist_proc[k] ) break;
               aggr_stat[inode]  = mdiff - sendlist_proc[k-1];
               aggr_index[inode] = - 100 - neighbors[k-1];
               break;
            }
         }
      }
   }
printf("%d : Phase 4 check 3\n", mypid);
for ( i = 0; i < N_neighbors; i++ ) 
   printf("%d : Phase 4 check 3 : recv_leng = %d\n", mypid, recv_leng[i]);
 
   /* ------------------------------------------------------------- */
   /* communicate the index information for this phase              */
   /* ------------------------------------------------------------- */

   for ( i = 0; i < total_send_leng; i++ ) 
   {
      com_buf[i] = aggr_stat[send_list[i]];
   }
   msgtype = 49935;
   ML_Aggregate_ExchangeData2((char*)&aggr_stat[Nrows],(char*) com_buf,
        N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,
        msgtype,ML_INT,comm);

printf("%d : Phase 4 check 4\n", mypid);
   for ( i = 0; i < total_send_leng; i++ ) 
   {
      com_buf[i] = aggr_index[send_list[i]];
   }
   msgtype = 49936;
   ML_Aggregate_ExchangeData2((char*)com_buf2,(char*) com_buf,
        N_neighbors,neighbors,recv_leng,send_leng,recv_list,Nrows,
        msgtype,ML_INT,comm);

   free( com_buf );
printf("%d : Phase 4 check 5\n", mypid);

   /* ------------------------------------------------------------- */
   /* process the incoming data                                     */
   /* ------------------------------------------------------------- */

   length = 0;
   for ( i = 0; i < N_neighbors; i++ )
   {
      for ( j = 0; j < recv_leng[i]; j++ )
      {
         if ( aggr_stat[Nrows+length+j] >= 0 &&
              (-com_buf2[length+j]+100) == mypid )
         {
            index = aggr_stat[Nrows+length+j]; /* intra-proc offset */
            for ( k = 0; k < i; k++ ) index += send_leng[k];
            index = aggr_index[send_list[index]];
            aggr_cnt_array[index]++;
            aggr_index[Nrows+length+j] = index;
         }
      }
      length += recv_leng[i];
   } 
   free( com_buf2 );

   /* ------------------------------------------------------------- */
   /* set the status of the selected node to the SELECTED state     */
   /* ------------------------------------------------------------- */

   for ( inode = 0; inode < Nrows; inode++ )
   {
      if ( aggr_stat[inode] >= 0 ) aggr_stat[inode] = ML_AGGR_SELECTED;
   }

#ifdef AGG_OUTPUT

   /* ------------------------------------------------------------- */
   /* output information about aggregation progress                 */
   /* ------------------------------------------------------------- */

   m = 0;
   for (i = 0; i < Nrows; i++) if (aggr_stat[i] == ML_AGGR_SELECTED) m++;
   k = ML_Comm_GsumInt( comm, m);
   m = ML_Comm_GsumInt( comm, Nrows);
   j = ML_Comm_GsumInt( comm, aggr_count );
   if ( mypid == 0 )
   {
      printf("Aggregation(CC) : Phase 4  - nodes aggregated = %d (%d)\n",k,m);
      printf("Aggregation(CC) : Phase 4  - total aggregates = %d \n",j);
   }
#endif

   /* ============================================================= */
   /* final checking                                                */
   /* ============================================================= */

   for (i = 0; i < Nrows; i++)
   {
      if (aggr_index[i] >= aggr_count)
      {
         printf("WARNING (VC Phase 3) : index out of range (%d,%d,%d,%d)\n",
                    mypid,i,aggr_index[i], aggr_count);
         break;
      }
      if ( aggr_stat[i] != ML_AGGR_SELECTED )
      {
         printf("%d : ERROR (C) : node %d not aggregated (%d)\n", mypid, i,
                aggr_stat[i]);
         for ( j = mat_indx[i]; j < mat_indx[i+1]; j++ )
            printf("%d : neighbors = %d %d %d\n", mypid, mat_indx[j], 
                   aggr_stat[mat_indx[j]], aggr_index[mat_indx[j]]);
         exit(1);
      }
   }

   /* ============================================================= */
   /* final clean up                                                */
   /* ============================================================= */

   free( node_dist );
   free( sendlist_proc );
   free( aggr_stat );
   free( node_type );
   free( order_array );
   (*cnt_array) = aggr_cnt_array;
   (*aggr_count_out) = aggr_count;
   (*aggr_index_out) = aggr_index;
   return 0;
}

/* ******************************************************************** */
/* ******************************************************************** */
/* Exchange data between processors given communication information     */
/* -------------------------------------------------------------------- */

int ML_Aggregate_ExchangeData2(char *recvbuf, char *sendbuf, int N_neighbors,
              int *neighbors, int *recv_leng, int *send_leng, int *recv_list,
              int Nrows, int msgid, int datatype, ML_Comm *comm)
{
   int     i, nbytes, fromproc, length, typeleng, msgtype, offset;
   int     total_recv_leng, *int_array, *iarray;
   char    *char_array, *carray;
   double  *dble_array, *darray;
   USR_REQ *Request;

/*
static int flag=0;
int j, count;
if (flag == 0)
{
   flag = 1;
   count = 0;
   for (i=0; i <N_neighbors; i++)
      for (j=0; j <recv_leng[i]; j++)
         printf("recv_list[%4d,%4d] = %d\n", i, j, recv_list[count++]);
}
*/
   
   switch ( datatype ) 
   {
      case ML_CHAR    : typeleng = sizeof(char);   break;
      case ML_INT     : typeleng = sizeof(int);    break;
      case ML_DOUBLE  : typeleng = sizeof(double); break;
      default :         typeleng = datatype;       break;
   }

   nbytes = N_neighbors * sizeof(USR_REQ);
   if ( nbytes > 0 ) Request = (USR_REQ *) malloc(nbytes);
   else              Request = NULL;
   offset = 0;
   msgtype = msgid;
   for ( i = 0; i < N_neighbors; i++ ) 
   {
      fromproc = neighbors[i];
      length = recv_leng[i] * typeleng;
      if ( length > 0 )
         comm->USR_irecvbytes(&recvbuf[offset*typeleng],length,&fromproc,
                           &msgtype, comm->USR_comm, (void *) &Request[i] );
      offset += recv_leng[i];
   }
   offset = 0;
   msgtype = msgid;
   for ( i = 0; i < N_neighbors; i++ ) 
   {
      length = send_leng[i] * typeleng;
      if ( length > 0 )
         comm->USR_sendbytes((void*) &sendbuf[offset*typeleng], length,
                             neighbors[i], msgtype, comm->USR_comm );
      offset += send_leng[i];
   }
   offset = 0;
   for ( i = 0; i < N_neighbors; i++ ) 
   {
      fromproc = neighbors[i];
      length = recv_leng[i] * typeleng;
      msgtype = msgid;
      if ( length > 0 )
         comm->USR_waitbytes(&recvbuf[offset*typeleng], length, &fromproc,
                             &msgtype, comm->USR_comm, (void *) &Request[i] );
      offset += recv_leng[i];
   }
   if ( Request != NULL ) free( Request );

   /* ----------------------------------------------------------------- */
   /* if a receive list is given, then permute the incoming data        */
   /* ----------------------------------------------------------------- */

   if ( recv_list != NULL )
   {
      total_recv_leng = 0;
      for ( i = 0; i < N_neighbors; i++ ) total_recv_leng += recv_leng[i];
      switch ( datatype ) 
      {
         case ML_CHAR    : nbytes = total_recv_leng * sizeof(char);
                           char_array = (char *) malloc(nbytes);
                           carray = (char *) recvbuf;
                           for ( i = 0; i < total_recv_leng; i++ )
                              char_array[recv_list[i]-Nrows] = carray[i];
                           for ( i = 0; i < total_recv_leng; i++ )
                              carray[i] = char_array[i];
                           free(char_array);
                           break;
         case ML_INT     : nbytes = total_recv_leng * sizeof(int);
                           int_array = (int *) malloc(nbytes);
                           iarray = (int *) recvbuf;
                           for ( i = 0; i < total_recv_leng; i++ )
                              int_array[recv_list[i]-Nrows] = iarray[i];
                           for ( i = 0; i < total_recv_leng; i++ )
                              iarray[i] = int_array[i];
                           free(int_array);
                           break;
         case ML_DOUBLE  : nbytes = total_recv_leng * sizeof(double);
                           dble_array = (double *) malloc(nbytes);
                           darray = (double *) recvbuf;
                           for ( i = 0; i < total_recv_leng; i++ )
                              dble_array[recv_list[i]-Nrows] = darray[i];
                           for ( i = 0; i < total_recv_leng; i++ )
                              darray[i] = dble_array[i];
                           free(dble_array);
                           break;
      }
   }
   return 0;
}

/* ******************************************************************** */
/* compose receive information from send information                    */
/* -------------------------------------------------------------------- */

int ML_Aggregate_ComposeRecvInfo(int nprocs, int mypid, int new_N_send,
       int *new_send_leng, int *new_send_neighbors, int *N_rcv, 
       int **recv_leng, int **recv_neighbors, ML_Comm *comm)
{
   int     i, nbytes, *int_buf, *int_buf2, new_N_rcv, *new_recv_neighbors;
   int     msgtype, fromproc, *new_recv_leng;
   USR_REQ *Request;

   if ( nprocs > 1 )
   {
      /* -------------------------------------------------------------- */
      /* compute new_N_rcv                                              */
      /* -------------------------------------------------------------- */

      int_buf  = (int *) malloc(nprocs * sizeof(int));
      int_buf2 = (int *) malloc(nprocs * sizeof(int));
      for (i = 0; i < nprocs; i++) int_buf[i] = 0;
      for (i = 0; i < new_N_send; i++) int_buf[new_send_neighbors[i]] = 1;
      ML_Comm_GsumVecInt(comm, int_buf, int_buf2, nprocs);
      free( int_buf2 );
      new_N_rcv = int_buf[mypid];
      free( int_buf );

      /* -------------------------------------------------------------- */
      /* get receive processor and the receive length                   */
      /* -------------------------------------------------------------- */

      nbytes = new_N_rcv * sizeof(int);
      if ( nbytes > 0 )
      {
         ML_memory_alloc((void**)&new_recv_leng, nbytes, "AGM");
         ML_memory_alloc((void**)&new_recv_neighbors, nbytes, "AGM");
      } else new_recv_leng = new_recv_neighbors = NULL;
      nbytes = new_N_rcv * sizeof(USR_REQ);
      if ( nbytes > 0 ) Request = (USR_REQ *) malloc(nbytes);
      else              Request = NULL;
      msgtype = 97531;
      for ( i = 0; i < new_N_rcv; i++ ) 
      {
         fromproc = -1;
         comm->USR_irecvbytes(&new_recv_leng[i],sizeof(int),&fromproc,
                   &msgtype, comm->USR_comm, (void *) &Request[i] );
      }
      for ( i = 0; i < new_N_send; i++ ) 
      {
         comm->USR_sendbytes((void*) &new_send_leng[i], sizeof(int), 
                      new_send_neighbors[i], msgtype, comm->USR_comm);
      }
      for ( i = 0; i < new_N_rcv; i++)
      {
         fromproc = -1;
         comm->USR_waitbytes((void*) &new_recv_leng[i], sizeof(int), 
                  &fromproc,&msgtype,comm->USR_comm,(void *) &Request[i]);
         new_recv_neighbors[i] = fromproc;
      }
      ML_az_sort( new_recv_neighbors, new_N_rcv, new_recv_leng, NULL);
      if ( new_N_rcv > 0 ) free( Request );

      (*recv_leng) = new_recv_leng;
      (*recv_neighbors) = new_recv_neighbors;
      (*N_rcv) = new_N_rcv;
   }
   else
   {
      (*recv_leng) = NULL;
      (*recv_neighbors) = NULL;
      (*N_rcv) = 0;
   } 
   return 0;
} 

