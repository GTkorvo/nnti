% @HEADER
% ***********************************************************************
%
%            Trilinos: An Object-Oriented Solver Framework
%                 Copyright (2001) Sandia Corporation
%
% Under terms of Contract DE-AC04-94AL85000, there is a non-exclusive
% license for use of this work by or on behalf of the U.S. Government.
%
% This library is free software; you can redistribute it and/or modify
% it under the terms of the GNU Lesser General Public License as
% published by the Free Software Foundation; either version 2.1 of the
% License, or (at your option) any later version.
%
% This library is distributed in the hope that it will be useful, but
% WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
% Lesser General Public License for more details.
%
% You should have received a copy of the GNU Lesser General Public
% License along with this library; if not, write to the Free Software
% Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301
% USA
% Questions? Contact Michael A. Heroux (maherou@sandia.gov)
%
% ***********************************************************************
% @HEADER

\documentclass[11pt,relax]{SANDreport}
\usepackage{graphicx}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{rotating}
\usepackage{times}

\def\choicebox#1#2{\noindent$\hphantom{th}$\parbox[t]{1.8in}{\sf
#1}\parbox[t]{4.5in}{#2}\\[0.8em]}

\author{Marzio Sala \\
Institute of Computational Science, \\
ETH Zurich, Switzerland \\[1cm]
Michael Heroux,   Robert Hoekstra, Alan Williams\\
Computational Mathematics and Algorithms Department \\
Sandia National Laboratories \\
P.O. Box 5800 \\
Albuquerque, NM 87185-1110 \\
}

\title{Serialization and Deserialization Tools for Distributed Linear Algebra Objects}
\SANDnum{SAND2006-XXXX}
\SANDauthor{Marzio Sala, Michael Heroux, Robert Hoekstra, and Alan Williams}

\SANDprintDate{April 2006}
\SANDreleaseType{Unlimited Release}

\newcommand{\Trilinos}{Trilinos}
\newcommand{\TrilinosTM}{Trilinos \copyright}
\newcommand{\trilinos}{{\sc Trilinos}}
\newcommand{\ifpack}{{\sc Ifpack}}
\newcommand{\aztecoo}{{\sc AztecOO}}
\newcommand{\amesos}{{\sc Amesos}}
\newcommand{\epetra}{{\sc Epetra}}
\newcommand{\ml}{{\sc ML}}
\newcommand{\mb}[1]{{\mathbf {#1} }}
\newcommand{\teuchos}{{\sc Teuchos}}
\newcommand{\triutils}{{\sc Triutils}}
\newcommand{\metis}{{\sc METIS}}

\newcommand{\ie}{i.e., }
\newtheorem{remark}{Remark}

\begin{document}

\maketitle

\begin{abstract}
We describe the design and usage of the serialization and deserialization
tools contained in the EpetraExt package of
Trilinos~\cite{trilinos-home-page}. These offer (parallel) I/O for most
of the distributed linear algebra objects defined by the Epetra package. A
reader for the popular Harwell/Boeing format and a collection of readers and
writers for the MatrixMarket format are presented. The report also describe a
binary, portable and parallel class, based on the HDF5 file format. Finally,
  an XML-compatible file format is described. 
\end{abstract}

\SANDmain

\tableofcontents

\newpage

% ============================================================================
\section{Introduction}
\label{sec:introduction}
% ============================================================================

Consider the following scenarios:
\begin{enumerate}
\item A programmer is experiencing convergence
problems within his/her Newton-like nonlinear solver, because the
preconditioner does not yield convergence as expected. The application is
non-standard, custom-made, proprietary, and the source codes cannot be
distributed.
\item During a time-dependent
simulation, a particular linear system solve phase does not behave as expected.
This occurs after several
hours of computations, on a quite large problem, running on distributed memory
machines.
\end{enumerate}
Developers of both scenarios will benefit from being able to reproduce their
linear algebra objects {\sl outside} their codes, in a testing environment that
can be made simpler and more compact to use, without all the complexity
typical of large application codes. If the testing environment  can
reproduce the particular phase where problems are experienced, then it will be
possibly to analyze in detail the behavior of the algorithm, possibly with the
help of experts in the field.

The process of moving objects from one application to the next is
typically called {\sl serialization}.
In the modern computer science context, serialization refers to
converting an object's detailed state data into a single byte stream to
transmit the object from its current location to a new location.  The most
important goal of serialization is to re-create an object that is identical to
the original object. This type of serialization is used mostly to transport an
object across a network, to persist objects to a file or database, or to
distribute identical objects to several applications or locations.
Serialization can also be used to transform an object into a human-readable
state.
The processing of serializing an object is also known are {\sl deflating} or
{\sl marshalling} an object. The opposite operation of extracting a data
structure from a series of bytes, is called {\sl deserialization}, or {\sl
  unmarshalling} or {\sl inflating}.

\smallskip

Tools for serialization/deserialization are important because they can
provide:
\begin{itemize}
\item A simple and robust way to make objects persistent, so that they can be
later reused as reference, or collected to define standard problems;
\item A method for distributing objects across the network (e.g., with MPI);
\item An easy and convenient way to store or access standard problems for particular algorithms or techniques.
\item A mechanism to send and receive objects from other nodes in the Grid;
\item A convenient format to upload or download linear algebra objects for
web-based solvers (Web-IO);
\item A tool to restart a simulation.
\end{itemize}
In this document, we are interested in tool to serialize and
deserialize distributed linear algebra objects, internally defined
as Epetra object~\cite{Epetra-Users-Guide}. Our goal is to transmit
objects to and from storage media (files). The serialization
techniques we consider in this document aim to define flexible file
data formats. The Epetra objects we will consider in this document
are reported in Table \ref{tab:supported}. These objects are
characterized by the following properties:
\begin{itemize}
\item they are distributed across multiple processors, and therefore some for
of parallel I/O is required;
\item their data layout is determined by Epetra\_Map objects. The I/O should
be flexible enough to allow the clone object to have a different (tough
                                                                  compatible)
Epetra\_Map;
\item they require large chunks of memory;
\item the serialization and deserializaton process should allow I/O from
well-known formats, like MATLAB, MatrixMarket~\cite{boisvert97matrix}, and
Harwell/Boeing~\cite{duff89sparse}.
\end{itemize}
All the above objects
contain several pointers, which are too fragile to be saved. Therefore,
        the serialization process
must include procedures to convert the pointed memory into a local state, then
save this state into the final media. This means that the object has to be
converted into an intermediate state, which will be used to perform the
serialization itself. An analogous procedure occurs for deserialization. This
process is sometimes referred to as {\sl pointer unswizzling}.

\begin{table}
\begin{center}
\begin{tabular}{|l | c | c | c | c |}
\hline
object type           & H/B       & MM        & HDF5  & XML\\
\hline
Epetra\_BlockMap      & O  & I/O & I/O & --  \\
Epetra\_Map           & O  & I/O & I/O & I/O \\
Epetra\_IntVector     & -- & --  & I/O & --  \\
Epetra\_Vector        & O  & I/O & I/O & --  \\
Epetra\_MultiVector   & O  & I/O & I/O & I/O \\
Epetra\_CrsGraph      & -- & --  & I/O & I/O \\
Epetra\_RowMatrix     & O  &   O &   O &   O \\
Epetra\_CrsMatrix     & O  & I/O & I/O & I/O \\
Epetra\_VbrMatrix     & O  &   O &   O &   O \\
Teuchos::ParameterList& -- & --  & I/O & I/O \\
int                   & -- & --  & I/O & I/O \\
double                & -- & --  & I/O & I/O \\
void* array           & -- & --  & I/O &  -- \\
\hline
\end{tabular}
\caption{List of objects supported by the various I/O tools. ``H/B'' refers to
  the Harwell/Boeing format, ``MM'' to the MatrixMarket format, ``HDF5''
    to the HDF5 format, and ``XML'' to the XML-compatible format. 
    `I/O' means that both input and output are supported,
       while `O' that only output, `--' means no support.}
\label{tab:supported}
\end{center}
\end{table}

\smallskip

This manuscript outlines the serialization and deserialization tools available
within the EpetraExt package of Trilinos. The design requirements are outlined
in Section~\ref{sec:design}.
Section~\ref{sec:hb} describes the
Harwell/Boeing I/O; section~\ref{sec:mm} presents the MatrixMarket I/O;
section~\ref{sec:hdf5} outlines the design and the implementation of the
EpetraExt::HDF5 I/O. Finally, section~\ref{sec:xml} outlines the
XML-compatible format.

% ============================================================================
\section{Design Overview}
\label{sec:design}
% ============================================================================

% ============================================================================
\subsection{Requirements}
% ============================================================================

For the scientific computing applications considered in this paper, I/O
requirements fail into the following categories:
\begin{enumerate}
\item initial/intermediate/final I/O. Most programs need to read some data to
initialize a computation. PDE-based applications, for example, must read the
grid data structures. Typically, each processor only needs a part of the
complete data set. Output must often be generated for use on sequential
computers, for example to compare with earlier results, or to visualize or
analyze the results of the simulation;
\item out-of-core computations. A technique to lower the memory requirements
of an application is to hold on files all data structures containing
intermediate calculations that do not fit into main memory. These data
structures are called out-of-core structures, and they are brought into the
main memory in parts;
\item checkpointing and restart. For long-running production codes, it is
convenient to have the ability to save the state of the computation, in order
to continue computing from that point at a later date.
\item real-time I/O.
\end{enumerate}
We will consider only requirements (1) and (3), and we will focus on
flexibility and portability. Performances are addressed by the binary reader
only; however, even for the binary reader we never consider techniques to
overlap I/O and computations, which
might be of advantage for very intensive I/O applications. Note that for
requirements (1) and (3) a key question is whether the two phases of I/O occur
with the same number of processors.

% ============================================================================
\subsection{Requirements}
% ============================================================================

The serialization techniques considered in this report satisfy the
following requirements:
\begin{itemize}
\item
{\sl Code portability}: the ASCII serialization only depends on ANSI
C/C++ capabilities; the binary serialization has a dependency on a well-know
library, based on the widely-available MPI-IO;
\item
{\sl Deep copy behavior}: all data required to reconstruct the object is
serialized;
\item
{\sl Data Portability}: ASCII and binary streams of bytes created on one
platform are readable on any other;
\item
{\sl Non-intrusive}: Serialization tools can be applied to unaltered classes,
  that is, to classes developed independently of the serialization tools.
        Therefore, it is not required for the classes to be serialized to be
        derived from a specific base class or implement specified member
        functions.
\item
{\sl Simplicity}: The archive interface is simple enough to easily permit
creation of a new type of archive.
\item
{\sl Meta-data storage}
It is convenient to store {\sl metadata} together with the input and
output of a simulation. The simplest metadata is, for example, the name of the
object, or the class it belongs to. More sophisticated metadata can include
details on the procedure used to build the object, like for instance the
quadrature formula used to assemble the matrix, or the parameters used to
generate the preconditioner.
\end{itemize}

% ============================================================================
\subsection{Implementation}
% ============================================================================

Probably, the most critical aspect is the distributed nature of the object,
  which calls for efficient parallel I/O.
Parallel I/O is a mechanism that allow many
processors to perform I/O at the same time, with the goal of exploring
parallelism in the parallel computer's communication network and I/O system.
Parallel I/O on a shared file is possible only if the file is opened in
parallel by the participating processors.

The parallel programmer can take two different approaches to achieving
concurrency I/O operations. One approach is for each process to perform read
and write operations to a distinct file. While simple, this approach has
significant disadvantages: programs cannot easily be restarted on different
number of processors, the underlying file system has little information on
which to base optimization decisions, and files are not easily shared with
other programs. We decided to generate one single file, containing the entire
object. This is accomplished with different technical tools, depending on the
I/O format. For example, one can first reproduce the whole object on one
processor, then perform serial I/O, or let each processor write its part of
the object on the file.

Another design choice is  on the storage type of the resulting file, which
can be either human-readable (ASCII) or binary.
Human-readable objects are convenient when dealing with small objects.
Besides, they can easily edited or created with simple text editors, and at
least two formats have already been proposed in the literature: the
Harwell/Boeing file format, and the MatrixMarket file format. The
disadvantage of human-readable file formats is that their ASCII content is not
space-efficient, and the I/O is typically much slower than binary I/O. To
avoid these problems,
one can consider binary serialization. In order to make the resulting files
portable across different architectures, it is convenient to perform all the
binary I/O through some kind of library, and use some form of parallel I/O
techniques based on the widely available MPI-IO library.  This means that the
simple and fast procedure of directly copying the memory layout of the data
structure cannot work reliably for all architectures, and should instead be
replaced by more advanced techniques.

Another design choices must be considered.
The standard encoding method uses a simple translation of the field into a
byte steam, which contains all members of the object. This stream might
include other objects, referenced by the object currently under serialization;
all these objects must be in a serializable state as well. Alternatively, the
serialization must record enough information to instantiate these reference
objects without storing them in the stream. This process is sometimes refer to
as {\sl truncation}. We use truncation for all serialization tools presented
in this document, by serializing only those data that cannot be reproduced.

% ============================================================================
\section{The Harwell-Boeing I/O}
\label{sec:hb}
% ============================================================================

Harwell-Boeing files containing real matrices can be read using the following
the I/O function located in the Triutils package. The header file
\verb!Trilinos_Util.h! contains the signature of the function. Note that this
reader is only serial, and the objects have to be exported to distributed maps
in order to perform parallel computations. A typical usage for parallel runs
is reported below. The H/B reader operates on processor 0 only; therefore, if
more than one processor is considered in the computation, one need to declare
the following auxiliary objects:
\begin{verbatim}
string FileName = "my-file.rsa";
Epetra_Map* readMap;
Epetra_CrsMatrix* readA;
Epetra_Vector* readx;
Epetra_Vector* readb;
Epetra_Vector* readxexact;
\end{verbatim}
The read is performed by
\begin{verbatim}
Trilinos_Util_ReadHb2Epetra((char*)FileName_.c_str(), Comm, readMap,
                            readA, readx, readb, readxexact);
\end{verbatim}
At this point one can create a distributed map, for example
\begin{verbatim}
Epetra_Map map(readMap->NumGlobalElements(), 0, Comm);
\end{verbatim}
and allocate the final objects using this map,
\begin{verbatim}
Epetra_CrsMatrix A(Copy, map, 0);
Epetra_Vector x(map);          // distributed solution
Epetra_Vector b(map);          // distributed rhs
Epetra_Vector xexact(map);     // distributed exact solution
\end{verbatim}
Finally, one can export from the original map to the final map as follows:
\begin{verbatim}
const Epetra_Map &OriginalMap = readA->RowMatrixRowMap() ;
assert (OriginalMap.SameAs(*readMap));
Epetra_Export exporter(OriginalMap, map);

x.Export(*readx, exporter, Add);
b.Export(*readb, exporter, Add);
xexact.Export(*readxexact, exporter, Add);
A.Export(*readA, exporter, Add);
A.FillComplete();

// deletes memory
delete readMap;
delete readA;
delete readx;
delete readb;
delete readxexact;
\end{verbatim}

% ============================================================================
\section{The Matrix-Market I/O}
\label{sec:mm}
% ============================================================================

EpetraExt offers a variety of Matrix-Market I/O tools.
The Matrix Market format is a simple, portable and human-readable (ASCII)
format. The
specifications to create the corresponding ASCII files can be found at
\begin{verbatim}
http://math.nist.gov/MatrixMarket/
\end{verbatim}
where MATLAB files to perform I/O can be downloaded.
The header files to be includes are
\begin{verbatim}
#include "EpetraExt_BlockMapIn.h"
#include "EpetraExt_BlockMapOut.h"
#include "EpetraExt_VectorIn.h"
#include "EpetraExt_VectorOut.h"
#include "EpetraExt_MultiVectorIn.h"
#include "EpetraExt_MultiVectorOut.h"
#include "EpetraExt_CrsMatrixIn.h"
#include "EpetraExt_RowMatrixOut.h"
\end{verbatim}
All classes offer both serial and parallel support.
To show the usage, let us consider for example the following objects:
\begin{verbatim}
Epetra_Map Map(10, 0, Comm);
Epetra_MultiVector X(Map, 2);
Epetra_MultiVector B(Map, 2);
Epetra_CrsMatrix A(Copy, Map, 0);  // create a simple diagonal matrix
for (int i = 0 ; i < NumMyElements ; ++i)
{
  int j = Map.GID(i);
  double value = 1.0;
  EPETRA_CHK_ERR(A.InsertGlobalValues(j, 1, &value, &j));
}
A.FillComplete();
\end{verbatim}
where \verb!Comm! is an Epetra\_Comm object.
These objects can be saved on file
in both serial and parallel computations by using the commands
\begin{verbatim}
EpetraExt::MapToMatrixMarketFile("Map.mm", Map);
EpetraExt::MultiVectorToMatrixMarketFile("X.mm", X);
EpetraExt::MultiVectorToMatrixMarketFile("B.mm", B);
EpetraExt::RowMatrixToMatrixMarketFile("A.mm", A);
\end{verbatim}
By using the \verb!mmread.m! MATLAB
script available at the Matrix Market web site, one can type within MATLAB
\begin{verbatim}
>> X = mmread('X.mm');
>> A = mmread('A.mm')

A =

   (1,1)        1
   (2,2)        1
   (3,3)        1
   (4,4)        1
   (5,5)        1
\end{verbatim}
Alternatively, one can read the
previous files within a C++ code as follows:
\begin{verbatim}
Epetra_Map* newMap;
Epetra_MultiVector* newX;
Epetra_MultiVector* newB;
Epetra_CrsMatrix* newA;

EpetraExt::MatrixMarketFileToMap("Map.mm", Comm, newMap);
EpetraExt::MatrixMarketFileToMultiVector("X.mm", *newMap, newX);
EpetraExt::MatrixMarketFileToMultiVector("B.mm", *newMap, newB);
EpetraExt::MatrixMarketFileToCrsMatrix("A.mm", *newMap, newA);
\end{verbatim}
Note that one has to call method {\tt FillComplete()} to finalize the
structure of the Epetra\_CrsMatrix read by MatrixMarketFileToCrsMatrix.

% ============================================================================
\subsection{The Python Interface}
\label{sec:mm:python}
% ============================================================================

EpetraExt offers a Python interface to the MatrixMarket reader through the
PyTrilinos project~\cite{pytrilinos-la-guide,sala05pytrilinos}.  Example of
I/O using the Python interface is reported in Figure~\ref{fig:python}.

\begin{sidewaystable}
\begin{center}
\begin{tabular}{| c |}
\hline
\begin{minipage}{17cm}
\begin{verbatim}

from PyTrilinos import EpetraExt, Epetra
# Build a global communicator
comm    = Epetra.PyComm()
# Construct a vector x and populate with random values
n       = 10 * numProc
map     = Epetra.Map(n, 0, comm)
x       = Epetra.Vector(map)
x.Random()

# create a matrix and store it on file
A       = Epetra.CrsMatrix(Epetra.Copy, map2, 0)
Indices = Epetra.IntSerialDenseVector(1)
Values  = Epetra.SerialDenseVector(1)
for lrid in range(A.NumMyRows()):
  grid = A.GRID(lrid)
  Indices[0] = grid
  Values[0]  = grid
  A.InsertGlobalValues(grid, 1, Values, Indices)
A.FillComplete()

# Part I: writing

EpetraExt.BlockMapToMatrixMarketFile("map.mm", map)
EpetraExt.MultiVectorToMatrixMarketFile("x.mm", x)
EpetraExt.RowMatrixToMatrixMarketFile("A.mm", A)

# Part II: reading

(ierr, map2) = EpetraExt.MatrixMarketFileToMap("map.mm", comm)
(ierr, y) = EpetraExt.MatrixMarketFileToMultiVector("x.mm", map2)
(ierr, B) = EpetraExt.MatrixMarketFileToCrsMatrix("A.mm", map2)

\end{verbatim}
\end{minipage} \\
    \hline
\end{tabular}
\caption{Example of Python code using the EpetraExt MatrixMarket
  capabilities.}
\label{fig:python}
\end{center}
\end{sidewaystable}

% ============================================================================
\section{HDF5 I/O}
\label{sec:hdf5}
% ============================================================================

Matrix-Market files have several advantages, but their usage for large-scale
problems is limited by their size. Also, there is no read parallel I/O in the
Matrix-Market tools, and therefore a non-negligible performance penalty may
occur when large number of processors are involved. In this cases, it is
convenient to adopt a fully-parallel, binary reader, based on the MPI-IO
library. MPI-IO derives must of its philosophy and interface from the MPI
standard. In MPI-IO, file I/O is modeled as message passing. This is, reading
from a file is analogous to receiving a message and writing to a file is
analogous to sending a message. MPI-IO benefits from its association with MPI,
which is the de-facto standard for parallel computations, and provides a
common interface with optimized implementations across many different
platforms. The primary disadvantage of MPI-IO, instead, is the difficulty to
use. As such, it is more convenient to adopt libraries like HDF5, that offer
an intermediate layer between the MPI-IO implementation and user's data. This
library can be downloaded  at the web address:
\begin{verbatim}
http://hdf.ncsa.uiuc.edu/HDF5/
\end{verbatim}
An interface between HDF5 and Epetra objects is provided by the
EpetraExt::HDF5 class.

HDF5 is a general purpose library and file format for storing scientific data.
HDF5 can store two primary objects: datasets and groups. A dataset is
essentially a multidimensional array of data elements, and a group is a
structure for organizing objects in an HDF5 file. Using these two basic
objects, one can create and store almost any kind of scientific data
structure, such as images, arrays of vectors, and structured and unstructured
grids.

While building Trilinos, it should be enough to specify the location of the
header files using \verb!--with-incdirs!, the location of the library using
\verb!--with-ldflags!, and the HDF5 library using \verb!--with-libs!. Note
that one might need to add \verb!-lz! to the list of linked libraries; this library
is typically already installed on all system;

The HDF5 class of EpetraExt has the following advantages:
\begin{itemize}
\item The file format is binary and portable;
\item The file format can be read and written in parallel;
HDF5 is based on MPI-IO, and allows for true parallel I/O;
\item MATLAB contains a built-in HDF5 data reader, making it easy to interface
Trilinos application with MATLAB, and vice-versa;
\item The number of processors reading a given
data does not have to coincide with that used to write the data.
\end{itemize}


The HDF5 class has the following limitations:
\begin{enumerate}
\item Objects stored in a file cannot be deleted; if you want to do that, you should read the
  content of the file, then create a new file and store on it the information to keep;
\item It is not possible to overwrite distributed objects.
\end{enumerate}


% ============================================================================
\subsection{An Example of Usage}
\label{sec:hdf5:example}
% ============================================================================

This section reports several examples of usage of the EpetraExt::HDF5 class.
First, one has to create an HDF5 class, then either {\tt Open()}
(for reading or appending to an already existing file) or
{\tt Create()} (to generate a new file, or delete all the contents of an
                already existing one) the file:
\begin{verbatim}
EpetraExt::HDF5 HDF5(Comm);
HDF5.Create("myfile.h5");
\end{verbatim}
Let us consider that {\tt Map} is an Epetra\_Map object, {\tt BlockMap} an
Epetra\_BlockMap object, {\tt LHS} and {\tt RHS} two Epetra\_MultiVector
objects, and {\tt Matrix} an Epetra\_RowMatrix. To write these objects on a
file, simply do
\begin{verbatim}
HDF5.Write("map", *Map);
HDF5.Write("matrix", *Matrix);
HDF5.Write("solution vector", LHS);
HDF5.Write("right-hand side", RHS);
\end{verbatim}
Epetra\_Map and Epetra\_BlockMap objects are the only Epetra objects
that can be read only with the same number of processors used for writing.
Therefore, these types of object require an additional care. One can, for
example, define the number of processors as part of the name:
\begin{verbatim}
HDF5.Write("map-" + toString(Comm.NumProc()), *Map);
\end{verbatim}

The HDF5 class also offers I/O for Teuchos::ParameterList objects. Types
within the list that are not {\tt bool}, {\tt
  int}, {\tt double} and {\tt string} types or sublists are ignored.

In all the above instructions, the first input variable is a user-defined name
that identifies the object. Note that the {\sl same} file can contain an
arbitrary number of objects, of the same type or of different type, as long as
the associated names differ. It is therefore possible, for example, to store
all the Jacobians and the associated right-hand sides in a Newton-type
procedures in the same file.

An advantage of the HDF5 file format is that
it is very easy to add "meta-data" to your data.
HDF5 naturally stores
datatype information and ``metadata'' describing the rank, dimension, and
other data properties. Data are stored in datasets which can be queried by
names to find out the size, layout, and other properties.
For example, a string
containing information about the machine where the code was executed, the
parameter list used for the preconditioner or the nonlinear solver, the
convergence history, can all be save in the same file;
In fact, the HDF5 library itself can be used to define very general data
formats; this class, instead, is only structured around the concept of {\sl
  groups}.
A {\sl group}
is an entity, like for example a scalar value, an Epetra\_Map, or a
Teuchos::ParameterList. Within each group, different datasets describe the
content of the group. Class EpetraExt::HDF5 serializes each Epetra object by
writing all the required data, plus other metadata that can be useful to query
the object properties without reading (and therefore building) the object
itself. The list of metadata is reported in Table~\ref{tab:metadata}.
For example, an Epetra\_MultiVector is specified by
datasets {\tt NumVectors} and {\tt Values}, which contain the number of vectors, and
the numerical values, respectively. The {\tt comment} field of each group is a
character string that must match the class name. A snippet of code reading the
metadata of an Epetra\_Map is as follows:
\begin{verbatim}
int NumGlobalElements, IndexBase, NumProc;
HDF5.ReadMapProperties("map", NumGlobalElements, IndexBase, NumProc);
if (NumProc != Comm.NumProc()) {
  // build a linear map
  Map = new Epetra_Map(NumGlobalRows, IndexBase, NumProc);
} else {
  HDF5.Read("map", Map);
}
\end{verbatim}

A snippet of code reading the
metadata of a Epetra\_CrsMatrix is as follows:
\begin{verbatim}
int NumGlobalRows, NumGlobalCols, NumGlobalNonzeros;
int NumGlobalDiagonals, MaxNumEntries;
double NormOne, NormInf;

HDF5.ReadCrsMatrixProperties(GroupName, NumGlobalRows, NumGlobalCols,
                             NumGlobalNonzeros, NumGlobalDiagonals,
                             MaxNumEntries, NormOne, NormInf);
\end{verbatim}
We refer to the up-to-date Doxygen documentation of the EpetraExt::HDF5 class
for more details on the property reading methods.

\begin{table}
\begin{center}
\begin{tabular}{|l | p{10cm} |}
\hline
Epetra object & Associated metadata \\
\hline
Epetra\_BlockMap & NumGlobalElements,
                   NumGlobalPoints,
                   IndexBase,
                   NumProc \\
\hline
Epetra\_Map & NumGlobalElements,
              IndexBase,
              NumProc \\
\hline
Epetra\_IntVector & GlobalLength \\
    \hline
Epetra\_MultiVector & GlobalLength,
                      NumVectors \\
\hline
Epetra\_CrsGraph & NumGlobalRows,
                   NumGlobalCols,
                   NumGlobalNonzeros,
                   NumGlobalDiagonals,
                   MaxNumIndices\\
\hline
Epetra\_CrsMatrix & NumGlobalRows,
                    NumGlobalCols,
                    NumGlobalNonzeros,
                    NumGlobalDiagonals,
                    MaxNumEntries,
                    NormOne,
                    NormInf \\
\hline
\end{tabular}
\caption{Metadata associated with each  Epetra object. These metadata can be
  queries by using the appropriate read method.}
\label{tab:metadata}
\end{center}
\end{table}

The metadata reported in Table~\ref{tab:metadata} are a subset of what is
stored in the HDF5 file. The actual content of the file can be visualized by
using the command
\begin{verbatim}
$ h5dump filename.h5
\end{verbatim}
distributed within the HDF5 library. Note also that an arbitrary number of
metadata can be associated with any group in the file.  A group can contain
more than one dataset, and can be a new group or an already existing group.
For example, to specify the numerical quadrature formula used to assemble the
matrix, one can do as follows:
\begin{verbatim}
HDF5.Write("matrix", "quadrature order", 3);
\end{verbatim}
In this case, dataset {\tt quadrature order} is associated to group {\tt
  matrix}, which already contains an Epetra\_CrsMatrix object.
Alternatively, datasets can be assigned to a new group, in this case
{\tt my parameters}:
\begin{verbatim}
HDF5.Write("my parameters", "latitude", 12);
HDF5.Write("my parameters", "longitude", 67);
HDF5.Write("my parameters", "angle", 12.3);
\end{verbatim}
Another data type can be stored on file are arrays. The type of the array is
specified using native HDF5 datatypes. Two important types are {\tt
  H5T\_NATIVE\_INT} and {\tt H5T\_NATIVE\_DOUBLE}. For example:
\begin{verbatim}
vector<int> iarray(3);
iarray[0] = 0, iarray[1] = 1; iarray[2] = 2;
HDF5.Write("my parameters", "int array", H5T_NATIVE_INT,
           3, &iarray[0]);
\end{verbatim}
Note that all non-distributed data are supposed to be in the same state on all
processors. Without considering Epetra objects, EpetraExt::HDF5 allows only
one type of distributed object, as detailed in section \ref{sec:hdf5:arrays}.

\smallskip

Reading data is as easy as writing them. For example, to read an
Epetra\_CrsMatrix one can do as follows:
\begin{verbatim}
Epetra_CrsMatrix* NewMatrix = 0;
HDF5.Read("matrix", NewMatrix);
\end{verbatim}
Since no Epetra\_Map has been specified,
the newly created object {\tt NewMatrix} is based on a linear map. If the DomainMap() and RangeMap() are
known and non-trivial, one can use
\begin{verbatim}
HDF5.Read("matrix", DomainMap, RangeMap, NewMatrix);
\end{verbatim}
Reading meta-data looks like:
\begin{verbatim}
HDF5.Read("my parameters", "latitude", new_latitude);
HDF5.Read("my parameters", "longitude", new_longitude);
HDF5.Read("my parameters", "int array", H5T_NATIVE_INT,
          3, &new_iarray[0]);
\end{verbatim}

Class EpetraExt::HDF5 has few other public methods that can be used to
manipulate directly the HDF5 file. Method
{\tt CreateGroup()} creates the specified group in the file;
{\tt IsContained()} returns {\tt true} is the specified group is already
contained in the file;
{\tt WriteComment()} allows to write any string as comment for a group.

Finally, when an error arises, an EpetraExt::Exception object is
thrown. Method Print() of the Exception class gives a description of
what went wrong.

% ============================================================================
\subsection{I/O for Distributed Arrays}
\label{sec:hdf5:arrays}
% ============================================================================

EpetraExt::HDF5 allows to perform I/O on distributed arrays, that is, for an
array of global length {\tt GlobalLength} and local size {\tt MyLength}, where
this latter value can assume a different value on each processor. The
following example, to be executed on two processors, writes an array on
integers, which has 3 elements on processor 0 and 2 on processor 1.
\begin{verbatim}
Epetra_MpiComm Comm(MPI_COMM_WORLD);
int MyLength, GlobalLength = 5;
if (Comm.MyPID() == 0) MyLength = 3;
else                   MyLength = 2;
std::vector<int> data(MyLength); // populate the vector

EpetraExt::HDF5 HDF5(Comm);
HDF5.Create("myfile.h5");
HDF5.Write("my-array", "values", MyLength, GlobalLength,
           H5T_NATIVE_INT, &data[0]);
HDF5.Close();
\end{verbatim}
In the above example, the distributed data is saved in group {\tt my-array},
   using the dataset {\tt values}. The reading might be as follows, when using
   5 processors:
\begin{verbatim}
int data;
HDF5.Open("myfile.h5");
HDF5.Read("my-array", "values", 1, 5, H5T_NATIVE_INT, &data);
HDF5.Close();
\end{verbatim}

% ============================================================================
\subsection{The MATLAB Interface}
\label{sec:hdf5:matlab}
% ============================================================================

The build-in functions {\tt hdf5read, hdf5write, hdf5info} can be used to read
or write EpetraExt-compatible HDF5 files from MATLAB. Figure \ref{fig:matlab}
reports two sets of MATLAB commands. The first set shows how to read an
Epetra\_CrsMatrix stored in the group {\tt matrix}, while the second present
a typical procedure to write on file a MATLAB sparse matrix
(in this case, a diagonal matrix of size 10). This matrix will be saved within
the group {\tt speye}.

\begin{sidewaystable}
\begin{tabular}{| c |}
\hline
\begin{minipage}{22cm}
\begin{verbatim}

>> % Part I: reading data
>> NumGlobalRows = double(hdf5read('myfile.h5', '/matrix/NumGlobalRows/'));
>> NumGlobalCols = double(hdf5read('myfile.h5', '/matrix/NumGlobalCols/'));
>> ROW = double(hdf5read('myfile.h5', '/matrix/ROW/'));
>> COL = double(hdf5read('myfile.h5', '/matrix/COL/'));
>> VAL = hdf5read('myfile.h5', '/matrix/VAL/');
>> matrix = sparse(ROW + 1, COL + 1, VAL, NumGlobalRows, NumGlobalCols);
>>
>> % Part II: writing data
>> n = 10;
>> A = speye(n, n);
>> [ROW,COL,VAL] = find(A);
>> hdf5write('matlab.h5', '/speye/__type__',           'Epetra_RowMatrix');
>> hdf5write('matlab.h5', '/speye/NumGlobalRows',      int32(n), 'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/NumGlobalCols',      int32(n), 'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/NumGlobalNonzeros',  int32(n), 'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/NumGlobalDiagonals', int32(n), 'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/MaxNumEntries',      int32(1), 'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/NormOne',            1.0,      'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/NormInf',            1.0,      'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/ROW', int32(ROW - 1), 'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/COL', int32(COL - 1), 'WriteMode', 'append');
>> hdf5write('matlab.h5', '/speye/VAL', VAL,            'WriteMode', 'append');

\end{verbatim}
\end{minipage} \\
\hline
\end{tabular}
\caption{Example of input/output for HDF5 from MATLAB.
The use of {\tt double()} is required by sparse, which does not accept {\tt
  int32} data.  }
\label{fig:matlab}
\end{sidewaystable}

% ===========================================================================
\subsection{The HYPRE Interface}
\label{sec:hdf5:hypre}
% ===========================================================================

EpetraExt can be used to read in a matrix that was created in Hypre. This
method will read from a file that was created using the HYPRE\_IJMatrixPrint()
command. It takes the same filename as the one that was used as the parameter
to the Hypre command.

% ============================================================================
\section{XML I/O}
\label{sec:xml}
% ============================================================================

We now describe the XML-compatible file format. XML is a specification of the
the World Wide Web Consortium (W3C) for document representation. Initially, it
was designed to represent text documents. Technically, XML is a meta-language,
that is, a language that describes how to specify languages. 
XML files are made up by {\sl tags} that can be arbitrarily defined. Tags are
defined by {\sl tagsets} called document type definitions (DTDs). DTDs can be used
to represent any kind of document; here, we investigate how to use them to
store Trilinos objects.

XML I/O in EpetraExt is performed by classes XMLWriter and XMLReader. This
latter class requires Teuchos to be configured with the option 
\verb!--enable-teuchos-expat!.

\smallskip

Writing objects goes as follows. Let \verb!Map!, \verb!Matrix!, \verb!LHS! and
\verb!RHS! an 
Epetra\_Map, Epetra\_CrsMatrix, and two Epetra\_MultiVector's, respectively.
To write these objects to file \verb!data.xml!, one first has to define an
XMLWriter object,
\begin{verbatim}
EpetraExt::XMLWriter XMLWriter(Comm, "data.xml");
\end{verbatim}
then open the file using \verb!MyProblem! as label:
\begin{verbatim}
XMLWriter.Create("MyProblem");
\end{verbatim}
Writing objects simply goes as
\begin{verbatim}
XMLWriter.Write("MyMap", Map);
XMLWriter.Write("MyMatrix", Matrix);
XMLWriter.Write("MyLHS", LHS);
XMLWriter.Write("MyRHS", RHS);
\end{verbatim}
A Teuchos::ParameterList, a \verb!string!, and a \verb!vector<string>! can be written as
\begin{verbatim}
XMLWriter.Write("MyParameters", List);
XMLWriter.Write("Author", "myself and others");
vector<string> Content;
Content.push_back("first line");
Content.push_back("second line");
XMLWriter.Write("MyContent", Content);
\end{verbatim}
Note that all serial objects (strings and Teuchos::ParameterList's) are
written by processor 0 only.

The output file is closed using
\begin{verbatim}
XMLWriter.Close();
\end{verbatim}
File \verb!data.xml! is reported in Figure~\ref{fig:xml}.

\begin{table}
\begin{tabular}{| c |}
\hline
\small
\begin{minipage}{16cm}
\begin{verbatim}

<ObjectCollection Label="MyProblem">
<Text Label="Author">
myself and others
</Text>
<Text Label="Date">
May 2006
</Text>
<Map Label="MyMap" NumElements="4" IndexBase="0" NumProc="1" 
 ElementsOnProc0="4">
<Proc ID="0">
0
1
2
3
</Proc>
</Map>
<PointMatrix Label="MyMatrix" Rows="4" Columns="4" Nonzeros="4" 
 Type="double" StartingIndex="0">
0 0 1
1 1 1
2 2 1
3 3 1
</PointMatrix>
<MultiVector Label="MyLHS" Length="4" NumVectors="2" Type="double">
-0.232996 -0.893077 
0.0388327 0.0594004 
0.661931 0.342299 
-0.930856 -0.984604 
</MultiVector>
<MultiVector Label="MyRHS" Length="4" NumVectors="2" Type="double">
0 0 
0 0 
0 0 
0 0 
</MultiVector>
<Text Label="MyContent">
This is an example of description
The description is as long as desired,
just put it in a vector of strings.
</Text>
<List Label="MyParameters">
<ParameterList>
<Parameter name="double parameter" type="double" value="10"/>
<Parameter name="int parameter" type="int" value="10"/>
<Parameter name="string parameter" type="string" value="string"/>
</ParameterList>
</List>
</ObjectCollection>

\end{verbatim}
\end{minipage} \\
\hline
\end{tabular}
\caption{Example of file format using XML.}
\label{fig:xml}
\end{table}

Reading objects is even easier. First, one has to define an XMLReader object
and a set of pointers for the objects to be read,
\begin{verbatim}
EpetraExt::XMLReader XMLReader(Comm, "data.xml");
Epetra_Map* MyMap;
Epetra_CrsMatrix* MyMatrix;
Epetra_MultiVector* MyLHS;
Epetra_MultiVector* MyRHS;
Teuchos::ParameterList MyParameters;
vector<string> Author;
vector<string> Date;
vector<string> MyContent;
\end{verbatim}
Reading simply goes as follows:
\begin{verbatim}
XMLReader.Read("Author", Author);
XMLReader.Read("Date", Date);
XMLReader.Read("MyMap", MyMap);
XMLReader.Read("MyMatrix", MyMatrix);
XMLReader.Read("MyLHS", MyLHS);
XMLReader.Read("MyRHS", MyRHS);
XMLReader.Read("MyContent", MyContent);
XMLReader.Read("MyParameters", MyParameters);
\end{verbatim} 
If an object is not found, the null pointer is returned.
All the created objects must be deleted from the user using \c delete. 

The XML file format can be used in serial and parallel environments. While
Epetra\_Map objects can be read only when  using the same number of processors
used for writing, all the other distributed objects can be read with any
number of processors.  Note that the reader for Epetra\_MultiVector,
Epetra\_CrsGraph and Epetra\_CrsMatrix assumes a linear distribution. 

% ============================================================================
\section*{Acknowledgments}
% ============================================================================

The authors would like to acknowledge the support of the ASCI and LDRD programs
that funded development of Trilinos. John Shadid, Prof. Peter Arbenz and Prof.
Petros Koumoutsakos are acknowledged for part of the financial coverage.

\medskip

% ============================================================================
\bibliographystyle{plain}
\bibliography{biblio,../../../../doc/CommonFiles/TrilinosBibliography}
% ============================================================================

\newpage

\noindent
{\bf
Distribution List for ``Serialization Tools for Distributed Linear Algebra Objects:''
}

\begin{itemize}
\item MS 9018 Central Technical Files, 8945-1
\item MS 0899 Technical Library, 9616
\item MS 0123 LDRD Donna Chavez, 1011
\end{itemize}

\end{document}
