
% Outlining a Development Model for CSE Software
% Jim Willenbring, Mike Phenow, Mike Heroux

%## Header ####################################################################

\documentclass[12pt,relax]{article}
\addtolength {\textheight}{0.2in}
\addtolength {\textwidth}{0.2in}
\linespread{1.6}
\newcommand{\DisplayCommand}[1]{%
\par\vspace{1ex}%
{\bf Command:}%
{\hspace{0.2 in}} {\tt #1} {\par\vspace{1ex}}}

% InlineCommand
\newcommand{\InlineCommand}[1]{
  {\hspace{0.01 in}} {\tt #1} {\hspace{0.01 in}}}

% InlineDirectory
\newcommand{\InlineDirectory}[1]{
  {\hspace{0.01 in}} {\tt #1} {\hspace{0.01 in}}}

\usepackage{array}

%## Content ###################################################################

%== Title Page ================================================================

\title{Outlining a Development Model for CSE Software}

\author{
Michael Heroux\\
James Willenbring\\
Michael Phenow\\
}

% There is a "Printed" date on the title page of a SAND report, so
% the generic \date should generally be empty.
\date{\today} % Remove ``\today'' in final version

\begin{document}

\maketitle
%\setcounter{page}{3} % Accounts for blank page at beginning

%== Abstract ==================================================================

\begin{abstract}

Most existing computational science and engineering (CSE) software has been 
developed without the benefit of Software Quality Assurance (SQA) processes.
The increasing complexity of applications is dictating a higher standard for 
CSE software quality; it is no longer sufficient to claim to have 
written high quality software.  However, traditional
software development models can be impractical for CSE projects to implement.
Despite this, CSE software teams can benefit by implementing
valuable SQA processes and tools.  We will outline some the
processes and tools that the Trilinos Project has had success with.  These 
tools and processes have been useful not only in increasing 
\textit{verifiable} software quailty, but also have improved 
overall software quality, and the development experience in 
general.

\end{abstract}

\clearpage

%== Acknowledgements ==========================================================

\section*{Acknowledgments}

The authors would like to acknowledge the support of the ASC and LDRD programs 
that funded development of Trilinos and recognize all Trilinos contributors:
Michael Heroux (project leader), Teri Barth, Ross Bartlett, Paul Boggs, Jason
Cross, David Day, Clark Dohrmann, Robert Heaphy, Ulrich Hetmaniuk, Robert
Hoekstra, Russell Hooper, Vicki Howle, Jonathan Hu, Tammy Kolda, Kris
Kampshoff, Sarah Knepper, Joe Kotulski, Richard Lehoucq, Kevin Long, Joe
Outzen, Roger Pawlowski, Eric Phipps, Andrew Rothfuss, Marzio Sala, Andrew
Salinger, Paul Sery, Paul Sexton, Ken Stanley, Heidi Thornquist, Ray Tuminaro
and Alan Williams.

\clearpage
\tableofcontents

\clearpage

%== Introduction ==============================================================

\section{Introduction}
\label{Section:Introduction}


Four years ago the Trilinos development team was charged with the task of 
improving existing software quality practices.  Since many computational 
science and engineering (CSE) software projects are not dedicated to formal
Softare Quality Assurance (SQA) practices, a lot of work is required to 
define practices that are compatible with the the project.
%Developing computational science and engineering (CSE) software presents some 
%unique challenges.  CSE software projects frequently don't have large budgets 
%to spend on advanced software engineering tools, processes, and personnel.  
%They often are developed by small groups of experts in the particular 
%computational science or engineering domain in question, not experts on 
%software engineering or software project management.  The Trilinos Project
%(an effort to develop parallel solver algorithms and libraries within an
%object-oriented software framework for the solution of large-scale, complex
%multi-physics engineering and scientific applications), which is developed at
%Sandia National Laboratories, is no different.  
It is our belief that 
there are certain low-cost, high-yield processes and tools that tend to work 
well to enable the development of high quality CSE software.  To demonstrate 
this, we will present some facts and high-level goals that apply to most CSE 
software projects.  We will then present aspects of
a development model that we think do a good job job of enabling developers to
reach those ends.  Finally, we will discuss some general classes (and specific
instances) of tools that enable the development model, and through that, 
the ultimate goals of the project.  Throughout we will use our experiences on 
the Trilinos project to provide specific examples of these tools and processes.

Those who are interested in learning more about the Trilinos project should
consult {\it An Overview of Trilinos}~\cite{Trilinos-Overview} or the
{\it Trilinos Users Guide}~\cite{Trilinos-Users-Guide}.  Trilinos also has an
extensive web site that can be found at \newline
\InlineDirectory{http://software.sandia.gov/trilinos}~\cite{Trilinos-home-page}.

%== Project Characteristics ===================================================
\section{Project Characteristics}
\label{Section:ProjectCharacteristics}

The goals, driving principles, and tools discussed below were defined or 
adopted based on a number of characteristics of the Trilinos Project.  Many of 
these characteristics apply more broadly to a large percentage of CSE software.

\begin{itemize}

\item Requirements are intractable.

\item Written by small, inter-related teams.
%distributed teams

\item Users should be shielded from softare complexity.

\item Interoperability is extremely important.

\item Claiming to do a good job is insufficient.
%mention also limited budget for anything outside of algorithms development

\end{itemize}

%== Goals =====================================================================

\section{Goals}
\label{Section:Goals}

Based on the above project characteristics, it is easy to extract some high-
level project goals.  These goals can be applied to most software projects,
but are described below in the specific context of the Trilinos Project.

\subsection{Quality}
%-------------------
Trilinos, like all software projects, seeks quality as a primary goal--quality
both in the colloquial meaning of the word and the particular meaning it
carries in the software engineering world, specifically:  a measure of the
degree to which software meets its stated requirements.

\subsection{Modularity}
%----------------------
Individual sets of functionality in Trilinos are contained in individual,
autonomous modules called packages, which are developed by individuals or small
teams.  Keeping logically distinct pieces of functionality modular is critical
to the long-term health of the project.  

\subsection{Interoperability}
%----------------------------
Because of this modular architecture, it is of utmost importance that the
various packages ``play well together.''  For Trilinos to realize its full
potential, all of the various independent parts need to work together in
concert.  This is an important issue for CSE software in general.  There 
is a lot of excellent existing software that cannot be seemlessly be 
brought to bear for the purpose of solving a single problem.

\subsection{Scalability}
%-----------------------
Trilinos started as a collection of three packages.  In a few short years, it
has organically grown to include more than 25 packages.  To maximize the
benefits reaped from economies of scale and to leverage to power of other
codes, scalability, the ability to continue to add more packages, is a primary
concern for Trilinos.  The degree to which the Trilinos architecture scales
is directly dependent on the level of modularity and interoperability achieved.

\subsection{Reliability}
%-----------------------
Trilinos developers are not generally experts in software engineering, nor do
they wish to sample the bleeding edge of software engineering 
tools.  Rather, tools that are established and well tested are preferable
to newer, experimental tools.  Fortunately, the tools that have been adopted 
are not only reliable, but are also freely available.

%\subsection{Availability}
%------------------------
%Cannot identify a tool that addresses this area; more of a sysadmin issue


\subsection{Efficient Use of Expert Time}
%----------------------------------------
Trilinos packages are developed by experts in the particular domain of a
package.  One very critical goal of the Trilinos project is to make efficient
use of these experts' time.  These experts ought to be spending as much time as
possible in their domain of expertise, not bothering with the comparatively
mundane tasks of software project management, which, unchecked, have a way of
crowding out other tasks.  When inefficient SQA processes are adopted, it can 
decreasei, rather than increase, efficiency.

\subsection{Support}
%-------------------
Finally, the ultimate goal of any piece of software is to actually get used.  
It is important to provide support so that all of the energy spent developing
the software is put to good use, but, here again, it is important that the
experts don't have to spend their time helping users install and use the
software.

\clearpage

%== Driving Principles =========================================================

\section{Driving Principles}
\label{Section:Driving Principles}

For many CSE software projects it simply isn't efficient to use a traditional, 
formal development model.  There are many reasons for this:  CSE software tends
to be research-based or exploratory in nature, CSE software projects tend not
to be on the same scale as large commercial software efforts, and CSE software 
projects often don't have guaranteed funding far into the future.  

\subsection{Two-Tiered Architecture}
%-----------------------------------

(orthogonality, organic growth, don't repeat yourself (DRY), economies of scale)

One particularly strong feature of the development model employed by the
Trilinos Project is its two-tiered architecture.  The functionality of Trilinos
is divided into a number of small, autonomous modules, called packages. 
Packages are self-driven, but at the central Trilinos level, called the
framework, guidelines and services are provided.  The package architecture
helps to encourage modularity throughout Trilinos and also promotes scalability
by providing a working model for adding new functionality.  The guidelines
provided by the framework help promote interoperability between packages.
The services provided by the framework help to minimize the overhead that the
expert developers need to concern themselves with.  The framework also provides
a first line of support to effectively shield developers from having to deal
with the trivial support requests.  The net effect of all of these factors is
a higher level of quality and improving efficiency throughout the project.

Trilinos, which began as a set of three packages, got its name from the Greek
``trilinos,'' which loosely translated means ``string of pearls,'' and is
meant to convey the idea that each package is a valuable pearl, but is even
more valuable when combined with the rest of the packages.  This image also
contains the notion of a common thread holding all the packages together.

  \subsubsection{Packages}
  %-----------------------
  
  Grouping functionality into self-contained packages provides a number of
  benefits:  it keeps teams to small groups of experts, it allows for local
  autonomy, and it allows for local authority.
  
  As mentioned above, Trilinos began as three packages and has since grown to 
  include more than 25.  Each of these packages has a different story.  Some
  were started from scratch within Trilinos.  Many others were existing
  projects imported into Trilinos.  Of these, we find the whole range, from
  those just off the ground, to mature codes that have been in use for years.
  In all cases, the development of the code is done by experts in the given
  domain.  These groups generally consist of one to five developers.  This
  small size keeps the groups focused, agile, and accountable.
    
  Packages that join Trilinos after they are relatively mature often wouldn't
  do so if they felt they would be forever dependent on Trilinos.  The design
  of the Trilinos architecture very deliberately seeks to prevent a central
  entity upon which all packages must be dependent.  Many packages came to 
  Trilinos already having an established user base and it is very important
  for some packages to be able to exist either within the Trilinos framework
  or completely apart from it.
  
  Similarly, many packages would not be inclined to become a part of Trilinos
  if they had to surrender the control of their package.  Being a part of
  Trilinos brings with it very few requirements.  Instead, there are many
  guidelines and services that, in practice, are almost all adopted by all
  packages.  Local decisions about the direction or design of a package are
  left in the hands of the package developers.

  \subsubsection{Framework}
  %------------------------
  
  In the two-tiered architecture, we generally refer to the upper tier as the
  framework.  The framework is the string holding the pearls of the various
  packages together.  The framework exists for the benefit of member
  packages, providing numerous services and suggested practices.

  The Trilinos Framework makes many optional, valuable services available to
  member packages.  Focusing on a large number of packages makes more advanced
  services available to development teams that otherwise might be too
  small to have access to such an array of services.  Some of the standard
  services include source control, an issue reporting tool, and mail lists.
  More advanced services include a package webpage prototype and personal 
  assistance in creating and maintaining package websites as well as a build 
  system that allows all packages to be built as a part of a single process 
  and helps to ease some porting issues.  A functional example package called
  New Package can be used by developers to quickly adapt an existing package 
  to the suggested Trilinos build system or to hasten the process of 
  building a portable package from scratch.  Automated testing on an expanding 
  number of platforms as well as the ability to set up customized test runs is 
  available via the Trilinos Test Harness.  A relatively new service provided 
  by  the framework is the ability to view test results on the internet from
  all of the Trilinos Test Harness testing platforms.
  
  As mentioned above, Trilinos does not impose a large number of requirements
  on member packages.  Rather, the Trilinos Framework provides suggested 
  practices that, with very few exceptions, are adopted by all packages.
  For example, packages are required to complete some sort of organized
  process prior to an external release (having a documented release
  process is a requirement that is imposed by powers above the Trilinos
  Framework).  The Trilinos Framework team has developed a checklist that
  packages can complete to satisfy this requirement; however, package teams
  are free to develop an alternative process.  At this time, every package
  uses the default release checklist, which saves developers the hassle of
  developing an individualized process and gives them a release process that
  has been hardened through process improvement based on feedback from
  member package teams.  Another suggested practice is running tests
  associated with a package before committing new code for that package to the 
  CVS repository.

  With some Trilinos team members concentrated on framework-level issues and
  valuable input from numerous Trilinos package developers, the Trilinos 
  Framework now provides many valuable services and suggested practices that
  are inexpensive for package teams to utilize and that have evolved over 
  time based on the experience of dozens of people.  

  The impact of the Trilinos Framework has spread beyond the boundaries of 
  the project.  The package website template and New Package are available 
  at the Trilinos website.  Other project teams at Sandia are also in various
  stages of adapting for their own project one or more of many Trilinos
  services, including the test harness, homepage, results webpage, 
  release checklists, or build system to meet their specific needs.
  
\subsection{Tight Collaboration}
%-------------------------------

CSE software, like most software, has grown in complexity in recent years.
The most interesting and challenging problems are generally not solved by an
individual or project team working in isolation.  Solid relationships with 
external and internal collaborators are essential.  It may even be the case
that an outside collaborator is a significant stakeholder in the project and 
whose requirements are of utmost importance.

But how do you gather the requirements of your stakeholders?  What happens
when they change?  Classical development models would prescribe a formal
requirements gathering process to set the direction of the project from the
outset.  From then on, all development has to be traceable back to the
requirements and any deviation from the requirements warrants a formal revision
of them.  

For many CSE projects, this is not a reasonable approach.  When your work, or 
the work of your stakeholders, is research-intensive or exploratory in nature, 
the problem may not be understood well enough at the outset of the project to 
make it worthwhile to define traditional formal requirements.  Requirements 
will likely change and evolve very quickly.  In such cases, attempting to
adhere to a classical development model becomes, instead of necessary
bookkeeping, an exercise in paper-generation.

How then to communicate effectively with your stakeholders?  Establish a
collaborative relationship with them.  Bring them into the workings of your
project.  This doesn't mean that they have to be concerned with the day to day
activities, but rather, use close collaboration to gather, implement,
integrate, and iterate on their requirements.  Proactively seek additional
input from stakeholders on a regular basis and keep them well informed.

Between packages, Trilinos takes advantage of close collaboration by 
establishing well-defined channels of communication.  Issue-tracking
software, mail lists, and regular meetings all give developers of one package
the means to communicate with other packages to coordinate important design
decisions.

Outside of the project, Trilinos maintains close relationships with its primary
stakeholders, some of whom have a developer working on both Trilinos and the
project in question.  This helps ensure the successful integration of Trilinos
into their codes.  It also provides an effective means of staying abreast of
the changing requirements of these external codes.  Close collaborations of
this nature help Trilinos prevent possible problems before they arise and also
help to steer the project in the right direction.

\subsection{Iterative Development}
%---------------------------------

(simplicity (KISS), YAGNY, organic growth, rapid prototyping)

Close collaborations facilitate the communication of design decisions, 
requirements, and countless other important bits of information, but the
ultimate goal of all this communication is to produce working code and the
longer development continues without being integrated and tested, the more
time will have to be sunk into the integration and debugging processes.  This
has led the Trilinos Project to strive for shorter iterations where possible.
%Trilinos tends to release every 6-9 months, so in the context of some 
%development paradigms, such as XP (cite), Trilinos iterations would not be
%considered short, but Trilinos tends to release more often than many of
%its customers and has shortened some iterations within the release cycle...
%not working now, try to revise later
This is a practice that is valuable in a number of areas, from design,
development, and debugging to building, testing, and integrating.  Below we
will discuss a number of tools that the Trilinos Project relies on to enable
these short iterations.

\subsection{Process Improvement}
%-------------------------------

Software is always a work in progress.  On any project there are things
being done well and things that need work.  One of the difficulties of 
software engineering or software project management is to take the realities
of a given project and mold them into a form that is in agreement with the
theories of accepted development models.  After realizing that a wholesale 
overhaul of an entire project to bring it into compliance with an accepted
model was infeasible, but also that acceptance of sub-optimal processes is
inefficient, the Trilinos Project adopted a model of process improvement by
which the processes that drive the project are always subject to ongoing,
incremental revision and and improvement.  We always keep our eyes open for the 
``low-hanging fruit,'' or those modifications to existing processes that are
likely to yield the most benefit at the least cost.

\clearpage

%== Tools =====================================================================

\section{Tools}
\label{Section:Tools}

We have laid out the goals for our project.  We have described a development
model to steer us towards those goals.  But all of that is just talk unless we
really make progress towards our ultimate goals.  The tools of a project are
where the rubber hits the road.  They have to be chosen carefully to serve the
needs of the project and to minimize overhead while producing the most benefit.
Here we'll discuss a number of different general classes of tools that we feel
a project should have and then discuss the particular tools we have chosen.

\subsection{Source Management}
%-----------------------------
One of the first steps that should be taken to improve software quality is the 
adoption of a version control system.  Trilinos source code is maintained in a 
Concurrent Versions System~\cite{CVS}
(CVS) repository.  Projects that already use CVS and are to be merged with 
another project can even retain their CVS history!

CVS has many useful features that are not discussed here.  For a more 
complete listing of CVS features and a description of valid CVS commands, 
see the GNU CVS Home Page~\cite{CVS}.  Those who still want more information 
might wish to obtain a copy of 
{\it Open Source Development with CVS}~\cite{FogelBarCVS}.

A CVS repository stores all of the information about current and past versions
of all of the files in a project.
Developers can ``checkout'' a snapshot of 
the repository, edit one or more files and then ``commit'' the changes to the
repository.  Complicated situations arise when multiple developers are 
editing the same files at the same time.  How these potential ``conflicts'' 
are resolved is beyond the scope of this document.  Suffice it to say that 
CVS handles all of the situations that it can.  When it cannot safely handle 
the situation, it provides a developer with a clear description of which 
lines of code are in conflict so that the developer can resolve the 
conflict more quickly.  The ability to checkout a snapshot of the 
repository from the past has many obvious advantages including making it easy 
to revert back to an old version of a piece of code that is found to be not 
portable to an important platform and making it possible to pinpoint the exact 
commit that caused an error.

Some of the most useful features of CVS include the fact that a CVS 
repository can be set up in such a way that it is accessible from anywhere, 
and the ability to create multiple ``branches'' of the same project.  For 
example, a development branch and multiple release branches would be 
appropriate for most software projects.  Patches that are applied 
to a release branch can be ``merged'' back into the development branch.  
In addition, security can be enforced in a fine-grained manner if necessary.  

Another endearing feature of CVS is that other software quality tools can 
interact seamlessly with CVS.  For example, CVS commit messages can be sent to
a Mailman mail list for distribution.  Also, Bonsai provides a convenient 
interface for accessing CVS information.  See section~\ref{subsect:Bonsai} 
for a thorough description about how the details of CVS commits are accessible 
via Bonsai.

% revise and add branch /tag info and more about release uses in general

The CVS history of a project can be made accessible via a
web-based interface program called Bonsai~\cite{Bonsai}.  This tool can be 
found on the web at 
\newline
\InlineDirectory{http://www.mozilla.org/bonsai.html}.
Bonsai gives developers the ability to view the changes made to the files in 
the repository. Developers can search 
based on filename, directory, branch, date, user who made the 
change, or any combination of these criteria.  The differences between any two 
versions of a file may also be viewed, which can be very helpful when 
debugging.  

Along with the results of a search, the CVS commit messages corresponding to 
the changes that match the query are also shown.  If any Bugzilla bug numbers 
were referenced in a commit message, the number of each bug is clickable.  
Clicking on a bug number will bring up the bug in question.

One very useful advanced feature that Bonsai provides is called ``blame''.  
Blame allows a developer to view the code within a file and see who was the 
last person to edit each line and which version of the file 
the most recent change to each line was made in.

Bonsai doesn't 
provide any capabilities that are not available via another method.  
Rather, Bonsai makes doing difficult things a lot easier.
For example, having the CVS commit message one click away from the line 
by line changes that
were made to a file can save a lot of time.  
The interface for Bonsai is very intuitive and can be learned in a matter of 
minutes.  The time spent learning how to use Bonsai will be more than made up 
for by using it to track and correct one bug.

\subsection{Communication Channels}
%----------------------------------

Mailman~\cite{Mailman} is an easy-to-use tool that helps to facilitate 
communication between
those involved with a project and to extend the usefulness of other 
software development tools.  It can be found on the web at 
\InlineDirectory{http://www.list.org}.  

A specific example of how Mailman 
has had a positive impact on the Trilinos project is that when a new person
joins the development team or becomes a user, that person is able to 
subscribe to the appropriate mail lists and is instantly involved in the 
conversations that take place.  The mail list archives are also searchable, 
which allows people new to Trilinos to catch up on interesting events from the 
past.  Obviously, the searchable archives are useful for new and existing 
developers, users and management.  The self-documenting feature provided 
by Mailman's searchable archives is also useful for creating artifacts for 
audits.  It creates a ``paper trail'' that tracks major decisions that were 
arrived at and closely follows 
the evolution of the entire project, especially when Mailman is used in 
conjunction with other tools such as CVS.

The Trilinos project maintains more than one hundred separate mail lists.  
Mail lists are maintained for Trilinos as a whole and for each 
package.  Each Trilinos 
package usually has five mailing lists.  The example mailing lists mentioned 
below are to be used for issues relating to all of Trilinos.  
The names for the lists pertaining to individual packages follow the same 
naming scheme, simply replace ``Trilinos'' with the name of the package.  For example, the list for Trilinos users is 
called Trilinos-Users and the email address is 
\InlineCommand{trilinos-users@software.sandia.gov}  The list 
for Epetra users is called Epetra-Users and the associated email address is 
\InlineCommand{epetra-users@software.sandia.gov}.  
The 
Trilinos development team has found the break down of lists that is outlined 
below to be very effective.

\begin{itemize}
\item Trilinos-Announce 
\InlineCommand{trilinos-announce@software.sandia.gov}

All Trilinos release announcements and other major news.  The appropriate 
audience for this list includes developers, users and management.

\item Trilinos-Checkins 
\InlineCommand{trilinos-checkins@software.sandia.gov}

CVS commit log messages that are related to Trilinos in general or packages 
that have not had separate lists established.  The appropriate audience for 
this list includes developers who are very closely involved with particular 
aspects of Trilinos development.  Those who are not as closely involved might 
choose to search the archives as necessary, rather than elect to receive 
each of the CVS commit log messages.

\item Trilinos-Developers 
\InlineCommand{trilinos-developers@software.sandia.gov}

All discussions related to Trilinos-specific development (not specific to a 
Trilinos package) are conducted via this list.  Important development 
decisions that originate in other places (regular email, discussions, etc) 
should also be posted to this list (or to the appropriate package list).  
By doing this, the list archive can provide records that explain why various 
changes were made over time.  As the name implies, the appropriate audience for
this list includes Trilinos developers.

\item Trilinos-regression 
\InlineCommand{trilinos-regression@software.sandia.gov}

All regression test output that is not specific to a package.  The appropriate 
audience for this list includes developers who are interested in the daily 
results of the Trilinos test harness.  In reality, few subscribe to this list.
When problems need to be tracked, the archive can provide all available 
information.  This list gathers the artifacts necessary to prove that 
regression testing takes place on a regular basis.

\item Trilinos-Users 
\InlineCommand{trilinos-users@software.sandia.gov}

List for Trilinos Users.  General discussions about the use of Trilinos.  In 
addition to users, developers also subscribe to this lists to answer user 
questions.

\item Trilinos-Leaders
\InlineCommand{trilinos-leaders@software.sandia.gov}

Mailing list for representatives for each Trilinos package.  There are no 
leaders lists for individual packages.  In addition to package leaders and 
interested developers, management will also want to subscribe to this list.
\end{itemize}

\subsection{Requirements \& Issue-Tracking}
%------------------------------------------

An important step in achieving a high level of software quality is tracking
and organizing issues pertaining to faults in the software and issues related 
to enhancement requests.  The Trilinos team has implemented a tool called 
Bugzilla~\cite{Bugzilla} to achieve this end.  Bugzilla  can be found 
on the web at \newline
\InlineDirectory{http://www.bugzilla.org}.

Issues tracked by Bugzilla can be searched by owner, platform, and many other 
criteria.  The 
interface for entering and searching for bugs is both user friendly and 
customizable.  Major pieces of a software project can be 
designated as ``products'', different aspects of those products can be 
listed as ``components'', and versions of the various products can also be 
entered.  This breakdown makes it easy to categorize and find issues in the 
Bugzilla database.  Issues can be assigned to any 
individual with a Bugzilla account.  If a 
person who is entering a bug report does not know who to assign the bug to,
the bug can be assigned to a default owner of the selected component 
by leaving the ``Assigned To'' field blank.  

When submitting an issue, a 
priority and severity of the bug can be selected (and later changed by the 
issue owner if desired).  Priority and severity are related, but certainly are 
not the same.  Priority refers to the order in which the issue should be 
resolved relative to other issues.  Severity refers to what degree the issue 
negatively affects the proper functions of the software.  Often there is a 
correlation between priority and severity; however, this does not have to be
the case.  For example, an issue that reports a build failure on a 
machine should be given a severity of ``blocker'' (the highest level of 
severity), but might be given a low priority because the build failure occurs
on a platform that is not supported.  Conversely an ``enhancement'' (the 
lowest severity level) might be a very high priority issue
~\cite{Bugzilla}.

In addition to the basic functionality described above, Bugzilla provides some 
useful advanced features.  The more advanced features include
granular security checking, the ability to integrate information with 
other software development tools including CVS, and inter-bug 
dependencies and dependency tracking~\cite{Bugzilla}.  Dependency tracking 
makes it easy to see the relationship 
between bugs.  The Trilinos team utilizes the concept of a metabug which 
is a larger task that is dependent on multiple smaller tasks.  Each of the 
smaller tasks can be assigned to different people. Metabugs make it is easy 
for project leaders (or management) to track the status of important issues. 
One very useful application of metabugs has been during the stabilization
period before a release.  We establish a hierarchy of bugs that includes
a framework metabug, framework issues, package metabugs, package issues,
and other categories of bugs.  
Each logical dependence is tracked.  By the time the framework metabug is 
closed, the release has been announced and the release tarball is available
on the website.  For a more complete graphical representation of this
hierarchy of bugs, please visit the Trilinos Developer website.  Using
Bugzilla in the fashion has produced a noticable improvement in the 
organization and efficiency of the Trilinos release process.

\subsection{Documentation}
% not a complete documentation solution

Doxygen~\cite{Doxygen} is a tool that can be used to create 
extensive documentation for a software project.  In a very short period of 
time, it is possible to take a well-commented piece 
of code and create nicely styled and easy to navigate documentation using 
Doxygen.  For information about how to use 
Doxygen, see the Doxygen 
web site at \InlineDirectory{http://www.doxygen.org}.  

Doxygen is meant to be used with C++, C, Java, and IDL, but can also be used 
in a more limited fashion to create documentation for code written in other
programming languages.  Doxygen documentation 
can be generated in several formats including HTML, \LaTeX, Rich Text Format 
(RTF is compatible Microsoft Word), PostScript, and
Unix man pages.  One of the most impressive features of Doxygen is its ability 
to generate dependency graphs, inheritance diagrams, and collaboration 
diagrams~\cite{Doxygen}.  Another impressive feature of Doxygen is that the 
documentation is very easy to navigate.  For a sample of how easily Doxygen 
documentation can be navigated go to
\newline
\InlineDirectory{http://software.sandia.gov/trilinos/packages/epetra}.  Then
click on \InlineDirectory{Documentation}, and then 
\InlineDirectory{Development Docs}. 
Throughout the documentation, the name of objects, 
the name of files, and line numbers within files are all clickable.

An example of one of the services provided by the Trilinos Framework is a
centralized Doxygen generation system.  By writing a few simple scripts, 
the Framework developers have simplified the task of keeping up-to-date
Doxygen documentation.  All a package needs to do then is to maintain the 
Doxygen markup in their code and keep a Doxygen configuration file in the
"doc" directory of the package's source tree.  The script then automatically
generates the documentation twice daily and publishes it on the website.  These
same scripts can be used to generate a package's Doxygen documentation (or all
of the Trilinos Doxygen documentation) locally, which allows for streamlined
iterative development of the documentation.

\subsection{Configuration Management}
% revisit all of this!

Achieving a high level of software quality is complicated when 
a software project is required to be portable to a wide array of platforms.
In the past, the Trilinos development team attempted to maintain a large 
number of platform specific makefiles to improve portability.  We have since 
moved to a build system based on  GNU Autoconf~\cite{Autoconf} and 
Automake~\cite{Automake}. 
For a complete description how to use Autoconf and Automake, see 
{\it GNU Autoconf, Automake, and Libtool}~\cite{GoatBook}, which is 
more commonly referred to as the ``Goat Book''.  (Libtool is the third tool 
in the set of three tools commonly referred to as the ``Autotools''.  Trilinos 
has chosen not to use Libtool.)

Unfortunately, Autoconf and Automake have not eliminated all portability 
problems for Trilinos.  We still have to provide a set of platform specific
``invoke-configure''scripts to feed to Autoconf.  In addition, the learning 
curve for Autoconf and Automake was quite steep.  Despite these facts, 
as a whole, the migration to Autoconf and Automake has been very 
beneficial.  

Of particular interest to CSE software developers is the fact that Autoconf 
provides a macro called F77\_FUNC that can be 
automatically defined during the configure stage to the proper Fortran
name mangling scheme for the platform that the configure script is run on.  
Knowing the Fortran name mangling scheme is necessary when calling routines 
from Fortran libraries such as the BLAS~\cite{BLAS1,BLAS2,BLAS3} and 
LAPACK~\cite{lapack} from a C or C++ library.  Aside from a few special cases, 
Autoconf is able to detect the proper name mangling scheme automatically.  
This eliminates the need for Trilinos packages to have ifdef's for every 
platform that doesn't use the most common scheme.

The configure script generated by Autoconf conducts many other configure 
time tests to determine various 
characteristics of the machine it is running on.  Additional tests can 
easily be written to test for other characteristics.  The results of these 
tests can then be used for various purposes, such as conditionally compiling 
a piece of code, or to define any number of macros.

Automake has greatly simplified the process of writing makefiles.  All a 
developer has to do is provide a few simple pieces of information, and 
Automake will generate another file called Makefile.in which is used to 
generate the appropriate Makefile during the configure stage.

As mentioned in Section~\ref{subsect:Framework} there exists a package called 
New Package that can be used to jump start an effort to set up a 
build system that uses Autoconf and Automake.  The effort was focused 
primarily on helping new packages join Trilinos, but the directions that 
New Package provides can be applied to more general cases as well.  Several
developers have successfully used New Package as a starting point for 
putting an additional
package into Trilinos.  It is possible to download New Package from the 
Trilinos web site.  The download page can be found at \newline 
\InlineDirectory{http://software.sandia.gov/trilinos/downloads.html}.  After
downloading new\_package, direct your attention to the README file.

Included with new\_package is a large set of M4~\cite{M4} macros that can 
be freely used by other projects.  These macros perform many common 
configuration tasks such as locating a valid LAPACK~\cite{lapack} library, 
or checking for additional values to prepend to CXXFLAGS that have been 
specified by a user.  The macros can be found in the \InlineDirectory{config}
subdirectory of the new\_package download.  These macros minimize the amount of
redundant effort in using Autoconf and make it easier to apply a common change 
to multiple projects.  The macros are meant to supplement the large number of 
M4 macros that come with Autoconf.  Additional M4 macros that are designed for 
specialized tasks are also available from various sites on the web.

No current tools make porting a trivial issue.  However, a 
configure and build system using Autoconf and Automake is a 
noticeable improvement over a more traditional system using simple makefiles.

\subsection{Website}
%-------------------

Quite obviously, a website can be a great way to publish a little bit about
your project and post various links and contact information.  But to take full
advantage of a project website, it is important to bring together the whole
range of resources related to the project.  Somebody should be able to start at
the front page of a project's site and, from there, learn everything there is
to know about the project or know exactly where to go for more information
(with a strong preference for the former).  This applies for both the user
and the developer use cases.  With the deluge of information we are faced with
today, people have come to rely on the internet so heavily that frequently
people will scarcely remember the answer to a question, but rather, will
remember where to go online to find it.  If they can't find it on your site,
they will either 1) waste precious time rediscovering known information, 2)
contact the project directly, which, for most inquiries, is inefficient and
potentially redundant, or 3) go without the information altogether.  Publish
the information once, in an organized, accessible manner and let the web server
do the work.

And more than just compiling a litany of links, the value of a project website
increases with number of tools it is able to successfully integrate.  Trilinos
has CVS+Bonsai source control, Mailman mail lists, Bugzilla issue tracking,
Doxygen documentation, Autotools-generated distribution tarballs, a nightly
test harness, and much more.  These tools are all quite valuable in their own
rite, but bring them together and they become even more powerful.

\subsection{Test Harness}
%------------------------

Few will argue the need for testing in the course of developing software.  As
with all things, it's quite a reasonable proposition in the simple case, but
becomes considerably more challenging as the problem scales.

\$ ./hello\_world.exe

\$ Hello, World!

That was easy enough wasn't it?  Consider it tested.  No need to write
extensive tests, automate, aggregate, report, or develop any kind of process,
system, or framework.  To do so would be overkill.  But now consider, much to
our hypothetical surprise and delight, our Hello World application has spread
like the plague.  Before we know it, we're adding functions, classes, modules,
extensions, APIs, are porting to every platform under the sun, and have grown
our development team by orders of magnitude.  Each step of the way, the
previous level of testing proves inadequate and we are forced to improve,
expand, or completely overhaul our testing methods.

Not surprisingly, this is how many projects, including Trilinos, have evolved
over their lifespan.  As Trilinos grew, the need for more testing
infrastructure grew.  Once it was no longer feasible to run tests manually,
a test harness was developed to automate the task of configuring, building, 
and testing the software.  This first version, a single Perl script, was a
boon, running nightly on a variety of machines and sending the results to the
appropriate regression mail lists.  Unfortunately, an actively developed
project is a moving target and value of the test harness diminished as the
project continued to grow.  Trilinos began to add more packages at various
stages of stability.  When a package would fail to configure or make, there
was no way for the test harness to recover and the rest of the packages went
untested.  The emails became difficult to sift through every day.  With these
concerns in mind, development of a second generation of the test harness began.
This version, another single Perl script, included the ability to recover from
configure or make failures by removing the offending package from configure
line and trying again until a working subset was reached and could be tested.  
This version also was more configurable, improved the format of the emails, and
generated a summary email for each run of the test harness on a given test
machine.

But again, the usefulness of the test harness shrank as the project grew.  The
emails became even more difficult to sift through as we tested on more
platforms.  There were instances of false positives and failures being
attributed to one package when caused by another.  There was no good way to
summarize the information.  The combination of all these factors caused the
daily emails to go all but ignored and the stability of the code base to 
degrade.  In addition, the method of designating tests, a relic of the original 
version, had petrified beyond reasonable usability.  In this context,
development of the third generation of the test harness began.  The design
was hashed out over months of formal and informal discussions and was iterated
upon as it was implemented.

This test harness that we use today is a collection of Perl scripts working
together to configure, build, and test Trilinos.  Each package now has a test
definition file where they can control the execution of all tests within their
package (a mechanism which is useful outside the nightly test harness runs
as well).  The results are saved in simple, parsable text files, which are
committed to a CVS repository on the web server.  There, they are parsed by
another Perl script and inserted into a MySQL database.  (If you think this
sounds round-a-bout, you're right.  This approach allows use an existing
channel to get data from computers on one network to the server on another
without incurring the wrath of the network security group.  It also has the
side-effect of creating another form of backup.)  At the same time every day,
a Perl script queries the database and generates one brief summary email for
every package.  A whole array of web pages were then developed that query the
database and display the results.

There are many great benefits to this approach.  Clearly, the emails have
become much more useful (since they're concise enough to actually look at) and
the method of specifying which tests to run has become considerably more usable.
Developers, without subscribing to dozens of mail lists, have access to all of
the information about test builds, not just those events directly concerning
their package.  Old results can be found without having to save thousands of
emails or dig through mail list archives for plain-text emails.  The data
is centrally located so there is never a problem with synchronicity or lost
emails.  Since the data is stored in a database, it can be extracted and
displayed in a variety of meaningful ways.  We can create lists, tables,
summaries, and charts of any subset of the data without having to restructure
the data itself in any way.  Specifically, the data can be observed and
summarized in the time dimension, something that was unthinkable before.  
Being online, one can now link to results and refernce others to a given piece
of information.  This adds another layer of integration among the suite of
online tools.  This approach is also much more modular and extensible.  We are
currently in the process of integrating coverage testing and plan to add 
memory checking and performance testing.  

\clearpage

%== Conclusion ================================================================

\section{Conclusion}
\label{Section:Conclusion}

Developing quality CSE software is tough.  Finding the time, energy, and
resources to improve the processes by which you develop it can be even tougher.
Often the biggest obstacle is the mere thought of the daunting task of getting
from where you are to where you should be.  But, through organic integration of
these simple, proven, freely-available tools and techniques, you can
incrementally improve the quality of your project's processes which will, in
turn, improve the quality of your software.

\clearpage

%== More Information ==========================================================

** From Jim's paper, revise, but this shows how to cite papers and prevents the
empty bib problem.

Those who are interested in learning more about the Trilinos project should 
consult {\it An Overview of Trilinos}~\cite{Trilinos-Overview} or the
{\it Trilinos Users Guide}~\cite{Trilinos-Users-Guide}.  Trilinos also has an 
extensive web site that can be found at \newline
\InlineDirectory{http://software.sandia.gov/trilinos}~\cite{Trilinos-home-page}.

\clearpage

%== Bibliography ==============================================================

\bibliographystyle{plain}
%\bibliography{SIAMnews}
\bibliography{../CommonFiles/TrilinosBibliography}
\addcontentsline{toc}{section}{References}

\end{document}

%## Notes #####################################################################

%== Outline ===================================================================

%I.    Introduction                                                                                
%      A.  Motivation (problem)
%      B.  Claim (proposed solution)
%      C.  Preview (teaser, road map)
%                                                                      
%II.   Body                                                                                
%      A.  Goals (problem)
%          1.  Quality
%          2.  Modularity
%          3.  Interoperability
%          4.  Scalability
%          5.  Efficient use of expert time
%          6.  Support                                                                                
%      B.  Development model (proposed solution)
%          1.  Tight collaboration
%          2.  Frequent iterations
%          3.  Quality control, process improvement
%          4.  Two-tiered organizational architecture
%              a.  Packages/modules
%                  1.  Small expert groups
%                  2.  Highly autonomous
%                  3.  Local authority
%              b.  Framework/project
%                  1.  Global "control"
%                  2.  Global "services"
%                  3.  Support filter, common front
%      C.  Tools (to support/enable proposed solution)
%          1.  version system
%          2.  mail lists
%          3.  bug-tracking
%          4.  website
%          5.  test harness
%                                                                                
%III.  Conclusion                                                                                
%      A.  Recapitulate problem
%      B.  Recapitulate solution
%      C.  Claim / action item / prediction (say *something*)

%== Titles ====================================================================

%Modern Software Development practices for CSE
%Impact of Modern Software Tools on CSE
%Exploring the Impact of Modern Development practices on CSE
%Examining the Impact of Modern Software Tools on CSE
%Assessing the Impact of Modern Software Tools on CSE
%Assessing the Impact of Tools and Processes on CSE Software Development
%Assessing the Impact of a Customized Development Processes on ...
%Outlining a Development Model for CSE Software
%Making the Case for Agile Models in CSE Software

%== Thesis ====================================================================

%== Ideas =====================================================================
