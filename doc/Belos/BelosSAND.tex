\documentclass[pdf,ps2pdf,11pt]{SANDreport}
\usepackage{pslatex}

%Local stuff
\usepackage{graphicx}
\usepackage{latexsym}
\input{rab_commands}

% If you want to relax some of the SAND98-0730 requirements, use the "relax"
% option. It adds spaces and boldface in the table of contents, and does not
% force the page layout sizes.
% e.g. \documentclass[relax,12pt]{SANDreport}
%
% You can also use the "strict" option, which applies even more of the
% SAND98-0730 guidelines. It gets rid of section numbers which are often
% useful; e.g. \documentclass[strict]{SANDreport}

% ---------------------------------------------------------------------------- %
%
% Set the title, author, and date
%

\title{
{\Huge\bf Belos}\\[1.5ex] The Trilinos package of next-generation
object-oriented iterative linear solvers }
\author{
Heidi Thornquist \\
Michael Heroux \\
Computational Math/Algorithms \\ \\
Roscoe Bartlett \\
Optimization/Uncertainty Estim \\ \\
Sandia National Laboratories\footnote{
Sandia is a multiprogram laboratory operated by Sandia Corporation, a
Lockheed-Martin Company, for the United States Department of Energy
under Contract DE-AC04-94AL85000.}, Albuquerque NM 87185 USA
}
\date{}

% ---------------------------------------------------------------------------- %
% Set some things we need for SAND reports. These are mandatory
%
\SANDnum{SAND2004-???}
\SANDprintDate{October 22,2004}
\SANDauthor{
Heidi Thornquist \\
Michael Heroux \\
Roscoe Bartlett
}

% ---------------------------------------------------------------------------- %
% The following definitions are optional. The values shown are the default
% ones provided by SANDreport.cls
%
\SANDreleaseType{Unlimited Release}
%\SANDreleaseType{Not approved for release outside Sandia}

% ---------------------------------------------------------------------------- %
% The following definition does not have a default value and will not
% print anything, if not defined
%
%\SANDsupersed{SAND1901-0001}{January 1901}

% ---------------------------------------------------------------------------- %
%
% Start the document
%
\begin{document}

\maketitle

% ------------------------------------------------------------------------ %
% An Abstract is required for SAND reports
%

%
\begin{abstract}
%
Belos first and foremost is a package that contains a standard set of
interfaces for next-generation iterative linear solvers in Trilinos.
These interfaces are based on TSFCore and lead to extremely efficient
and flexible iterative solver implementations.  In addition, the Belos
package has a collection of many different advanced ready to use block
and non-block Krylov iterative linear solvers such as block GMRES and
block CG as well as BiCG and BiCGStab.  It is also expected any new
general iterative solvers implemented to support the Belos interfaces
will also be added to the Belos package.
%
\end{abstract}
%

% ------------------------------------------------------------------------ %
% An Acknowledgement section is optional but important, if someone made
% contributions or helped beyond the normal part of a work assignment.
% Use \section* since we don't want it in the table of context
%
\clearpage
\section*{Acknowledgments}
We like everyone!

The format of this report is based on information found
in~\cite{Sand98-0730}.

% ------------------------------------------------------------------------ %
% The table of contents and list of figures and tables
% Comment out \listoffigures and \listoftables if there are no
% figures or tables. Make sure this starts on an odd numbered page
%
\clearpage
\tableofcontents
\listoffigures
%\listoftables

% ---------------------------------------------------------------------- %
% An optional preface or Foreword
%\clearpage
%\section{Preface}
%Although muggles usually have only limited experience with
%magic, and many even dispute its existence, it is worthwhile
%to be open minded and explore the possibilities.

% ---------------------------------------------------------------------- %
% An optional executive summary
%\clearpage
%\section{Summary}
%Once a certain level of mistrust and scepticism has
%been overcome, magic finds many uses in todays science
%and engineering. In this report we explain some of the
%fundamental spells and instruments of magic and wizardry. We
%then conclude with a few examples on how they can be used
%in daily activities at national Laboratories.

% ---------------------------------------------------------------------- %
% An optional glossary. We don't want it to be numbered
%\clearpage
%\section*{Nomenclature}
%\addcontentsline{toc}{section}{Nomenclature}
%\begin{itemize}
%\item[alohomora]
%spell to open locked doors and containers
%\end{itemize}

% ---------------------------------------------------------------------- %
% This is where the body of the report begins; usually with an Introduction
%
\SANDmain % Start the main part of the report

\section{Introduction}

Here we describe a set of object-oriented interfaces based on TSFCore
{}\cite{ref:TSFCore} for the development and use of preconditioned
iterative linear solvers for sets of of simultaneous block linear
equations of the form
%
\begin{equation}
A X = B
\label{belos:eqn:AX=B}
\end{equation}
%
{}\noindent{}where $A\in\RE^{n {}\times n}$ is a matrix operator,
$X\in\RE^{n {}\times m}$ is the solution multi-vector and $B\in\RE^{n
{}\times m}$ is the right-hand side multi-vector.  From here on, the
matrix $A$, which is a linear operator, will be referred to as ``the
operator'' to distinguish it from other linear operators.

Associated with every linear system of the form (\ref{belos:eqn:AX=B})
is an initial guess $X_0$ which in many cases will just be zero.

Typically, when an iterative solver is used, and if the operator is in
matrix coefficient form, then the system(s) are first scaled and then
a preconditioner is generated from the scaled operator.  This sequence
of activities is shown in the UML {}\cite{ref:booch_et_al_1999}
activity diagram in Figure
{}\ref{belos:fig:GeneralLinearSolveActivities}.

Note that similar activities are performed when a direct solver is
used.  The main difference, however, is that for a direct method
typically a complete sparse factorization is computed instead of just
perhaps an incomplete factorization as is commonly used to generate
preconditioners for iterative methods.  While we recognize these
similarities between direct and iterative solvers our discussion will
only focus on iterative solvers.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{GeneralLinearSolveActivities}
%}
\end{center}
\caption{
\label{belos:fig:GeneralLinearSolveActivities}
UML activity diagram : Common activities
performed in solving a linear system using an iterative method.}
\end{figure}
\esinglespace}

In many cases, the first activity after the matrix $A$ is generated is
the computation of diagonal scaling matrices $S_L$ and $S_R$ and then
a scaled matrix $\tilde{A}$ is formed as
%
\begin{equation}
S_L A S_R \Rightarrow \tilde{A}.
\label{belos:eqn:A_tilde}
\end{equation}
%
These scalings transform the system in ({}\ref{belos:eqn:AX=B}) into
%
\[
\underbrace{S_L A S_R}_{\displaystyle{\tilde{A}}}
\underbrace{S_R^{-1} X}_{\displaystyle{\tilde{X}}}
=
\underbrace{S_L B}_{\displaystyle{\tilde{B}}}
\]
%
\begin{equation}
\nonumber \\
\tilde{A} \tilde{X}  = \tilde{B}.
\label{belos:eqn:ScaledSystem}
\end{equation}
%
After the operator matrix $A$ is scaled to form $\tilde{A}$, left
and/or right preconditioners $P_L$ and $P_R$ are typically formed
which transform the system ({}\ref{belos:eqn:ScaledSystem}) into
%
\[
\underbrace{P_L \tilde{A} P_R}_{\displaystyle{\hat{A}}}
\underbrace{P_R^{-1} \tilde{X}}_{\displaystyle{\hat{X}}}
=
\underbrace{P_L \tilde{B}}_{\displaystyle{\hat{B}}}
\]
%
\begin{equation}
\nonumber \\
\hat{A} \hat{X}  = \hat{B}.
\label{belos:eqn:PreconditionedSystem}
\end{equation}
%
If scaling is not first performed then the preconditioners $P_L$ and
$P_R$ are formed from the unscaled operator $A$.  The operator
$\hat{A} = P_L \tilde{A} P_R$.  will be refereed to as the
{}\textit{composite} operator.

In order to use the scaled preconditioned operator $\hat{A}$, the the
original right-hand side(s) $B$ must be transformed as
%
\begin{equation}
\hat{B} = P_L S_L B \in \RE^{n \times m}
\label{B-preprocess}
\end{equation}
%
{}\noindent{}before the iterative solve is performed.

Note that a transformation of an initial guess $X_0$ to form an
initial guess $\hat{X}_0$ is not necessary since most iterative
methods just need the initial residual
%
\begin{eqnarray}
\hat{R}_0
& = & \hat{A} \hat{X}_0 - \hat{B}
\nonumber \\
& = & \left( P_L \tilde{A} P_R \right) \left( P_R^{-1} S_R^{-1} X_0 \right) - \hat{B}
\nonumber \\
& = & P_L \tilde{A} S_R^{-1} X_o - \hat{B}
\label{belos:eqn:R_hat_0}
\end{eqnarray}
%
{}\noindent{}which just requires a simple inverse diagonal scaling
with $S_R$ followed by an application of the matrix operator
$\tilde{A}$ and the left preconditioner $P_L$.

Once a system is solved for $\hat{X}$, the unscaled unpreconditioned
solution is easily recovered as
%
\begin{equation}
X = S_R P_R \hat{X} \in \RE^{n \times m}.
\label{X-postprocess}
\end{equation}
%
{}\noindent{}The details on how this solution multi-vector $X$ is
recovered will vary based on the specific type of concrete
{}\textit{concrete iterative linear solver} being used (for example,
GMRES and BiCGStab will handle this differently).

The software described here is designed to accept the operators
$\tilde{A}\in\RE^{n \times n}$, $P_L\in\RE^{n \times n}$,
$P_R\in\RE^{n \times n}$, the scaling vectors $s_L\in\RE^{n}$,
$s_R\in\RE^{n}$ (which form the diagonals of $S_L\in\RE^{n
\times n}$ and $S_R\in\RE^{n \times n}$) and the original
LHS $X$ and RHS $B$ multi-vectors.  Once the linear system is
constructed, this software can then invoke an iterative method to
attempt to solve the resulting linear system(s).  Since preprocessing
of the RHS $B$ before the solution (as in (\ref{B-preprocess})) and
post-processing of the LHS $X$ after the solution (as in
(\ref{X-postprocess})) are so common, these activities are performed
by a common set of software that all iterative linear solvers use (see
the {}\texttt{Linear\-Problem} classes below).

%
\section{Basics of block iterative solvers}
\label{sec:basic-block-solves}
%

In this sections we describe some basic mathematical quantities that
are associated with a block iterative solver such as block GMRES or
block CG.  When a block solver is used to solve a multiple set of
equations as in (\ref{belos:eqn:AX=B}), typically smaller sub-blocks
of equations are solved seperately in order to balance memory movement
efficiency and total memory usage.  For example, if $m=100$ sets of
equations are to be solved, a block size of $b=20$ may be used to
solve the block system in (\ref{belos:eqn:AX=B}) in $m/b = 100/20 = 5$
separate iterative runs.  However, there may be situations where $m <
b$ in which case a set of $m-b$ artificial augmented systems are
solved along with the $m$ systems.  Augmenting the set of linear
systems can reduce the number of iterations needed for certain block
iterative solvers [???].

Here we state in more precise mathematical terms what multi-vector
quantities that a block iterative solver maintains.  It is important
to define these quantities carefully since they can be used to
determine convergence of the iterative method.  When a new block of
systems is setup to be solved, the current unscaled unpreconditioned
RHS $\bar{B}$ and the current starting initial guess $\bar{X}_0$ are
defined either as
%
\begin{eqnarray}
\bar{X}_0 & = & (X_0)_{(:,k+1:k+b)} \in \RE^{n \times b} \label{X_bar_r_b} \\
\bar{B}   & = & (B)_{(:,k+1:k+b)} \in \RE^{n \times b} \label{B_bar_r_b}
\end{eqnarray}
%
{}\noindent{}for the case $k+b {}\leq m$, where $k\in[0,m-1]$ is the
current offset for the linear systems to solved, or as
%
\begin{eqnarray}
\bar{X}_0 & = & {\bmat{cc} (X_0)_{(:,k+1:m)} & 0 \emat} \in \RE^{n \times b} \label{X_bar_m} \\
\bar{B}   & = & {\bmat{cc} (B)_{(:,k+1:m)} & \bar{V} \emat} \in \RE^{n \times b} \label{B_bar_m}
\end{eqnarray}
%
{}\noindent{}for the case $k+b > m$, where $0\in\RE^{(n) {}\times
(m-(k+b))}$ is a multi-vector of zeros and $\bar{V}\in\RE^{(n) {}\times
(m-(k+b))}$ is some (usually random) well-scaled multi-vector.  In
(\ref{X_bar_m})--(\ref{B_bar_m}), the block of linear systems are
argumented with $m-(k+b)$ artificial systems in order to attempt to
reduce the number of iterations while achieving good memory movement.

Once the iterative solve is started, restarts may be performed and
linear systems may be removed (or deflated) as they converge thereby
reducing the block size to $\bar{b} < b$.  We now define the mapping
matrix $\bar{Q}\in\RE^{m {}\times {}\bar{m}}$ (where $\bar{m} {}\leq
\bar{b}$) to select the columns in $B$ and $X$ for the linear systems
currently being solved which defines the current quantities:

\begin{itemize}

{}\item $R_0 = A X_0 - B {}\in\RE^{n {}\times m}$ : The full unscaled
unpreconditioned residual multi-vector with respect to full initial
guess $X_0$ and right-hand side $B$.

{}\item $\bar{B}={\bmat{cc} B \bar{Q} & \bar{V} \emat}\in\RE^{n
{}\times \bar{b}}$ : The current unscaled unpreconditioned (augmented
if $k+b > m$) right-hand side mulit-vector (where $\bar{V}=\emptyset$
if $k+b {}\leq m$ or is some well-conditioned mulit-vector
$\bar{V}\in\RE^{n {}\times m-(k+\bar{m})}$ if $k+b > m$).

{}\item $\breve{B} = P_L S_L \bar{B}$ : The current scaled
preconditioned right-hand side mulit-vector.

{}\item $\bar{X}_0={\bmat{cc} X_0 \bar{Q} & 0 \emat}\in\RE^{n {}\times
{}\bar{b}}$ : The current (augmented if $k+b > m$) starting initial
guess for the unscaled unpreconditioned solution associated with
$\bar{B}$ (where $0=\emptyset$ if $k+b {}\leq m$ or $0\in\RE^{n
{}\times m-(k+\bar{m})}$ if $k+b > m$).

{}\item $\breve{X} = S_R P_R \bar{X}_0$ : The current starting initial
guess for the scaled preconditioned solution.

{}\item $\bar{R}_0 = A \bar{X}_0 - \bar{B} {}\in\RE^{n {}\times
{}\bar{b}}$ : The current staring initial unscaled unpreconditioned
residual multi-vector with respect to current starting initial guess
$\bar{X}_0$.

{}\item $\breve{R}_0 = A \breve{X}_0 - \breve{B} = P_L S_L \bar{R}_0$
: The current staring initial scaled preconditioned residual
multi-vector.

{}\item $\bar{X}_{0,r}\in\RE^{n {}\times {}\bar{b}}$ : The current
initial guess for the unscaled unpreconditioned solution associated
with $\bar{B}$ for the current restart (i.e.~$\bar{X}_{0,r} {}\neq
\bar{X}_0$ after the first restart).

{}\item $\bar{X}\in\RE^{n {}\times {}\bar{b}}$ : The current
approximate left-hand-side unscaled unpreconditioned solution
associated for the current restart.

{}\item $\breve{X} = S_R P_R \bar{X}$ : The current approximate
left-hand-side scaled preconditioned solution associated with
$\breve{B}$ for the current restart.

{}\item $\breve{Z}\in\RE^{n {}\times {}\bar{b}}$ : The unscaled
unpreconditioned update multi-vector defining $\bar{X} = \bar{X}_{0,r}
+ S_R P_R {}\breve{Z}$ which is computed directly in many cases by the
iterative solver (i.e.~GMRES).  Note that $\breve{Z}$ is defined as
the update from the guess for the most recent restart $\bar{X}_{0,r}$
and not from the starting inital guess $\bar{X}_0$.

{}\item $\bar{R} = A \bar{X} - \bar{B} {}\in\RE^{n {}\times
{}\bar{b}}$ : The current unscaled unpreconditioned residual
multi-vector with respect to $\bar{X}$ and $\bar{B}$.

{}\item $\breve{R} = \hat{A} \breve{X} - \breve{B} = P_L S_L \bar{R}$
: The current scaled preconditioned residual multi-vector with respect
to $\breve{X}$ and $\breve{B}$.

\end{itemize}

The unscaled unpreconditioned multi-vector quantities $\bar{B}$,
$\bar{R}_0$, $\bar{R}$ and $\bar{X}$ are defined for every block
iterative solver method and should be accessible for the definition of
convergence (i.e.~status) tests.  In all of the iterative linear
solvers these quantities can be viewed as derived attributes of the
state of the iterative solver and while these quantities may require
extra computation this does not change whether or not they are
computable for all iterative solvers.  In all of the iterative solvers
it will be clear what quantities are immediately available and what
quantities will require extra computation.

The scaled preconditioned multi-vector quantities $\breve{R}$,
$\breve{X}$ and/or $\breve{Z}$ would be dealt with by a concrete
iterative linear solver that did not want to be concerned about what
type of scaling and/or preconditioning was being used but instead just
cared about the composite operator.

Every iterative solver method can cheaply define at least some native
relative residual error.  This native relative residual error will
come in one of two forms.  Either the relative norms will be based on
the scaled unpreconditioned residuals
%
\begin{equation}
n_j = ||S_L \bar{R}_{(:,j)}|| / ||S_L (\bar{R}_0)_{(:,j)}||, \; \mbox{for} j = 1 \ldots \bar{b}
\label{belos:eqn:scaled_unprec_rel_norms}
\end{equation}
%
in the case of a standard CG algorithm where the preconditioner was
used to define the scalar product for instance, or will be based on
scaled preconditioned residuals
%
\begin{equation}
n_j = ||\breve{R}_{(:,j)}|| / ||(\breve{R}_0)_{(:,j)}||, \; \mbox{for} j = 1 \ldots \bar{b}
\label{belos:eqn:scaled_prec_rel_norms}
\end{equation}
%
in the case of GMRES, BiCGStab and others that only care about the
composite operator.  Here the norm $||.||$ will be defined to be the
natural norm of the vector spaces involved (i.e.~$||x|| =
{}\sqrt{<x,x>}$ where $<.,.>$ is the defined scalar product of the
vector space involved).

%
\section{Basic interfaces for iterative linear solvers}
%

Here we describe the basic interfaces to iterative linear solvers
given that the operator, scalings and preconditioner objects, along
with the RHS and LHS multi-vector objects, are already formed.

%
\subsection{Requirements for basic interfaces to iterative solvers}
\label{sec:requirements}
%

Before describing the requirements of the linear solvers, a few
definitions are needed to identify two types of software and therefore
two types of software developers:

\begin{itemize}

\item{}\textit{Client} :
An external entity that requires the services of an iterative linear
solver (such as a nonlinear ANA).  Such a client will assume to have
already generated the operator, appropriate scalings and/or
preconditioners for the operator at hand and will have already
generated the RHS and initial LHS multi-vectors (or single vectors)
that define the linear system.  All of these objects shall be
represented using basic TSFCore interfaces.  In addition, the
{}\textit{client} shall be able to define arbitrary convergence
criteria.  Such convergence criteria will be referred to as
{}\textit{status tests}.

\item{}\textit{Concrete iterative linear solver} : 
An implementation of a (Krylov) iterative linear equation solver such
as GMRES.  Such an implementation may be a true block RHS solver or
just a single-RHS solver.

\end{itemize}

Figure {}\ref{belos:fig:BelosUseCases} shows the basic use cases for
solving a set of equations using these iterative linear solvers.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{BelosUseCases}
%}
\end{center}
\caption{
\label{belos:fig:BelosUseCases}
UML use-case diagram : Basic use cases
for {}\textit{clients} and {}\textit{concrete iterative linear solver}.}
\end{figure}
\esinglespace}

Some more specific requirements related to the use cases shown in
Figure {}\ref{belos:fig:BelosUseCases} for of above defined
{}\textit{client} and {}\textit{concrete iterative linear solver}
software are given below:

\begin{enumerate}

\item

A {}\textit{client} should be able to setup and solve a linear system
without knowing the concrete type of iterative linear solver being
used.  {}\textit{Justification:} This is the main -- if not the entire
-- point of this whole design.  {}\textit{Importance:} Fundamental.

\item

The implemented algorithms should be near optimal in storage and CPU
time.  {}\textit{Justification:} An algorithm coded by hand in Fortran
77 should not be significantly more efficient any way which is
critical for scientific computing.  {}\textit{Importance:}
Fundamental.

\item

The linear solvers should accept objects only through the basic
TSFCore linear operator, vector, multi-vector and vector space
interfaces.  {}\textit{Justification:} Automatic interoperability
between different types of ANAs requires this.  {}\textit{Importance:}
Fundamental.

\item

The linear solvers should use the definition of the scalar product
defined by the vector spaces defined by the operators in the linear
problem.  This means that the scalar product $<x,u>$ defined by the
vector space for $x$ and $u$ must be used and not just simply the dot
product $x^T u$.  This also means using the definition of the natural
norm $||x|| = {}\sqrt{<x,x>}$ as defined by the scalar product $<x,x>$
and just simply the Euclidean norm $||x||_2 = \sqrt{x^T x>}$.
{}\textit{Justification:} For some types of applications the
definition of the scalar product can have a dramatic impact on
improving the performance of an iterative method.  While in theory
these scalar products can also be represented as operators that can be
aggregated with the other preconditioners, in practice it is much more
convienent to only require the accumulation of the scalar product
itself.  {}\textit{Importance:} Fundamental.

\item

These interfaces should be general and efficient for both true block
RHS and single RHS iterative linear solvers.
{}\textit{Justification:} While block iterative linear solvers are
very important, many different uses of iterative solvers only require
or can only exploit linear solves for single RHSs.  For example, a
basic Newton method can only solve linear systems one RHS at a time.
In addition, we want to encourage the development of single-RHS
iterative methods in this framework, not discourage it by requiring
that all {}\textit{concrete iterative linear solvers} be true block
solvers.  {}\textit{Importance:} Fundamental.

\item

These interfaces should support left and/or right preconditioners.
{}\textit{Importance:} Fundamental.

\item

The interfaces should support {}\textit{concrete iterative linear
solvers} that do not require adjoints and those that do (only for
operators that support adjoints of course).  {}\textit{Importance:}
Fundamental.

\item

Interfaces and utilities should, when possible, insulate
{}\textit{concrete iterative linear solver} away from details of
whether left and/or right preconditioning is being used when applying
the composite operator but also allow this information to be known,
and access to constituent operators should be provided if desired.
{}\textit{Justification:} Most iterative solver algorithms only care
about the composite operator and need not be bothered with
preconditioners but others do like flexible GMRES which needs to apply
the right preconditioner separately from the left preconditioner and
operator itself.  CG is another example where the preconditioner can
be treated in a special way (i.e.~to define a new definition of the
scalar product). {}\textit{Importance:} Desired.

\item

For the {}\textit{client's} and the {}\textit{concrete iterative
linear solver's} benefit, default handling of standard pre- and
post-processing of RHS and LHS associated with left and/or right
scaling and left and/or right preconditioning should be provided.
{}\textit{Justification:} It seems reasonable to collect this commonly
needed functionality in one standard place so that different
{}\textit{concrete iterative linear solvers} do not need to rewrite
this code over and over again.  {}\textit{Importance:} Desired.

\item

These interfaces should be minimal but sufficient for
{}\textit{clients} of iterative solvers and {}\textit{concrete
iterative linear solvers}.  {}\textit{Justification:} This is a basic
principle of good object-oriented software design.
{}\textit{Importance:} Desired.

\item

Allow for flexible and powerful status (i.e.~convergence) tests that
can be provided by the {}\textit{client} and are independent from the
{}\textit{concrete iterative linear solver}.  Cheap native norm-based
or iteration count-based status tests should be automatically
available but more expensive status tests based on the unscaled,
unpreconditioned solutions and residuals should also be supported.
{}\textit{Justification:} One reason that some iterative linear solver
algorithms are constantly rewritten over and over again is to
accommodate different convergence criteria.  By separating the
convergence criteria from {}\textit{concrete iterative linear solver},
these solver implementations become much more reusable.
{}\textit{Importance:} Fundamental.

\item

Expanding on the above requirement, every {}\textit{concrete iterative
iterative solver} must provide a cheap estimate of the relative
unpreconditioned or preconditioned residual error as defined in either
(\ref{belos:eqn:scaled_unprec_rel_norms}) or
(\ref{belos:eqn:scaled_prec_rel_norms}).  In addition a
{}\textit{concrete iterative linear solver} will identify the exact
nature of this residual.  {}\textit{Justification:} Most iterative
solver algorithms maintain the preconditioned residual $\P_L S_L
{}\bar{R}$ itself while, on the other hand, GMRES can cheaply maintain
its norm.  CG will maintian the scaled but unpreconditioned residual
$S_L {}\bar{R}$.  Providing such a well defined relative residual
error to status tests (i.e.~{}\textit{clients}) is critical in many
applications in order to ensure certain numerical properties of an
algorithm.  {}\textit{Importance:} Fundamental.

\item

Status tests should allow for dynamic (i.e.~during an iteration run)
deflation (i.e.~the removal of individual RHS and LHS vectors for
systems that are converged) but an {}\textit{concrete iterative linear
solver} should be free to keep such tagged linear systems in the
current set.  {}\textit{Justification:} Some block iterative solvers,
such as block CG, can effectively remove individual RHSs as they
converge thereby reducing the cost of block solves in some cases
(especially when some RHSs have tighter tolerances than others).
Without the functionality of deflation, a block iterative solver may
result in more work than a single RHS linear solver in some extreme
cases (e.g.~two linear systems that have radically different
convergence criteria).  {}\textit{Importance:} Fundamental.

\item

Status tests should be alerted when a new iterative run (on one or
more simultaneous RHSs) is started.  {}\textit{Justification:}
Alerting a status test when a new iterative run is started allows a
simplification of the design of status tests.  {}\textit{Importance:}
Desired.

\item

Multiple independent status tests should be allowed and the overall
efficiency of these independent status tests should be very close to
the performance were the status tests to be composite in more careful
manner.  {}\textit{Justification:} More than one status test may
require the current unscaled unpreconditioned solution $\bar{X}$
and/or the unscaled unpreconditioned residual $\bar{R}$ and these
quantities should not have to be recomputed from scratch by different
independent status tests.  {}\textit{Importance:} Fundamental.

\item

Specialized status tests for specific types of iterative solvers
should be allowed.  {}\textit{Justification:} Very specialized status
tests can be based on things like estimates of the eigenvalues of a
matrix that is generated from information being accumulated during an
iterative solve (i.e.~from the Krylov subspace).  {}\textit{Importance:} Fundamental.

\item

These interfaces should be designed and partitioned so as to minimize
opportunities for mistakes by developers of {}\textit{client} and
{}\textit{concrete iterative linear solver} software.
{}\textit{Justification:} It is a good object-oriented design
principle to design, develop and deploy interfaces that are designed
for specific types of clients and use cases.  Such designs result in
smaller easier to understand interfaces, minimize misuse of the
interfaces and simplify maintenance (i.e.~changes in requirements
resulting in changes to software).  {}\textit{Importance:} Desired.

\end{enumerate}

\subsection{Basic interfaces for object-oriented iterative linear solvers}

\subsubsection{High-level model}

Figure {}\ref{belos:fig:BelosInterfacesSimple} shows a high-level
object-oriented model for the basic interfaces to iterative linear
solvers.  All of the UML classes shown in this diagram do not map
directly into C++ classes but this simple model will help to describe
the major features of the design and how this design meets several of
the requirements described above.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{BelosInterfacesSimple}
%}
\end{center}
\caption{
\label{belos:fig:BelosInterfacesSimple}
UML class diagram : High-level model of
the most basic interfaces for iterative linear solvers.}
\end{figure}
\esinglespace}

The roles of each of the high-level classes shown in Figure
{}\ref{belos:fig:BelosInterfacesSimple} is now described.

\begin{itemize}

\item{}\texttt{Client}:
The {}\textit{client} (as defined above in Section
{}\ref{sec:requirements}) shown in the UML diagram represents some
external piece of software that requires the services of an iterative
linear solver (such as a nonlinear ANA).  The client has direct
relationships with many of the other classes in the diagram as
depicted through the dotted lines (which represent dependency
relationships in UML).

\item{}\texttt{TSFCore::LinearOp}:
This class is used to abstract the linear operator for $\tilde{A}$ and
the optional left and right preconditioners $P_L$ and $P_R$
respectively.

\item{}\texttt{TSFCore::Vector}:
While not shown in the UML diagram, this class is used to abstract the
left and right scaling vectors $s_R$ and $s_L$ respectively.

\item{}\texttt{TSFCore::MultiVector}:
This class is used to abstract the multi-vector objects for the
multiple-RHS $B$ and the multiple-LHS solution $X$.

\item{}\texttt{Belos::BasicIteration}:
This is the base interface class for all iterative linear solvers.
This class serves in two roles.  In its first role this interface
decouples concrete {}\textit{concrete iterative linear solver} from
{}\textit{client} software and is the basic mechanism for delivering a
linear problem to be solved and for invoking the iterative solver.
The second role of this interface is to present basic information
about the progress of the iteration to a {}\texttt{Status\-Test}
object (described below).  Because of these two roles, this class is
broken up into two interfaces in the actual C++ interface classes
({}\texttt{Basic\-Iteration} and {}\texttt{Basic\-Iteration\-State}).

\item{}\texttt{IterativeSolverImplemenation}:
This is a place holder for any particular {}\textit{concrete iterative
linear solver} such as block or non-block GMRES or block or non-block
CG.

\item{}\texttt{Belos::LinearProblem}:
This class serves in several related roles.  In its first role, the
{}\texttt{Linear\-Problem} object serves as a convenient common
aggregation of the operators, the scaling vectors and the RHS and LHS
multi-vector objects.  It is a {}\texttt{Linear\-Problem} that is
passed to a {}\texttt{Basic\-Iteration} object in order to solve a set
of linear systems.  In its second role, the {}\texttt{Linear\-Problem}
object provides basic services such as preprocessing the RHS and
post-processing the LHS for the {}\texttt{Basic\-Iteration} subclass
{}\texttt{Concrete\-Iterative\-Linear\-Solver}.  The third role that
{}\texttt{Linear\-Problem} serves is as an interface that a
{}\texttt{Status\-Test} object can query to get unscaled
unpreconditioned residuals and other information if so desired.  This
concept of a {}\texttt{Linear\-Problem} class is broken up into three
interfaces that are customized for these three different roles
({}\texttt{Linear\-Problem\-Setup},
{}\texttt{Linear\-Problem\-Iteration} and
{}\texttt{Linear\-Problem\-State}).

\item{}\texttt{StatusTest}:
This abstract interface class decouples {}\textit{concrete iterative
linear solvers} away for specific types of status (convergence) tests.
This allows a {}\textit{concrete iterative linear solver} to focus on
its basic iteration, without having to worry about when to stop
(i.e.~converge).  A single {}\texttt{Status\-Test} object is
associated with a a single {}\texttt{Linear\-Problem} object and this
{}\texttt{Status\-Test} object may know specific convergence test for
individual RHSs in $B$ which forms the set of linear equations.

\item{}\texttt{MySpecializedStatusTest}:
This class is a place-holder for any particular concrete
{}\texttt{Status\-Test} subclass.  The {}\textit{client} knows about
the concrete type of this object but the {}\textit{concrete iterative
linear solver} does not (because it is abstracted through the
{}\texttt{StatusTest} interface).  While most concrete
{}\texttt{StatusTest} subclasses can get everything they need from the
{}\texttt{Basic\-Iteration} and {}\texttt{Linear\-Problem} interfaces
about the state of the iterative solver, this particular subclass
{}\texttt{My\-Specialized\-Status\-Test} shows that it has a
dependency on the the concrete
{}\texttt{Concrete\-Iterative\-Linear\-Solver} subclass so as to take
advantage of some more specialized specific information about the
iteration.  Access to this derived type is accomplished through a
dynamic cast when needed.  However, in most cases, dynamic casting
should not be necessary.

\end{itemize}


\subsubsection{Design-level model}

Now that the basic object model for these interfaces has been
described we now show a more detailed design-level model where all the
UML classes map directly to actual C++ classes.  The basic
design-level model of the interfaces for iterative linear solvers is
shown in Figure {}\ref{belos:fig:BelosInterfacesHarder}.  A more
detailed model showing member functions and more relationships is
shown in Figture {}\ref{belos:fig:BelosInterfaces}.



{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{BelosInterfacesHarder}
%}
\end{center}
\caption{
\label{belos:fig:BelosInterfacesHarder}
UML class diagram : Design-level model
for the most basic interfaces for iterative linear solvers.}
\end{figure}
\esinglespace}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[scale=0.72]{BelosInterfaces}
%}
\end{center}
\caption{
\label{belos:fig:BelosInterfaces}
UML class diagram : Detailed design-level model for the most basic
interfaces for iterative linear solvers.}
\end{figure}
\esinglespace}

\subsubsection{Use case descriptions}

We now describe how the interfaces and various classes in Figure
{}\ref{belos:fig:BelosInterfaces} work in the context of the use cases
shown in Figure {}\ref{belos:fig:BelosUseCases}.  For each of these
use cases, we describe what classes and interfaces are involved and
how they collaborate together in order to implement the use case.

The use case descriptions will involve collaborations with the
following objects in pseudo-code:

\begin{tabular}{lll}
{\small\texttt{TSFCore::LinearOpHandle<Scalar>}} & {\small\texttt{A}} & : Unscaled operator $A$ \\
{\small\texttt{TSFCore::LinearOpHandle<Scalar>}} & {\small\texttt{A\_tilde}} & : Scaled operator $\tilde{A}$ \\
{\small\texttt{TSFCore::LinearOpHandle<Scalar>}} & {\small\texttt{P\_L}} & : Left preconditioner $P_L$ \\
{\small\texttt{TSFCore::LinearOpHandle<Scalar>}} & {\small\texttt{P\_R}} & : Right preconditioner $P_R$ \\
{\small\texttt{RefCountPtr<const TSFCore::Vector<Scalar> >}} & {\small\texttt{s\_R}} & : Left scaling vector $s_L$ \\
{\small\texttt{RefCountPtr<const TSFCore::Vector<Scalar> >}} & {\small\texttt{s\_R}} & : Right scaling vector $s_R$ \\
{\small\texttt{RefCountPtr<const TSFCore::MultiVector<Scalar> >}} & {\small\texttt{B}} & : RHS $B$ \\
{\small\texttt{RefCountPtr<TSFCore::MultiVector<Scalar> >}} & {\small\texttt{X}} & : RHS $X$ \\
{\small\texttt{RefCountPtr<StatusTest<Scalar> >}} & {\small\texttt{st}} & : A concrete status test object  \\
{\small\texttt{RefCountPtr<LinearProblemSetup<Scalar> >}} & {\small\texttt{lpup}} & : ``Setup'' interface to {}\texttt{lp} \\
{\small\texttt{RefCountPtr<LinearProblemIteration<Scalar> >}} & {\small\texttt{lpi}} & : ``Iteration'' interface to  {}\texttt{lp} \\
{\small\texttt{RefCountPtr<LinearProblemState<Scalar> >}} & {\small\texttt{lps}} & : Status test interface to  {}\texttt{lp} \\
{\small\texttt{RefCountPtr<BasicIteration<Scalar> >}} & {\small\texttt{bi}} & : A basic iteration object
\end{tabular}

Note that {}\texttt{TSFCore::\-Linear\-Op\-Handle} is a small simple
concrete class whose only purpose for existence is to aggregate a
smart pointer to a {}\texttt{TSFCore::\-Linear\-Op} object and its
``mathematical'' definition of the nontranposed operator which is
stored as a {}\texttt{TSFCore::\-ETransp} enum object.

Most of these use cases do not involve very interesting dynamic
behavior but some do.  An overall UML diagram encompassing most of
these use cases into a single combined UML sequence diagram is shown
in Figure {}\ref{belos:fig:BelosSequence}.  The specific use cases
that are part of the scenario shown in Figure
{}\ref{belos:fig:BelosSequence} are described in more detail below as
well as variations on each of these use cases.

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{BelosSequence}
%}
\end{center}
\caption{
\label{belos:fig:BelosSequence}
UML sequence diagram : An example
scenario of an iterative block solver solving a set of right-hand
sides.}
\end{figure}
\esinglespace}

The first set of use cases involve the basic interactions of the
{}\textit{client} while the second set involve the interactions of the
{}\textit{concrete iterative linear solver}.

\subsubsection*{Use cases involving the {}\textit{client}}

\begin{enumerate}

\item Use case : \textbf{Setup linear problem}

{}\noindent{}Classes/interfaces involved : {}\texttt{Client},
{}\texttt{Linear\-Problem\-Setup}

This use case is very simple as it just involves the {}\texttt{Client}
setting up a {}\texttt{Linear\-Problem\-Setup} object with the
definition of the linear system.  This use case is not shown in Figure
{}\ref{belos:fig:BelosSequence}.  {}\texttt{Linear\-Problem\-Setup} is
not a concrete subclass but is only an interface.  The default
concrete subclass implementation {}\texttt{Linear\-Problem} is
provided and most {}\texttt{Client}s would use this class.  However,
there are some more specialized use cases where a different concrete
implementation may be needed.

In any case, a {}\texttt{Linear\-Problem\-Setup} object
{}\texttt{lpup} must be setup.  Before the linear problem is setup
it is a good idea to first wipe out any current linear system that
may be set using:

{\scriptsize\begin{verbatim}
  lpup->unitialize();
  lpup->setRhs(B);
  lpup->setLhs(X);
\end{verbatim}}

Once the {}\texttt{Linear\-Problem\-Setup} object {}\texttt{lpup} is
clean then, at a minimum, it must be setup with an operator, the RHS
and LHS as follows:

{\scriptsize\begin{verbatim}
  lpup->setOperator(A);
  lpup->setRhs(B);
  lpup->setLhs(X);
\end{verbatim}}

If left and/or right preconditioning but not scaling is used, then the
linear problem object {}\texttt{lpup} is setup as follows:

{\scriptsize\begin{verbatim}
  lpup->setOperator(A);
  if(useLeftPrec)  lpup->setLeftPrec(P_L);
  if(useRightPrec) lpup->setRightPrec(P_R);
  lpup->setRhs(B);
  lpup->setLhs(X);
\end{verbatim}}

Above, a left and/or right preconditioner can be specified.

If left and/or right preconditioning and left and/or right scaling is
used, then the linear problem object {}\texttt{lpup} is setup as
follows:

{\scriptsize\begin{verbatim}
  lpup->setOperator(A_tilde);
  if(useLeftPrec)  lpup->setLeftPrec(P_L);
  if(useRightPrec) lpup->setRightPrec(P_R);
  if(useLeftScaling)  lpup->setLeftScaling(s_L);
  if(useRightScaling) lpup->setRightScaling(s_R);
  lpup->setRhs(B);
  lpup->setLhs(X);
\end{verbatim}}

Furthermore, the {}\texttt{Client} may set a single
{}\texttt{Status\-Test} object that defines the convergence criteria
for each of the columns in $B$ and $X$ as follows:

{\scriptsize\begin{verbatim}
  lpup->setStatusTest(st);
\end{verbatim}}

A {}\texttt{Status\-Test} subclass object can apply a different status
test for each individual column in $B$ (in which case it needs to know
how many columns there are in $B$ at a minimum) or can just apply a
generic status test (in which case it does not need to know how many
columns there are in $B$).  A status test is optional but recommended
since the iterative solver will simply iterate to the maximum
iterations if not stopped by a status test.

Finally, the block size $b$ as defined in Section
(\ref{sec:basic-block-solves}) to be used by block solvers can be set
as:

{\scriptsize\begin{verbatim}
  lpup->setBlockSize(blockSize);
\end{verbatim}}

This block size may be modified by the {}\textit{concrete iterative
linear solver} for instance if deflation, as described in Section
{}\ref{sec:basic-block-solves}, is used.

Finally, the linear problem object setup is completed with a called to

{\scriptsize\begin{verbatim}
  lpup->completeSetup();
\end{verbatim}}

which performs several tasks such as checking that a valid problem has
been set up (by checking the compatibility of the various vector
spaces) and building a composite operator object for $\hat{A} = P_L
\tilde{A} P_R$.

{}\item Use case : \textbf{Iterate on linear problem}

{}\noindent{}Classes/interfaces involved : {}\texttt{Client},
{}\texttt{Basic\-Iteration}

The {}\texttt{Basic\-Iteration} interface abstracts the
{}\texttt{Concrete\-Iterative\-Linear\-Solver} away from the
{}\texttt{Client}.

The client sets the linear problem and invokes the solver as shown
in Figure {}\ref{belos:fig:BelosSequence} and as follows:

{\scriptsize\begin{verbatim}
  bi->setProblem(lpup);
  bi->initialize();
  IterateReturn iterateReturn = bi->iterate(maxNumIters);
\end{verbatim}}

The {}\texttt{Basic\-Iteration::\-set\-Problem(...)} function accepts
a linear problem object through the
{}\texttt{Linear\-Problem\-Iteration} interface.  The
{}\texttt{Linear\-Problem\-Iteration} interface contains all of the
functionality that a {}\texttt{Concrete\-Iterative\-Linear\-Solver}
needs to solve the set of equations but does not contain functions to
change the definition of the linear problem (i.e.~an iterative solver
can not accidentally change the operator, the RHS or any of the
preconditioners).  The {}\texttt{Linear\-Problem\-Iteration} interface
class is discussed in more detail in the other use cases which are
also shown in Figure {}\ref{belos:fig:BelosUseCases} involving the
{}\textit{concrete iterative linear solver} .  The actual linear
solver algorithm is invoked using the
{}\texttt{Basic\-Iteration::\-iterate(...)} function which only
returns when the {}\texttt{Status\-Test} object says to or if the
maximum number of iterations {}\texttt{maxNumIters} is reached.  When
this function returns, it returns a simple struct object
{}\texttt{iterateReturn} of type {}\texttt{IterateReturn}.  This
object gives the reason for the return in
{}\texttt{iterateReturn\-.iterateReturn} (takes on values
{}\texttt{TERMINATION\-\_STATUS\-\_TEST} and
{}\texttt{TERMINATION\-\_MAX\-\_NUM\-\_ITER}) and the cumulative
number of iterations required in
{}\texttt{iterateReturn\-.numCumulativeIter}.

{}\item Use case : \textbf{Retrieve ``solution''}

{}\noindent{}Classes/interfaces involved : {}\texttt{Client},
{}\texttt{Basic\-Iteration}, {}\texttt{Linear\-Problem\-Setup}

The final solution (or just the last candidate LHS if the solution was
not found) is obtained as shown in Figure
{}\ref{belos:fig:BelosSequence} and as follows:

{\scriptsize\begin{verbatim}
  bi->finalize();
  RefCountPtr<TSFCore::MultiVector<Scalar> > solution = bi->getProblem()->getLhs();
\end{verbatim}}

If status of this solution is given by the return value of the
{}\texttt{Basic\-Iteration::\-iterate(...)} function.

After a linear system is completely solved it is a good idea to unset the
linear problem and unintialize it as

{\scriptsize\begin{verbatim}
  bi->setProblem(null);
  lpup->uninitialize()
\end{verbatim}}

{}\noindent{}in order to make sure no references are remaining to the
various operators and multi-vector objects.

\end{enumerate}

\subsubsection*{Use cases involving the {}\textit{concrete iterative linear solver}}

All of the use cases involving the {}\textit{concrete iterative linear
solver} are wrapped in the above use case ``Iterate on linear
problem'' which is invoked using the function
{}\texttt{Concrete\-Iterative\-Linear\-Solver::\-iterate(...)}.
Pseudo code for how this function might be implemented that is
consistent with Figure {}\ref{belos:fig:BelosInterfaces} and Figure
{}\ref{belos:fig:BelosSequence} is shown below:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void LinearSolverImplementation<Scalar>::iterate( const int maxNumIters )
  { 
    int numCumulativeIter = 0;
    bool allConverged = true;
    // Do some initial setup for the particular solver algorithm
    ...
    // Solve the systems as a set of block solves
    const int numTotalRhs = lpi_->getTotalNumRhs();
    bool allFinished = false;
    while ( !allFinished ) {
      IterateReturn nextBlockReturn = nextBlock( maxNumIter, &allFinished );
      if(allFinished) break;
      numCumulativeIter += nextBlockReturn.numCumulativeIter;
      if( nextBlockReturn.iterateTermination != TERMINATION_STATUS_TEST ) allConverged = false;
    }
    return IterateReturn( allConverged ? TERMINATION_STATUS_TEST : TERMINATION_MAX_NUM_ITER, numCumulativeIter );
  }
\end{verbatim}}

Note that the fact that the function {}\texttt{nextBlock(...)} is
called iteratively is shown in Figure {}\ref{belos:fig:BelosSequence}
using an asterisk in {}\texttt{* nextBlock(...)} which is standard UML
notation for representing iteration in a UML sequence diagram
{}\cite{ref:uml_distilled_2nd_ed}.

These use cases are more complicated than those that just involved the
{}\textit{client} which where described above.  This is a good thing
since developers that write {}\textit{client} code are likely to be
less experienced C++ programmers.  However, developers of
{}\texttt{Concrete\-Iterative\-Linear\-Solver} subclasses are likely to
be more advanced C++ programmers but these interfaces should still try
to make the development of these subclasses as easy and error-free as
possible.  To help avoid mistakes, a minimal but complete interface to
a linear problem is presented to a
{}\texttt{Concrete\-Iterative\-Linear\-Solver} through the
{}\texttt{Linear\-Problem\-Iteration} interface.  This interface
allows the {}\texttt{Concrete\-Iterative\-Linear\-Solver} to setup the
current RHS $\bar{B}$ and LHS $\bar{X}$ multi-vectors and update the
current estimate of the solution.  This interface, however, does not
allow a {}\texttt{Linear\-Problem\-Iteration} to accidentally change
the definition of the original RHS $B$, or the operator for the matrix
$\tilde{A}$ or $A$ or any of the preconditioners $P_L$ or $P_R$.

The scenario shown in Figure {}\ref{belos:fig:BelosSequence} is
consistent with a BiCGStab or CG (using left and right
preconditioners) solver implementation.  This scenario however is not
100\% consistent with a GMRES solver.

\begin{enumerate}

{}\item Use case : \textbf{Setup to solve current block system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Concrete\-Iterative\-Linear\-Solver} and
{}\texttt{Linear\-Problem\-Iteration}

In this use case, the {}\texttt{Concrete\-Iterative\-Linear\-Solver} object
sets the linear problem object up for the next set of iterations on a
block of RHSs.  The {}\texttt{Concrete\-Iterative\-Linear\-Solver} object
tells the {}\texttt{Linear\-Problem\-Iteration} object {}\texttt{lpi}
which set of right-hand sides it will solve next and what block size
to use.  For a block linear solver that can gain from a multi-RHS
iteration, a non-unity block size will be set up.  For example, the
block size $b$ can be used to determine how many right-hand sides will
be iterated on next and what block size to use.

{\scriptsize\begin{verbatim}
  template <class Scalar>
  IterateReturn ConcreteIterativeLinearSolver<Scalar>::nextBlock( const int maxNumIters, bool *allFinished )
  {
    // Setup for next set of solves
  	*allFinished = !lpi_->setupCurrSystem(); // If there is not a current system then we are all finished!
    if(*allFinished) return IterateReturn(); 
    // Inform the status test that we are solving a new block of systems
    StatusTest<Scalar> *statusTest = lpi_->getStatusTest();
    if(statusTest) statusTest->reset();
    // Perform iterations on this block of RHSs
    EIterateTermination doIterationReturn = TERMINATION_UNDEFINED;
    for( currNumIters_ = 0; currNumIters_ < maxNumIter; ++currNumIters_ ) {
      doIterationReturn = doIteration();
      if(doIterationReturn==TERMINATION_STATUS_TEST)
       break;
    }
    if( currNumIters_==maxNumIter && doIterationReturn!=TERMINATION_STATUS_TEST )
      doIterationReturn = TERMINATION_MAX_NUM_ITER;
    // Copy whatever is remaining in current LHS into full LHS
    lpi_->finalizeCurrSystem(*this);
    // Return status of this block
    return IterateReturn(doIterationReturn,currNumIters_);
  }
\end{verbatim}}

{}\noindent{}The {}\texttt{Linear\-Problem\-Iteration} {}\texttt{lpi}
object is responsible for initializing {}\texttt{currRhs} and
{}\texttt{currLhs} multi-vectors with the appropriate columns from
{}\texttt{rhs} and {}\texttt{lhs} respectively inside of the call to
{}\texttt{set\-Curr\-System(...)}.  Above, if the block size
{}\texttt{blockSize} is larger than the number of right-hand sides
remaining {}\texttt{num\-Rhs\-Remaining}, then the {}\texttt{lpi}
object will, by default, pad the last {}\texttt{blockSize} -
{}\texttt{num\-Rhs\-Remaining} columns of the RHS and LHS with vectors
as described in Section {}\ref{sec:basic-block-solves}.

A {}\texttt{Concrete\-Iterative\-Linear\-Solver} that can only perform a
single-RHS iteration would ignore the block size and set the current
block size as 1 as:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  IterateReturn ConcreteIterativeLinearSolver<Scalar>::nextBlock(const int maxNumIters, bool *allFinished)
  {
    // Setup for next set of solves
    *allFinished = !lpi_->setupCurrSystem(); // If there is not a current system then we are all finished!
    if(*allFinished) return IterateReturn(); 
    // Perform iterations on this RHS
    EIterateTermination doIterationReturn = TERMINATION_UNDEFINED;
    for( currNumIters_ = 0; currNumIters_ < maxNumIter; ++currNumIters_ ) {
      doIterationReturn = doIteration();
      if(doIterationReturn==TERMINATION_STATUS_TEST)
       break;
    }
    if( currNumIters_==maxNumIter && doIterationReturn!=TERMINATION_STATUS_TEST )
      doIterationReturn = TERMINATION_MAX_NUM_ITER;
    // Copy current solution into full solution
    lpi_->setCurrToFullsolution(*this);
    *numRhsSolved += 1;
    // Return status of this block
    return IterateReturn(doIterationReturn,currNumIters_);
  }
\end{verbatim}}

{}\item Use case : \textbf{Determine status of individual RHSs in 
current block system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Concrete\-Iterative\-Linear\-Solver}, {}\texttt{Status\-Test},
{}\texttt{Basic\-Iteration\-State}, {}\texttt{Linear\-Problem\-State}

This is one of the more complex use cases.  The goal of the design to
support this use case should be to make the development of
{}\texttt{Status\-Test} subclasses as easy as possible and to minimize
the mistakes that developers of {}\texttt{Status\-Test} subclasses can
make.  A variety of status tests can be developed ranging from the
very cheap (i.e.~no extra cost) to very expensive (i.e.~doubling or
more the cost of an iteration) without having to perform any dynamic
casting.

As shown in Figure {}\ref{belos:fig:BelosSequence}, at the beginning
of each iteration, the {}\texttt{Status\-Test} object {}\texttt{st} is
called in order to determine the status of the current solution.  The
status test is performed before the computation of the iteration so as
to allow the status test to examine the starting guess for the
solution.  The status test is invoked as shown below:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  IterationReturn ConcreteIterativeLinearSolver<Scalar>::doIteration()
  {
    // Ask the status test to check the status of the current systems
    const int currBlockSize = lpi_->getCurrBlockSize();
    const int currNumRhs = lpi_->getCurrNumRhs();
    StatusTest<Scalar> *statusTest = lpi_->getStatusTest();
    if(statusTest) {
      std::vector<EStatusType> status(currBlockSize,STATUS_UNCHECKED);
      statusTest->checkStatus(*this,currBlockSize,currNumRhs,&status[0]);
      ...
    }
    ...
  }
\end{verbatim}}

Before the status test is invoked, the
{}\texttt{Concrete\-Iterative\-Linear\-Solver} object informs the
{}\texttt{Linear\-Problem\-Iteration} object if the solution
multi-vector {}\texttt{currLhs} is currently up to date or not.  This
is performed by the call to
{}\texttt{lpi\_->\-set\-Curr\-Lhs\-Updated(\-curr\-Lhs\-Updated\-)}
where {}\texttt{curr\-Lhs\-Updated} is a {}\texttt{bool}ean that is
determined by the type of solver algorithm.  For most solver
algorithms {}\texttt{curr\-Lhs\-Updated=false} would be set as is
shown in the scenario in Figure {}\ref{belos:fig:BelosSequence}.
However, there are cases when the current LHS may be directly updated
by the solver algorithm such as where there is no right
preconditioning or scaling when using BiCG, BiCGStab, QMR etc.~or when
using CG (where a single preconditioner is used to define the scalar
product).

After
{}\texttt{lpi\_->\-set\-Curr\-Lhs\-Updated(\-false\-)} is
called, the {}\texttt{Status\-Test} object {}\texttt{st} is invoked by
calling its virtual {}\texttt{checkStatus(...)} member function where
the solver passes itself as the first argument as shown above. By
passing the solver to the {}\texttt{Status\-Test} object, even the
most specialized status tests can be implemented through dynamic
casting.

Once this {}\texttt{Status\-Test} object is activated, it calls back
on the {}\texttt{Basic\-Iteration\-State} and
{}\texttt{Linear\-Problem\-State} interfaces to determine the status
of the current linear systems being solved.  The status of any
iterative solver can be queried by invoking any of the methods on
{}\texttt{Basic\-Iteration\-State} and
{}\texttt{Linear\-Problem\-State} (which is returned from the
{}\texttt{Basic\-Iteration\-State\-::get\-Problem()} function).
Specifically, the member functions shown in Figures
{}\ref{fig:BasicIterationState-functions} and
{}\ref{fig:LinearProblemState-functions} return the the derived
attributes defined in Section {}\ref{sec:basic-block-solves}.

\begin{figure}

\fbox{
\begin{minipage}{\textwidth}

{\scriptsize{}\noindent{}\texttt{const LinearProblemState<Scalar>\&
getProblem() const}} \\ $\bullet$ Returns reference to the
{}\texttt{Linear\-Problem\-State} object {}\texttt{lps}.

{\scriptsize{}\noindent{}\texttt{int getCurrNumIters() const}} \\
$\bullet$ Returns the total current number of iterative solver
iterations over all restarts.

{\scriptsize{}\noindent{}\texttt{int getCurrNumRestarts() const}} \\
$\bullet$ Returns the total current number of iterative solver
restarts (really only applicable to GMRES).

{\scriptsize{}\noindent{}\texttt{ENativeResidualType
getCurrNativeResidualType () const}} \\ $\bullet$ Returns the nature
of the native residual norms returned by
{}\texttt{get\-Curr\-Native\-Residuals(...)}.

{\scriptsize{}\noindent{}\texttt{void getCurrNativeResiduals( const
int currBlockSize, Scalar norms[], const MultiVector<Scalar>**
residuals = NULL ) const}} \\ $\bullet$ Returns the relative norms of
the current native residual as either
(\ref{belos:eqn:scaled_unprec_rel_norms}) for
{}\texttt{get\-Curr\-Native\-Residual\-Type()==NATIVE\-\_RESIDUAL\-\_UNPRECONDITIONED}
or (\ref{belos:eqn:scaled_prec_rel_norms}) for
{}\texttt{get\-Curr\-Native\-Residual\-Type()==NATIVE\-\_RESIDUAL\-\_PRECONDITIONED}
in the array output argument {}\texttt{norms[]} (length $\bar{b}$) and
optionally a pointer to the native residual multi-vector in
{}\texttt{*residuals} if such a multi-vector is being maintained
(e.g.~CG may have this residual multi-vector while GMRES will not).
Note that all iterative solvers must be able to return the relative
norms array {}\texttt{norms[]}.

\end{minipage}
} % \fbox

\caption{\label{fig:BasicIterationState-functions}
Derived attribute functions for {}\texttt{Basic\-Iteration\-State}
interface.  }

\end{figure}

\begin{figure}

\fbox{
\begin{minipage}{\textwidth}

{\scriptsize{}\noindent{}\texttt{int getCurrNumRhs() const}} \\
$\bullet$ Returns the current number of RHSs $\bar{m}$.

{\scriptsize{}\noindent{}\texttt{int getCurrBlockSize() const}} \\
$\bullet$ Returns the current block size $\bar{b}$.

{\scriptsize{}\noindent{}\texttt{void getCurrRhsIndexes( const int
currNumRhs, int currRhsIndexes[] ) const}} \\ $\bullet$ Returns array
{}\texttt{curr\-Num\-Indexes[]} of length $\bar{m}$ of indexes that
define mapping matrix $\bar{Q}$.  Note that entires in
{}\texttt{curr\-Num\-Indexes[]} for artificial augmented columns are
not given since they do not map to original RHSs.

{\scriptsize{}\noindent{}\texttt{const MultiVector<Scalar>\&
getCurrRhs() const}} \\ $\bullet$ Returns reference to non-mutable
current RHS $\bar{B}$.

{\scriptsize{}\noindent{}\texttt{const MultiVector<Scalar>\&
getCurrInitResidual() const}} \\ $\bullet$ Returns reference to
current initial residual multi-vector $\bar{R}_0$.

{\scriptsize{}\noindent{}\texttt{RefCountPtr<const MultiVector<Scalar>
> getCurrInitLhs() const}} \\ $\bullet$ Returns smart pointer to
non-mutable current initial LHS $\bar{X}_{0,r}$ for the current
restart.

{\scriptsize{}\noindent{}\texttt{const MultiVector<Scalar>\&
getCurrRhs() const}} \\ $\bullet$ Returns reference to non-mutable
current LHS $\bar{X}$.

{\scriptsize{}\noindent{}\texttt{const MultiVector<Scalar>\&
getCurrResidual() const}} \\ $\bullet$ Returns reference to current
residual multi-vector $\bar{R}$.

\end{minipage}
} % \fbox

\caption{\label{fig:LinearProblemState-functions}
Derived attribute functions for {}\texttt{Linear\-Problem\-State}
interface.  }

\end{figure}

Note that all of the derived atrributes $\bar{R}_0$, $\bar{X}$ and
$\bar{R}$ that may require extra computation have boolean query
functions that return whether or not these derived attributes have
been updated or not yet.  This allows {}\texttt{Status\-Test} objects
to be fully informed when extra compuation will be performed or not
and may even adjust what status tests are performed based on this
information.  These query functions are shown in Figure
{}\ref{fig:LinearProblemState-bool-functions}.

\begin{figure}

\fbox{
\begin{minipage}{\textwidth}

{\scriptsize{}\noindent{}\texttt{bool isCurrInitResidualComputed()
const}} \\ $\bullet$ Returns {}\texttt{true} if $\bar{R}_0$ is
currently computed.

{\scriptsize{}\noindent{}\texttt{bool isCurrLhsUpdated() const}} \\
$\bullet$ Returns {}\texttt{true} if $\bar{X}$ is currently updated.

{\scriptsize{}\noindent{}\texttt{bool isCurrResidualComputed() const}}
\\ $\bullet$ Returns {}\texttt{true} if $\bar{R}$ is currently
computed.

\end{minipage}
} % \fbox

\caption{\label{fig:LinearProblemState-bool-functions}
Derived attribute boolean query functions for
{}\texttt{Linear\-Problem\-State} interface.  }

\end{figure}

The scenario in Figure {}\ref{belos:fig:BelosSequence} shows a
norm-based status test being used.  In this case, converged solutions
must satisfy

\[
||\bar{R}_{(:,j)}|| / ||(\bar{R}_0)_{(:,j)}|| \leq \eta_{l_{(j)}}, \;
\mbox{for} j = 1 \ldots \bar{m}.
\]

The following pseudo-code shows how this {}\texttt{Status\-Test}
subclass might implement this status test:

{\scriptsize\begin{verbatim}
  template<class Scalar>
  void ResidualNormStatusTest<Scalar>::checkStatus(
    const BasicIterationState<Scalar>         &bis
    ,const int                                currBlockSize // == bis.getProblem().getBlockSize()
    ,const int                                currNumRhs    // == bis.getProblem().getCurrNumRhs()
    ,EStatusType                              status[]      // Array length currNumRhs
    )
  {
    const std::vector<typename Teuchos::ScalarTraits<Scalar>::magnitudeType> &tols = this->tols();
    const LinearProblemState<Scalar> &lps = bis.getProblem();
  #ifdef _DEBUG
    TEST_FOR_EXCEPT( tols.size() > 1 && ( lps.getTotalNumRhs() != static_cast<int>(tols.size()) ) );
  #endif
    // Force update of currLhs
    if(!lps.isCurrLhsUpdated()) bis.forceCurrLhsUpdate();  
    // Get the current and initial unscaled unpreconditioned residuals and compute their norms
    const TSFCore::MultiVector<Scalar>
      &R_bar_0 = lps.getCurrInitResidual(),
      &R_bar   = lps.getCurrResidual();
    if(static_cast<int>(R_bar_norms_.size()) < currBlockSize) {
      R_bar_norms_.resize(currBlockSize);
      R_bar_0_norms_.resize(currBlockSize);
    }
    TSFCore::norms( R_bar, &R_bar_norms_[0] );
    TSFCore::norms( R_bar_0, &R_bar_0_norms_[0] );
    if( static_cast<int>(currRhsIndexes_.size()) < currNumRhs ) currRhsIndexes_.resize(currNumRhs);
    bis.getProblem().getCurrRhsIndexes( currNumRhs, &currRhsIndexes_[0] );
    for( int k = 0; k < currNumRhs; ++k ) {
      const int origRhsIndex = currRhsIndexes_[k];
      const typename ST::magnitudeType R_rel_norm = R_bar_norms_[k] / R_bar_0_norms_[k];
      if( R_rel_norm <= tols[origRhsIndex-1] )  status[k] = STATUS_CONVERGED;
      else                                      status[k] = STATUS_UNCONVERGED;
    }
  }
\end{verbatim}}

The above example status test function can match a particular column
in the current residual $\bar{R}$ with an original column in the full
RHS $B$ by calling the function
{}\texttt{Linear\-Problem\-State::\-get\-Curr\-Rhs\-Indexes(...)}
which returns an array of indexes mapping the current RHSs to the
original RHSs.  The returned integer array essentially defines the
mapping matrix $\bar{Q}$ defined in Section
{}\ref{sec:basic-block-solves}.  These returned indexes (in the array
{}\texttt{currRhsIndexes[]}) are used to select potentially different
tolerances from the private array {}\texttt{tols} (where
{}\texttt{this->tols()} was setup by the client before invoking the
linear solver).

{}\texttt{Status\-Test} subclasses can also be easily setup that do
not require the current solution or unscaled unpreconditioned residual
but instead base the status test on the number of linear solver
iterations (by checking
{}\texttt{Basic\-Iteration\-State::\-get\-Curr\-Num\-Iters()}), the
number of restart iterations (i.e.~for GMRES by checking
{}\texttt{Basic\-Iteration\-State::\-get\-Curr\-Num\-Restarts()}), or
the native residual norms (returned by calling
{}\texttt{Basic\-Iteration\-State::\-get\-Curr\-Native\-Residuals(...)}).
Every implementation of {}\texttt{Basic\-Iteration} (and therefore
{}\texttt{Basic\-Iteration\-State}) is required to maintain an
estimate of the norm(s) of the current block of linear systems as
defined by (\ref{belos:eqn:scaled_unprec_rel_norms}) or
(\ref{belos:eqn:scaled_prec_rel_norms}).  The native norms are
returned by the function
{}\texttt{Basic\-Iteration\-State::\-getCurrNativeResidual(...)}.  The
following function shows how to check the native residual norms for a
simple norm-based status test subclass that only compares to a single
tolerance:

{\scriptsize\begin{verbatim}
  template<class Scalar>
  void ResidualNormStatusTest<Scalar>::checkStatus(
    const BasicIterationState<Scalar>         &bis
    ,const int                                currBlockSize // == bis.getProblem().getBlockSize()
    ,const int                                currNumRhs    // == bis.getProblem().getCurrNumRhs()
    ,EStatusType                              status[]      // Array length currNumRhs
    )
  {
    if(static_cast<int>(R_native_norms_.size()) < currBlockSize) R_native_norms_.resize(currBlockSize);
    bis.getCurrNativeResiduals( currBlockSize, &R_native_norms_[0] );
    for( int k = 0; k < currNumRhs; ++k ) {
      const int origRhsIndex = currRhsIndexes_[k];
      if( R_native_norms_[k] <= tol )  status[k] = STATUS_CONVERGED;
      else                             status[k] = STATUS_UNCONVERGED;
    }
  }
\end{verbatim}}

Note that the above {}\texttt{NativeNormStatusTest} subclass is
independent of the number of RHSs being solved and is likely to be a
very common type of status test in many cases.

{}\item Use case : \textbf{Deflate current block system removing
``converged'' RHSs}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Concrete\-Iterative\-Linear\-Solver} and
{}\texttt{Linear\-Problem\-Iteration}

After the {}\texttt{Status\-Test} object {}\texttt{st} has determined
which systems have been sufficiently converged then the
{}\texttt{Concrete\-Iterative\-Linear\-Solver} object can optionally remove
or deflate these systems from the current set of RHSs.  For some block
solvers, like block GMRES, it is not possible to deflate during an
iterative run but for others, like block CG, deflation is possible.
In any case, if the {}\texttt{Concrete\-Iterative\-Linear\-Solver} object
decides to remove some systems that have been converged, then it can
tell the {}\texttt{Linear\-Problem\-Iteration} object {}\texttt{lpi}
which RHSs these are and they will be removed as follows:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  IterationReturn ConcreteIterativeLinearSolver<Scalar>::doIteration()
  {
    ...
    if(statusTest) {
      ...
      // Get a list of the systems that have converged (according to status test)
      bool allConverged = true;
      int numToRemove = 0;
      std::vector<int> indexesToRemove(currNumRhs);
      for( int k = 0; k < currNumRhs; ++k ) {
        if(status[k]==STATUS_CONVERGED)
          indexesToRemove[numToRemove++] = k+1; // These are one-based
        else
          allConverged = false;
      }
      if(allConverged)
        return TERMINATION_STATUS_TEST;
      // Deflate systems that are converged (if not all converged)
      if(numToRemove) {
        lpi_->deflate(*this,numToRemove,&indexesToRemove[0]);
        // Deflate private workspace
        ...
      }
    }
    ...
  }
\end{verbatim}}

The above call to {}\texttt{deflate(...)} will result in a callback to
the {}\texttt{Basic\-Iteration\-State} interface to get the solution
for the converged and deflated RHSs.  The following is an
implementation of the {}\texttt{deflate(...)} function:

{\scriptsize\begin{verbatim}
  template<class Scalar>
  void LinearProblem<Scalar>::deflate(
    const BasicIterationState<Scalar>        &bis
    ,const int                               numCurrRhsToRemove
    ,const int                               currRhsIndexesToRemove[]
    )
  {
    if(!numCurrRhsToRemove) return; // Nothing to deflate!
    // Get the indexes in the original RHS of the converged RHSs
    std::vector<int> origRhsIndexesToRemove(numCurrRhsToRemove);
    for( int k = 0; k < numCurrRhsToRemove; ++k )
      origRhsIndexesToRemove[k] = currRhsIndexes_[currRhsIndexesToRemove[k]-1];
    // Copy converged LHS into full LHS
    if(!this->isCurrLhsUpdated()) bis.forceCurrLhsUpdate();
    assign( &*lhs_->subView(numCurrRhsToRemove,&origRhsIndexesToRemove[0])
            ,*currLhs_->subView(numCurrRhsToRemove,&currRhsIndexesToRemove[0]) );
    // Deflate private multi-vectors and arrays
    ...
    // Update the dimensions
    currNumRhs_ -= numCurrRhsToRemove;
    currBlockSize_ -= numCurrRhsToRemove;
    ...
  }
\end{verbatim}}

In the above function, if the current LHS solution $\bar{X}$ is not
updated then the function
{}\texttt{Basic\-Iteration\-State\-::force\-Curr\-Lhs\-Update()} is
called.

In addition, after the {}\texttt{deflate(...)} function is caled the
{}\texttt{Concrete\-Iterative\-Linear\-Solver} would also have to deflate
its data structures for ``converged'' the RHSs being removed but this
is simple given generic helper functions.

{}\item Use case : \textbf{Perform iteration(s) on current block
system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Concrete\-Iterative\-Linear\-Solver} and
{}\texttt{Linear\-Problem\-Iteration}

Really the only interaction between the
{}\texttt{Concrete\-Iterative\-Linear\-Solver} object and the
{}\texttt{Linear\-Problem\-Iteration} object needed in order to
perform a single iteration is in applying the operator and (optional)
preconditioners.  In order to insulate the
{}\texttt{Concrete\-Iterative\-Linear\-Solver} object from having to worry
about whether left and/or right preconditioning is being used a
composite linear operator object for $\hat{A} = P_L \tilde{A} P_R$ is
returned from the function
{}\texttt{Linear\-Problem\-State::\-get\-Conbined\-Operator(...)} (as
shown in the scenario in Figure {}\ref{belos:fig:BelosSequence}).  The
current scaled preconditioned residual $\breve{R}$ itself can be
computed using the function
{}\texttt{Linear\-Problem\-Iteration::\-compute\-Curr\-Prec\-Residual(...)} 
and this is all that most iterative solves need what wish to be
oblivious to the type of scaling and preconditioning being used.

{}\item Use case : \textbf{Finalize computation of ``solution'' of
current block system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Concrete\-Iterative\-Linear\-Solver} and
{}\texttt{Linear\-Problem\-Iteration}

After the {}\texttt{Status\-Test} object determines that all of the
current linear systems are solved for, the
{}\texttt{Concrete\-Iterative\-Linear\-Solver} object would then
update those components of the final solution by simply calling the
function

{\scriptsize\begin{verbatim}
   lpi_->finalizeCurrSystem(*this);
\end{verbatim}}

{}\noindent{}as shown in the pseudo code for the function
{}\texttt{nextBlock(...)} shown above.  This function calls back on
the {}\texttt{Basic\-Iteration\-State\-::force\-Curr\-Lhs\-Update()}
function to get the solution for whatever converged RHSs that have not
already been deflated out and then sets these into the full LHS.  An
concrete implementation of the
{}\texttt{finalize\-Curr\-System(...)} function is shown below:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void LinearProblem<Scalar>::finalizeCurrSystem( const BasicIterationState &bis )
  {
    if(!isCurrLhsUpdated_) bis.forceCurrLhsUpdate();
    assign( &*lhs_->subView(currNumRhs_,&currRhsIndexes_[0]), *currLhs_->subView(TSFCore::Range1D(1,currNumRhs_)) );
    currFirstRhsOffset_ += currInitNumRhs_; // Increment the current offset into the block of RHSs
    currNumRhs_ = 0;                        // Set as uninitialized
  }
\end{verbatim}}

\end{enumerate}

\subsection{Concrete iterative linear solvers}

There are several concrete iterative linear solver implementations
that support these interfaces:

\begin{enumerate}
\item {}\texttt{Belos::NonblockGmres}: Non-block GMRES (with only single RHS) (Ross/Heidi), status = completed
\item {}\texttt{Belos::NonblockCg}: Non-block CG (with simple multiple RHS) (Ross), status = completed
\item {}\texttt{Belos::BlockGmres}: Block flexible (and regular) GMRES (Heidi), status = not yet
\item {}\texttt{Belos::BlockCg}: Block CG (Heidi), not yet
\item {}\texttt{Belos::NonblockBiCg}: Non-block BiCG (with simple multiple RHS ) (Ross), status = not yet
\item {}\texttt{Belos::NonblockBiCgStab}: Non-block BiCGStab (with only single RHS) (Kevin), status = not yet
\end{enumerate}

The solvers {}\texttt{Belos::NonblockGmres} and
{}\texttt{Belos::NonblockCg} are working solvers but can also be
consisdered to be prototypical code to demonstrate the principles
involved.

\section{Summary}

The interfaces described in this document provide a very flexible and
efficient means to implement a wide range of iterative linear solvers
in such a way as to maximize reuse.

% ---------------------------------------------------------------------- %% References
%
\clearpage
\bibliographystyle{plain}
\bibliography{references}
\addcontentsline{toc}{section}{References}

% ---------------------------------------------------------------------- %
% Appendices should be stand-alone for SAND reports. If there is only
% one appendix, put \setcounter{secnumdepth}{0} after \appendix
%
%\appendix
%\input{apdx_TSFCoreClassDecl}

\begin{SANDdistribution}
% External
\SANDdistExternal{1}{} Matthias Heinkenschloss \\ Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Bill Symes\\Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Tony Padula\\Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Mark Gockenbach \\ Department of Mathematical Sciences\\Michigan Technological University\\ 
1400 Townsend Drive\\Houghton, Michigan 49931-1295, U.S.A.
\SANDdistExternal{1}{} Paul Sexton \\ Box 1560 \\ St. John's University \\ Collegeville, MN 56321
% Sandia Line
%\SANDdistInternal{1}{0847}{Bill Camp}{9200}
%\SANDdistInternal{1}{0847}{Sudip Dosanjh}{9233}
% 9211
\SANDdistInternal{1}{0370}{Scott Mitchell}{9211}
\SANDdistInternal{1}{0370}{Roscoe Bartlett}{9211}
\SANDdistInternal{1}{0370}{Bart van Bloemen Waanders}{9211}
% 9214
\SANDdistInternal{1}{9159}{Mark Adams}{9214}
\SANDdistInternal{1}{1110}{Pavel Bochev}{9214}
\SANDdistInternal{1}{1110}{Todd Coffey}{9214}
\SANDdistInternal{1}{1110}{David Day}{9214}
\SANDdistInternal{1}{1110}{John Delaurentis}{9214}
\SANDdistInternal{1}{1110}{Michael Heroux}{9214}
\SANDdistInternal{1}{1110}{Ulrich Hetmaniuk}{9214}
\SANDdistInternal{1}{9217}{Jonathan Hu}{9214}
\SANDdistInternal{1}{1110}{Richard Lehoucq}{9214}
\SANDdistInternal{1}{1110}{Louis Romero}{9214}
\SANDdistInternal{1}{1110}{David Ropp}{9214}
\SANDdistInternal{1}{1110}{Mazio Sala}{9214}
\SANDdistInternal{1}{1110}{Kendall Stanley}{9214}
\SANDdistInternal{1}{1110}{Heidi Thornquist}{9214}
\SANDdistInternal{1}{9217}{Raymond Tuminaro}{9214}
\SANDdistInternal{1}{1110}{James Willenbring}{9214}
% 9215
\SANDdistInternal{1}{1110}{William Hart}{9215}
\SANDdistInternal{1}{1110}{Erik Boman}{9215}
% 9233
% 9210
%\SANDdistInternal{1}{1110}{David Womble}{9210}
% 8962
%\SANDdistInternal{1}{9159}{Steve Thomas}{8962}
\SANDdistInternal{1}{9159}{Paul Boggs}{8962}
\SANDdistInternal{1}{9159}{Kevin Long}{8962}
\SANDdistInternal{1}{9159}{Patricia Hough}{8962}
\SANDdistInternal{1}{9159}{Tamara Kolda}{8962}
\SANDdistInternal{1}{9159}{Monica Martinez-Canales}{8962}
\SANDdistInternal{1}{9159}{Pamela Williams}{8962}
\SANDdistInternal{1}{9159}{Victoria Howle}{8962}
% Sandia Misc
%\SANDdistInternal{1}{0847}{Steve Wojtkiewicz}{9124}
% Xyce developers
\SANDdistInternal{1}{0316}{Eric Keiter}{9233}
\SANDdistInternal{1}{0316}{Scott Hutchinson}{9233}
\SANDdistInternal{1}{0316}{Robert Hoekstra}{9233}
% Premo developers
\SANDdistInternal{1}{0316}{Curt Ober}{9233}
\SANDdistInternal{1}{0316}{Tom Smith}{9233}
\SANDdistInternal{1}{0316}{Russel Hooper}{9233}
% Main Sierra developers
\SANDdistInternal{1}{0382}{Carter Edwards}{9143}
\SANDdistInternal{1}{0382}{James Stewart}{9143}
\SANDdistInternal{1}{0316}{Alan Williams}{9143}
% Main Nevada developers
\SANDdistInternal{1}{0617}{Ricard Drake}{9231}
% NOX/LOCA developers
\SANDdistInternal{1}{0316}{Roger Pawlowski}{9233}
\SANDdistInternal{1}{0316}{Eric Phipps}{9233}
\SANDdistInternal{1}{1110}{Andrew Salinger}{9233}
\SANDdistInternal{1}{1110}{Brett Bader}{9233}
% Charon developers
\SANDdistInternal{1}{0316}{Gary Hennigan}{9233}
% Other Trilinos developers
% Housekeeping copies necessary for every unclassified report:
\SANDdistInternal{1}{9018}{Central Technical Files}{8945-1}
\SANDdistInternal{2}{0899}{Technical Library}{9610}
\SANDdistInternal{2}{0612}{Review \& Approval Desk}{4916}
% If report has a Patent Caution or Patent Interest, add this:
%\SANDdistInternal{3}{0161}{Patent and Licensing Office}{4916}
\end{SANDdistribution}

\end{document}
