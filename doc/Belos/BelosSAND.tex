\documentclass[pdf,ps2pdf,11pt]{SANDreport}
\usepackage{pslatex}

%Local stuff
\usepackage{graphicx}
\usepackage{latexsym}
\input{rab_commands}

% If you want to relax some of the SAND98-0730 requirements, use the "relax"
% option. It adds spaces and boldface in the table of contents, and does not
% force the page layout sizes.
% e.g. \documentclass[relax,12pt]{SANDreport}
%
% You can also use the "strict" option, which applies even more of the
% SAND98-0730 guidelines. It gets rid of section numbers which are often
% useful; e.g. \documentclass[strict]{SANDreport}

% ---------------------------------------------------------------------------- %
%
% Set the title, author, and date
%

\title{
{\Huge\bf Belos}\\[1.5ex] The Trilinos package of next-generation
object-oriented iterative linear solvers }
\author{
Heidi Thornquist \\
Michael Heroux \\
Computational Math/Algorithms \\ \\
Roscoe Bartlett \\
Optimization/Uncertainty Estim \\ \\
Kevin Long \\
Paul Boggs \\
Computational Sciences \& Math \\ \\
Sandia National Laboratories\footnote{
Sandia is a multiprogram laboratory operated by Sandia Corporation, a
Lockheed-Martin Company, for the United States Department of Energy
under Contract DE-AC04-94AL85000.}, Albuquerque NM 87185 USA
}
\date{}

% ---------------------------------------------------------------------------- %
% Set some things we need for SAND reports. These are mandatory
%
\SANDnum{SAND2004-???}
\SANDprintDate{August 2004}
\SANDauthor{
Heidi Thornquist \\
Michael Heroux \\
Roscoe Bartlett \\
Kevin Long \\
Paul Boggs
}

% ---------------------------------------------------------------------------- %
% The following definitions are optional. The values shown are the default
% ones provided by SANDreport.cls
%
\SANDreleaseType{Unlimited Release}
%\SANDreleaseType{Not approved for release outside Sandia}

% ---------------------------------------------------------------------------- %
% The following definition does not have a default value and will not
% print anything, if not defined
%
%\SANDsupersed{SAND1901-0001}{January 1901}

% ---------------------------------------------------------------------------- %
%
% Start the document
%
\begin{document}

\maketitle

% ------------------------------------------------------------------------ %
% An Abstract is required for SAND reports
%

%
\begin{abstract}
%
Belos first and foremost is a package that contains a standard set of
interfaces for next-generation iterative linear solvers in Trilinos.
These interfaces are based on TSFCore and lead to extremely efficient
and flexible iterative solver implementations.  In addition, the Belos
package has a collection of many different advanced ready to use block
and non-block Krylov iterative linear solvers such as block GMRES and
block CG as well as BiCG and BiCGStab.  It is also expected any new
general iterative solvers implemented to support the Belos interfaces
will also be added to the Belos package.
%
\end{abstract}
%

% ------------------------------------------------------------------------ %
% An Acknowledgement section is optional but important, if someone made
% contributions or helped beyond the normal part of a work assignment.
% Use \section* since we don't want it in the table of context
%
\clearpage
\section*{Acknowledgments}
We like everyone!

The format of this report is based on information found
in~\cite{Sand98-0730}.

% ------------------------------------------------------------------------ %
% The table of contents and list of figures and tables
% Comment out \listoffigures and \listoftables if there are no
% figures or tables. Make sure this starts on an odd numbered page
%
\clearpage
\tableofcontents
\listoffigures
%\listoftables

% ---------------------------------------------------------------------- %
% An optional preface or Foreword
%\clearpage
%\section{Preface}
%Although muggles usually have only limited experience with
%magic, and many even dispute its existence, it is worthwhile
%to be open minded and explore the possibilities.

% ---------------------------------------------------------------------- %
% An optional executive summary
%\clearpage
%\section{Summary}
%Once a certain level of mistrust and scepticism has
%been overcome, magic finds many uses in todays science
%and engineering. In this report we explain some of the
%fundamental spells and instruments of magic and wizardry. We
%then conclude with a few examples on how they can be used
%in daily activities at national Laboratories.

% ---------------------------------------------------------------------- %
% An optional glossary. We don't want it to be numbered
%\clearpage
%\section*{Nomenclature}
%\addcontentsline{toc}{section}{Nomenclature}
%\begin{itemize}
%\item[alohomora]
%spell to open locked doors and containers
%\end{itemize}

% ---------------------------------------------------------------------- %
% This is where the body of the report begins; usually with an Introduction
%
\SANDmain % Start the main part of the report

\section{Introduction}

Here we describe a set of object-oriented interfaces based on TSFCore
{}\cite{ref:TSFCore} for the development and use of preconditioned
iterative linear solvers for the set of simultaneous block linear
equations
%
\begin{equation}
A X = B
\label{belos:eqn:AX=B}
\end{equation}
%
{}\noindent{}where $A\in\RE^{n {}\times n}$ is a matrix operator,
$X\in\RE^{n {}\times m}$ is the solution multi-vector and $B\in\RE^{n
{}\times m}$ is the right-hand side multi-vector.  From here on, the
matrix $A$, which happens to be a linear operator, will be referred to
as ``the operator'' to distinguish it from other linear operators.

Associated with every linear system of the form (\ref{belos:eqn:AX=B})
is an initial guess $X_0$ which in many cases will just be zero.

Typically, when an iterative solver is used, and if the operator is in
matrix coefficient form, then the system(s) are first scaled and then
a preconditioner is generated from the scaled operator.  This sequence
of activities is shown in the UML {}\cite{ref:booch_et_al_1999}
activity diagram in Figure
{}\ref{belos:fig:GeneralLinearSolveActivities}.

Note that similar activities are performed when a direct solver is
used.  The main difference, however, is that for a direct method
typically a complete sparse factorization is computed instead of just
perhaps an incomplete factorization as is commonly used to generate
preconditioners for iterative methods.  While we recognize these
similarities between direct and iterative solvers our discussion will
only focus on iterative solvers.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{GeneralLinearSolveActivities}
%}
\end{center}
\caption{
\label{belos:fig:GeneralLinearSolveActivities}
UML activity diagram : Common activities
performed in solving a linear system using an iterative method.}
\end{figure}
\esinglespace}

In many cases, the first activity after the matrix $A$ is generated is
the computation of diagonal scaling matrices $S_L$ and $S_R$ and then
a scaled matrix $\tilde{A}$ is formed as
%
\begin{equation}
S_L A S_R \Rightarrow \tilde{A}.
\label{belos:eqn:A_tilde}
\end{equation}
%
These scalings transform the system in ({}\ref{belos:eqn:AX=B}) into
%
\[
\underbrace{S_L A S_R}_{\displaystyle{\tilde{A}}}
\underbrace{S_R^{-1} X}_{\displaystyle{\tilde{X}}}
=
\underbrace{S_L B}_{\displaystyle{\tilde{B}}}
\]
%
\begin{equation}
\nonumber \\
\tilde{A} \tilde{X}  = \tilde{B}.
\label{belos:eqn:ScaledSystem}
\end{equation}
%
After the operator matrix $A$ is scaled to form $\tilde{A}$, left
and/or right preconditioners $P_L$ and $P_R$ are usually formed which
transform the system ({}\ref{belos:eqn:ScaledSystem}) into
%
\[
\underbrace{P_L \tilde{A} P_R}_{\displaystyle{\hat{A}}}
\underbrace{P_R^{-1} \tilde{X}}_{\displaystyle{\hat{X}}}
=
\underbrace{P_L \tilde{B}}_{\displaystyle{\hat{B}}}
\]
%
\begin{equation}
\nonumber \\
\hat{A} \hat{X}  = \hat{B}.
\label{belos:eqn:PreconditionedSystem}
\end{equation}
%
If scaling is not first performed then the preconditioners $P_L$ and
$P_R$ are formed from the unscaled operator $A$.

In order to use the scaled preconditioned operator $\hat{A}$, the the
original right-hand side(s) $B$ must be transformed as
%
\begin{equation}
\hat{B} = P_L S_L B \in \RE^{n \times m}
\label{B-preprocess}
\end{equation}
%
{}\noindent{}before the iterative solve is performed.

Note that a transformation of an initial guess $X_0$ to form an
initial guess $\hat{X}^0$ is not necessary since most iterative
methods just need the initial residual
%
\begin{eqnarray}
\hat{R}_0
& = & \hat{A} \hat{X}_0 - \hat{B}
\nonumber \\
& = & \left( P_L \tilde{A} P_R \right) \left( P_R^{-1} S_R^{-1} X_0 \right) - \hat{B}
\nonumber \\
& = & P_L \tilde{A} S_R^{-1} X_o - \hat{B}
\label{belos:eqn:R_hat_0}
\end{eqnarray}
%
{}\noindent{}which just requires a simple inverse diagonal scaling
with $S_R$ followed by an application of the matrix operator
$\tilde{A}$ and the left preconditioner $P_L$.

Once a system is solved for $\hat{X}$, the unscaled unpreconditioned
solution is easily recovered as
%
\begin{equation}
X = S_R P_R \hat{X} \in \RE^{n \times m}.
\label{X-postprocess}
\end{equation}
%
{}\noindent{}The details on how this solution multi-vector $X$ is
recovered will vary based on the specific type of concrete
{}\textit{iterative solver implementation} being used (for example,
GMRES and BiCGStab will handle this differently).

The software described here is designed to accept the operators
$\tilde{A}\in\RE^{n \times n}$, $P_L\in\RE^{n \times n}$,
$P_R\in\RE^{n \times n}$, the scaling vectors $s_L\in\RE^{n}$,
$s_R\in\RE^{n}$ (which form the diagonals of $S_L\in\RE^{n
\times n}$ and $S_R\in\RE^{n \times n}$) and the original
LHS $X$ and RHS $B$ multi-vectors.  Once the linear system is
constructed, this software can then invoke an iterative method to
attempt to solve the resulting linear system(s).  Since preprocessing
of the RHS $B$ before the solution (as in (\ref{B-preprocess})) and
post-processing of the LHS $X$ after the solution (as in
(\ref{X-postprocess})) are so common, these activities are performed
by a common set of software that all iterative linear solvers use (see
the {}\texttt{Linear\-Problem} classes below).

%
\section{Basics of block iterative solvers}
\label{sec:basic-block-solves}
%

In this sections we describe some basic mathematical quantities that
are associated with a block iterative solver such as block GMRES or
block CG.  When a block solver is used to solve a multiple set of
equations as in (\ref{belos:eqn:AX=B}), typically smaller sub-blocks
of equations are solved seperately in order to balance memory movement
efficiency and total memory usage.  For example, if $m=100$ sets of
equations are to be solved, a block size of $b=20$ may be used to
solve the block system in (\ref{belos:eqn:AX=B}) in $m/b = 100/20 = 5$
separate iterative runs.  However, there may be situations where $m <
b$ in which case a set of $m-b$ artificial augmented systems are
solved along with the $m$ systems.  Augmenting the set of linear
systems can reduce the number of iterations needed for certain block
iterative solvers [???].

Here we state in more precise mathematical terms what multi-vector
quantities that a block iterative solver maintains.  It is important
to define these quantities carefully since they can be used to
determine convergence of the iterative method.  When a new block of
systems is setup to be solved, the current RHS $\bar{B}$ and the
current starting initial guess $\bar{X}_0$ are defined either as
%
\begin{eqnarray}
\bar{X}_0 & = & (X_0)_{(:,k+1:k+b)} \in \RE^{n \times b} \label{X_bar_r_b} \\
\bar{B}   & = & (B)_{(:,k:k+1+b)} \in \RE^{n \times b} \label{B_bar_r_b}
\end{eqnarray}
%
{}\noindent{}for the case $k+b {}\leq m$, where $k\in[0,m-1]$ is the
current offset for the linear systems to solved, or as
%
\begin{eqnarray}
\bar{X}_0 & = & {\bmat{cc} (X_0)_{(:,k+1:m)} & 0 \emat} \in \RE^{n \times b} \label{X_bar_m} \\
\bar{B}   & = & {\bmat{cc} (B)_{(:,k+1:m)} & \bar{V} \emat} \in \RE^{n \times b} \label{B_bar_m}
\end{eqnarray}
%
{}\noindent{}for the case $k+b > m$, where $0\in\RE^{(n) {}\times
(m-(k+b))}$ is a multi-vector of zeros and $\bar{V}\in\RE^{(n) {}\times
(m-(k+b))}$ is some (usually random) well-scaled multi-vector.  In
(\ref{X_bar_m})--(\ref{B_bar_m}), the block of linear systems are
argumented with $m-(k+b)$ artificial systems in order to attempt to
reduce the number of iterations while achieving good memory movement.

Once the iterative solve is started, restarts may be performed and
linear systems may be removed (or deflated) as they converge thereby
reducing the block size to $\bar{b} < b$.  We now define the mapping
matrix $\bar{Q}\in\RE^{m {}\times {}\bar{m}}$ (where $\bar{m} {}\leq
\bar{b}$) to select the columns in $B$ and $X$ for the linear systems
currently being solved which defines the current quantities:

\begin{itemize}

{}\item $R_0 = A X_0 - B {}\in\RE^{n
{}\times m}$ : The full residual multi-vector with respect to
full initial guess $X_0$ and right-hand side $B$.

{}\item $\bar{B}={\bmat{cc} B \bar{Q} & \bar{V} \emat}\in\RE^{n
{}\times \bar{b}}$ : The current (augmented if $k+b > m$)
right-hand side mulit-vector (where $\bar{V}=\emptyset$ if $k+b {}\leq
m$ or is some well-conditioned mulit-vector $\bar{V}\in\RE^{n {}\times
m-(k+\bar{m})}$ if $k+b > m$).

{}\item $\bar{X}_0={\bmat{cc} X_0 \bar{Q} & 0 \emat}\in\RE^{n {}\times
{}\bar{b}}$ : The current (augmented if $k+b > m$) starting initial
guess for the solution associated with $\bar{B}$ (where $0=\emptyset$
if $k+b {}\leq m$ or $0\in\RE^{n {}\times m-(k+\bar{m})}$ if $k+b >
m$).

{}\item $\bar{R}_0 = A \bar{X}_0 - \bar{B} {}\in\RE^{n
{}\times {}\bar{b}}$ : The current staring initial residual
multi-vector with respect to current starting initial guess
$\bar{X}_0$.

{}\item $\bar{X}_{0,r}\in\RE^{n {}\times {}\bar{b}}$ : The current
initial guess for the solution associated with $\bar{B}$ for the
current restart (i.e.~$\bar{X}_{0,r} {}\neq \bar{X}_0$ after the first
restart).

{}\item $\bar{X}\in\RE^{n {}\times {}\bar{b}}$ : The current
approximate left-hand-side solution associated with $\bar{B}$ for the
current restart.

{}\item $\bar{Z}\in\RE^{n {}\times {}\bar{b}}$ : The update defining
$\bar{X} = \bar{X}_{0,r} + S_R P_R \bar{Z}$ which is computed directly
in many cases by the iterative solver.  Note that $\bar{Z}$ is defined
as the update from the guess for the most recent restart
$\bar{X}_{0,r}$ and not from the starting inital guess $\bar{X}_0$.

{}\item $\bar{R} = A \bar{X} - \bar{B} {}\in\RE^{n {}\times
{}\bar{b}}$ : The current residual multi-vector with respect to
$\bar{X}$ and $\bar{B}$.

{}\item $\breve{R} = P_L S_L \bar{R} {}\in\RE^{n {}\times {}\bar{b}}$
: The current native residual multi-vector with respect to $\bar{X}$
and $\bar{B}$.

\end{itemize}

The multi-vector quantities $\bar{B}$, $\bar{R}_0$, $\bar{X}$, and
$\breve{R}$ are defined for every block iterative solver method and
should be accessible for the definition of convergence tests.  In all
of the iterative linear solvers these quantities can be viewed as
derived attributes of the state of the iterative solver and while
these quantities may require extra computation this does not change
whether or not they are computable for all iterative solvers.  In all
of the iterative solvers it will be clear what quantities are
immediately available and what quantities will require extra
computation.  Of particualar importance are the column-wise norms $n_j
= ||\breve{R}_{(:,j)}||$ which every iterative solver implementation
is required (even GMRES) to provide at a relatively low cost (i.e.~no
more than just a simple norm calculation).

%
\section{Basic interfaces for iterative linear solvers}
%

Here we describe the basic interfaces to iterative linear solvers
given that the operator, scalings and preconditioner objects are
already formed as are the RHS and LHS multi-vector objects.

%
\subsection{Requirements for basic interfaces to iterative solvers}
\label{sec:requirements}
%

Before describing the requirements, a few definitions are needed to
identify two types of software and therefore two types of software
developers:

\begin{itemize}

\item{}\textit{Client} :
An external entity that requires the services of an iterative linear
solver (such as a nonlinear ANA).  Such a client will assume to have
already generated the operator, appropriate scalings and/or
preconditioners for the operator at hand and will have already
generated the RHS and initial LHS multi-vectors (or single vectors)
that define the linear system.  All of these objects shall be
represented using basic TSFCore interfaces.  In addition, the
{}\textit{client} shall be able to define arbitrary convergence
criteria.  Such convergence criteria will be referred to as
{}\textit{status tests}.

\item{}\textit{Iterative solver implementation} : 
An implementation of a (Krylov) iterative linear equation solver such
as GMRES.  Such an implementation may be a true block RHS solver or
just a single-RHS solver.

\end{itemize}

Figure {}\ref{belos:fig:BelosUseCases} shows the basic use cases for
solving a set of equations using these iterative linear solvers.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{BelosUseCases}
%}
\end{center}
\caption{
\label{belos:fig:BelosUseCases}
UML use-case diagram : Basic use cases
for {}\textit{clients} and {}\textit{iterative solver implementations}.}
\end{figure}
\esinglespace}

Some more specific requirements related to the use cases shown in
Figure {}\ref{belos:fig:BelosUseCases} for of above defined
{}\textit{client} and {}\textit{iterative solver implementation}
software are given below:

\begin{enumerate}

\item
A {}\textit{client} should be able to setup and solve a linear system
without knowing the concrete type of iterative linear solver being
used.  This is the main -- if not the entire -- point of this whole
design.  {}\textit{Importance:} Fundamental.

\item
The implemented algorithms should be near optimal in storage and CPU
time.  {}\textit{Justification:} An algorithm coded by hand in Fortran
77 should not be significantly more efficient any way which is
critical for scientific computing.  {}\textit{Importance:}
Fundamental.

\item
The linear solvers should accept objects only through the basic
TSFCore linear operator, vector, multi-vector and vector space
interfaces.  {}\textit{Justification:} Automatic interoperability
between different types of ANAs requires this.  {}\textit{Importance:}
Fundamental.

\item
These interfaces should be general and efficient for both true block
RHS and single RHS iterative linear solvers.
{}\textit{Justification:} While block iterative linear solvers are
very important, many different uses of iterative solvers only require
or can only exploit linear solves for single RHSs.  For example, a
basic Newton method can only solve linear systems one RHS at a time.
{}\textit{Importance:} Fundamental.

\item
These interfaces should support left and/or right preconditioners.
{}\textit{Importance:} Fundamental.

\item
The interfaces should support {}\textit{iterative solver
implementations} that do not require adjoints and those that do (only
for operators that support adjoints of course).
{}\textit{Importance:} Fundamental.

\item
Interfaces and utilities should, when possible, insulate
{}\textit{iterative solver implementations} away from details of
whether left and/or right preconditioning is being used when applying
the composite operator but also allow this information to be known,
and access to constituent operators should be provided if desired.
{}\textit{Justification:} Most iterative solver algorithms only care
about the combined preconditioned operator and need not be bothered
with preconditioners but others do like flexible GMRES which needs to
apply the right preconditioner separately from the left preconditioner
and operator itself.  {}\textit{Importance:} Desired.

\item
For the {}\textit{client's} and the {}\textit{iterative solver
implementation's} benefit, default handling of standard pre- and
post-processing of RHS and LHS associated with left and/or right
scaling and left and/or right preconditioning should be provided.
{}\textit{Justification:} It seems reasonable to collect this commonly
needed functionality in one standard place so that different
{}\textit{iterative solver implementations} do not need to rewrite
this code over and over again.  {}\textit{Importance:} Desired.

\item
These interfaces should be minimal but sufficient for
{}\textit{clients} of iterative solvers and {}\textit{iterative solver
implementations}.  {}\textit{Justification:} This is a basic principle
of good object-oriented software design.  {}\textit{Importance:}
Desired.

\item
Allow for flexible and powerful status (i.e.~convergence) tests that
can be provided by the {}\textit{client} and are independent from the
{}\textit{iterative solver implementation}.  Cheap native norm-based
or iteration count-based status tests should be automatically
available but more expensive status tests based on the unscaled
unpreconditioned solutions and residuals should also be supported.
{}\textit{Justification:} One reason that same iterative linear solver
algorithms are constantly rewritten over and over again is to
accommodate different convergence criteria.  By separating the
convergence criteria from {}\textit{iterative solver implementation},
these implementations become much more reusable.
{}\textit{Importance:} Fundamental.

\item
Status tests should allow for dynamic (i.e.~during an iteration run)
deflation (i.e.~the removal of RHS and LHS vectors for systems that
are converged) but an {}\textit{iterative solver implementation}
should be free to keep such tagged linear systems in the current set.
{}\textit{Justification:} Some block iterative solvers, such as block
CG, can effectively remove individual RHSs as they converge thereby
reducing the cost of block solves in some cases (especially when some
RHSs have tighter tolerances than others).  Without the functionality
of deflation, a block iterative solver may result in more work than a
single RHS linear solver in some extreme cases (e.g.~two linear
systems that have radically different convergence criteria).
{}\textit{Importance:} Fundamental.

\item
Status tests should be alerted when a new iterative run (on one or
more simultaneous RHSs) is started.  {}\textit{Justification:}
Alerting a status test when a new iterative run is stated allows a
simplification of the design of status tests.  {}\textit{Importance:}
Desired.

\item
Multiple independent status tests should be allowed and the overall
efficiency of these independent status tests should be very close to
the performance were the status tests to be combined in more careful
manner.  {}\textit{Justification:} More than one status test may
require the current unscaled unpreconditioned solution $\bar{X}$
and/or the unscaled unpreconditioned residual $\bar{R}$ and these
quantities should not have to be recomputed from scratch by different
independent status tests.  {}\textit{Importance:} Fundamental.

\item
Specialized status tests for specific types of iterative solvers
should be allowed.  {}\textit{Justification:} Very specialized status
tests can be based on things like estimates of the eigenvalues of a
matrix that is generated from information being accumulated during an
iterative solve (i.e.~from the Krylov subspace).  {}\textit{Importance:} Fundamental.

\item
These interfaces should be designed and partitioned so as to minimize
opportunities for mistakes by developers of {}\textit{client} and
{}\textit{iterative solver implementation} software.
{}\textit{Justification:} It is a good object-oriented design
principle to design, develop and deploy interfaces that are designed
for specific types of clients and use cases.  Such designs result in
smaller easier to understand interfaces, minimize misuse of the
interfaces and simplify maintenance (i.e.~changes in requirements
resulting in changes to software).  {}\textit{Importance:} Desired.

\end{enumerate}

\subsection{Basic interfaces for object-oriented iterative linear solvers}

\subsubsection{High-level model}

Figure {}\ref{belos:fig:BelosInterfacesSimple} shows a high-level
object-oriented model for the basic interfaces to iterative linear
solvers.  All of the UML classes shown in this diagram do not map
directly into C++ classes but this simple model will help to describe
the major features of the design and how this design meets several of
the requirements described above.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{BelosInterfacesSimple}
%}
\end{center}
\caption{
\label{belos:fig:BelosInterfacesSimple}
UML class diagram : High-level model of
the most basic interfaces for iterative linear solvers.}
\end{figure}
\esinglespace}

The roles of each of the high-level classes shown in Figure
{}\ref{belos:fig:BelosInterfacesSimple} is now described.

\begin{itemize}

\item{}\texttt{Client}:
The {}\textit{client} (as defined above in Section
{}\ref{sec:requirements}) shown in the UML diagram represents some
external piece of software that requires the services of an iterative
linear solver (such as a nonlinear ANA).  The client has direct
relationships with many of the other classes in the diagram as
depicted through the dotted lines (which represent dependency
relationships in UML).

\item{}\texttt{TSFCore::LinearOp}:
This class is used to abstract the linear operator for $\tilde{A}$ and
the optional left and right preconditioners $P_L$ and $P_R$
respectively.

\item{}\texttt{TSFCore::Vector}:
While not shown in the UML diagram, this class is used to abstract the
left and right scaling vectors $s_R$ and $s_L$ respectively.

\item{}\texttt{TSFCore::MultiVector}:
This class is used to abstract the multi-vector objects for the
multiple-RHS $B$ and the multiple-LHS solution $X$.

\item{}\texttt{Belos::BasicIteration}:
This is the base interface class for all iterative linear solvers.
This class serves in two roles.  In its first role this interface
decouples concrete {}\textit{iterative solver implementations} from
{}\textit{client} software and is the basic mechanism for delivering a
linear problem to be solved and for invoking the iterative solver.
The second role of this interface is to present basic information
about the progress of the iteration to a {}\texttt{Status\-Test}
object (described below).  Because of these two roles, this class is
broken up into two interfaces in the actual C++ interface classes
({}\texttt{Basic\-Iteration} and {}\texttt{Basic\-Iteration\-State}).

\item{}\texttt{IterativeSolverImplemenation}:
This is a place holder for any particular concrete {}\textit{iterative
solver implementation} such as block or non-block GMRES or block or
non-block CG.

\item{}\texttt{Belos::LinearProblem}:
This class serves in several related roles.  In its first role, the
{}\texttt{Linear\-Problem} object serves as a convenient common
aggregation of the operators, the scaling vectors and the RHS and LHS
multi-vector objects.  It is a {}\texttt{Linear\-Problem} that is
passed to a {}\texttt{Basic\-Iteration} object in order to solve a set
of linear systems.  In its second role, the {}\texttt{Linear\-Problem}
object provides basic services such as preprocessing the RHS and
post-processing the LHS for the {}\texttt{Basic\-Iteration} subclass
{}\texttt{Iterative\-Solver\-Implementation}.  The third role that
{}\texttt{Linear\-Problem} serves is as an interface that a
{}\texttt{Status\-Test} object can query to get unscaled
unpreconditioned residuals and other information if so desired.  This
concept of a {}\texttt{Linear\-Problem} class is broken up into three
interfaces that are customized for these three different roles
({}\texttt{Linear\-Problem\-Setup},
{}\texttt{Linear\-Problem\-Iteration} and
{}\texttt{Linear\-Problem\-State}).

\item{}\texttt{StatusTest}:
This abstract interface class decouples concrete {}\textit{iterative
solver implementations} away for specific types of status
(convergence) tests.  This allows a concrete {}\textit{iterative
solver implementation} to focus on its basic iteration, without having
to worry about when to stop (i.e.~converge).  A single
{}\texttt{Status\-Test} object is associated with a a single
{}\texttt{Linear\-Problem} object and this {}\texttt{Status\-Test}
object may know specific convergence test for individual RHSs in $B$
which forms the set of linear equations.

\item{}\texttt{MySpecializedStatusTest}:
This class is a place-holder for any particular concrete
{}\texttt{Status\-Test} subclass.  The {}\textit{client} knows about
the concrete type of this object but the {}\textit{iterative solver
implementation} does not (because it is abstracted through the
{}\texttt{StatusTest} interface).  While most concrete
{}\texttt{StatusTest} subclasses can get everything they need from the
{}\texttt{Basic\-Iteration} and {}\texttt{Linear\-Problem} interfaces
about the state of the iterative solver, this particular subclass
{}\texttt{My\-Specialized\-Status\-Test} shows that it has a
dependency on the the concrete
{}\texttt{Iterative\-Solver\-Implementation} subclass so as to take
advantage of some more specialized specific information about the
iteration.  Access to this derived type is accomplished through a
dynamic cast when needed.  However, in most cases, dynamic casting
should not be necessary.

\end{itemize}


\subsubsection{Design-level model}

Now that the basic object model for these interfaces has been
described we now show a more detailed design-level model where all the
UML classes map directly to actual C++ classes.  The basic
design-level model of the interfaces for iterative linear solvers is
shown in Figure {}\ref{belos:fig:BelosInterfaces}.

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[scale=0.72]{BelosInterfaces}
%}
\end{center}
\caption{
\label{belos:fig:BelosInterfaces}
UML class diagram : Design-level model
for the most basic interfaces for iterative linear solvers.}
\end{figure}
\esinglespace}

\subsubsection{Use case descriptions}

We now describe how the interfaces and various classes in Figure
{}\ref{belos:fig:BelosInterfaces} work in the context of the use cases
shown in Figure {}\ref{belos:fig:BelosUseCases}.  For each of these
use cases, we describe what classes and interfaces are involved and
how they collaborate together in order to implement the use case.

The use case descriptions will involve collaborations with the
following objects in pseudo-code:

\begin{tabular}{lll}
{\small\texttt{TSFCore::LinOp<Scalar>}} & {\small\texttt{A}} & : Unscaled operator $A$ \\
{\small\texttt{TSFCore::LinOp<Scalar>}} & {\small\texttt{A\_tilde}} & : Scaled operator $\tilde{A}$ \\
{\small\texttt{TSFCore::LinOp<Scalar>}} & {\small\texttt{P\_L}} & : Left preconditioner $P_L$ \\
{\small\texttt{TSFCore::LinOp<Scalar>}} & {\small\texttt{P\_R}} & : Right preconditioner $P_R$ \\
{\small\texttt{RefCountPtr<const TSFCore::Vector<Scalar> >}} & {\small\texttt{s\_R}} & : Left scaling vector $s_L$ \\
{\small\texttt{RefCountPtr<const TSFCore::Vector<Scalar> >}} & {\small\texttt{s\_R}} & : Right scaling vector $s_R$ \\
{\small\texttt{RefCountPtr<const TSFCore::MultiVector<Scalar> >}} & {\small\texttt{B}} & : RHS $B$ \\
{\small\texttt{RefCountPtr<TSFCore::MultiVector<Scalar> >}} & {\small\texttt{X}} & : RHS $X$ \\
{\small\texttt{RefCountPtr<StatusTest<Scalar> >}} & {\small\texttt{st}} & : A concrete status test object  \\
{\small\texttt{RefCountPtr<LinearProblemSetup<Scalar> >}} & {\small\texttt{lpup}} & : ``Setup'' interface to {}\texttt{lp} \\
{\small\texttt{RefCountPtr<LinearProblemIteration<Scalar> >}} & {\small\texttt{lpi}} & : ``Iteration'' interface to  {}\texttt{lp} \\
{\small\texttt{RefCountPtr<LinearProblemState<Scalar> >}} & {\small\texttt{lps}} & : Status test interface to  {}\texttt{lp} \\
{\small\texttt{RefCountPtr<BasicIteration<Scalar> >}} & {\small\texttt{bi}} & : A concrete basic iteration object
\end{tabular}

Note that {}\texttt{TSFCore::\-LinOp} is a small simple concrete class
whose only purpose for existence is to aggregate a smart pointer to a
{}\texttt{TSFCore::\-Linear\-Op} object and its ``mathematical''
definition of the nontranposed operator which is stored as a
{}\texttt{TSFCore::\-ETransp} enum object.

Most of these use cases do not involve very interesting dynamic
behavior but some do.  An overall UML diagram encompassing most or all
of these use cases into a single combined UML sequence diagram is
shown in Figure {}\ref{belos:fig:BelosSequence}.  The specific use
cases that are part of the scenario shown in Figure
{}\ref{belos:fig:BelosSequence} are described in more detail below as
well as variations on each of these use cases.

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[scale=0.85]{BelosSequence}
%}
\end{center}
\caption{
\label{belos:fig:BelosSequence}
UML sequence diagram : An example
scenario of an iterative block solver solving a set of right-hand
sides.}
\end{figure}
\esinglespace}

The first set of use cases involve the basic interactions of the
{}\textit{client} while the second set involve the interactions of the
{}\textit{iterative solver implementation}.

\subsubsection*{Use cases involving the {}\textit{client}}

\begin{enumerate}

\item Use case : \textbf{Setup linear problem}

{}\noindent{}Classes/interfaces involved : {}\texttt{Client},
{}\texttt{Linear\-Problem\-Setup}

This use case is very simple as it just involves the {}\texttt{Client}
setting up a {}\texttt{Linear\-Problem\-Setup} object with the
definition of the linear system.  This use case is not shown in Figure
{}\ref{belos:fig:BelosSequence}.  {}\texttt{Linear\-Problem\-Setup} is
not a concrete subclass but is only an interface.  The default
concrete subclass implementation {}\texttt{Linear\-Problem} is
provided and most {}\texttt{Client}s would use this class.  However,
there are some more specialized use cases where a different concrete
implementation may be needed.

In any case, a {}\texttt{Linear\-Problem\-Setup} object
{}\texttt{lpup} must be setup.  At a minimum, the linear problem
object must be setup with an operator, the RHS and LHS as follows:

{\scriptsize\begin{verbatim}
  lpup->setOperator(A);
  lpup->setRhs(B);
  lpup->setLhs(X);
\end{verbatim}}

If preconditioning but not scaling is used, then the linear problem
object {}\texttt{lpup} is setup as follows:

{\scriptsize\begin{verbatim}
  lpup->setOperator(A);
  lpup->setLeftPrec(P_L);
  lpup->setRightPrec(P_R);
  lpup->setRhs(B);
  lpup->setLhs(X);
\end{verbatim}}

If preconditioning and scaling is used, then the linear problem object
{}\texttt{lpup} is setup as follows:

{\scriptsize\begin{verbatim}
  lpup->setOperator(A_tilde);
  lpup->setLeftPrec(P_L);
  lpup->setRightPrec(P_R);
  lpup->setLeftScaling(s_L);
  lpup->setRightScaling(s_R);
  lpup->setRhs(B);
  lpup->setLhs(X);
\end{verbatim}}

Furthermore, the {}\texttt{Client} must set a single
{}\texttt{Status\-Test} object that defines the convergence criteria
for each of the columns in $B$ and $X$ as follows:

{\scriptsize\begin{verbatim}
  lpup->setStatusTest(st);
\end{verbatim}}

A {}\texttt{Status\-Test} subclass object can apply a different status
test for each individual column in $B$ (in which case it needs to know
how many columns there are in $B$ at a minimum) or can just apply a
generic status test (in which case it does not need to know how many
columns there are in $B$).

Finally, the block size $b$ as defined in Section
(\ref{sec:basic-block-solves}) to be used by block solvers can be set
as:

{\scriptsize\begin{verbatim}
  lpup->setBlockSize(blockSize);
\end{verbatim}}

This block size may be modified by the {}\textit{iterative solver
implementation} for instance if deflation, as described in Section
{}\ref{sec:basic-block-solves}X, is used.

{}\item Use case : \textbf{Iterate on linear problem}

{}\noindent{}Classes/interfaces involved : {}\texttt{Client},
{}\texttt{Basic\-Iteration}

The {}\texttt{Basic\-Iteration} interface abstracts the
{}\texttt{Linear\-Solver\-Implementation} away from the
{}\texttt{Client}.

The client sets the linear problem and starts the iteration as shown
in Figure {}\ref{belos:fig:BelosSequence} and as follows:

{\scriptsize\begin{verbatim}
  bi->setProblem(lpup);
  bi->initialize();
  bi->iterate(maxNumIters);
\end{verbatim}}

The {}\texttt{Basic\-Iteration::\-set\-Problem(...)} function accepts
a linear problem object through the
{}\texttt{Linear\-Problem\-Iteration} interface.  The
{}\texttt{Linear\-Problem\-Iteration} interface contains all of the
functionality that a {}\texttt{Linear\-Solver\-Implementation} needs
to solve the set of equations but does not contain functions to change
the definition of the linear problem (i.e.~an iterative solver can not
change the operator, the RHS or any of the preconditioners).  The
{}\texttt{Linear\-Problem\-Iteration} interface class is discussed in
more detail in the other use cases which are also shown in Figure
{}\ref{belos:fig:BelosUseCases} involving the {}\textit{iterative
solver implementation} .  The actual linear solver algorithm is
invoked using the {}\texttt{Basic\-Iteration::\-iterate(...)} function
which only returns when the {}\texttt{Status\-Test} object says to or
if the maximum number of iterations {}\texttt{maxNumIters} is reached.

{}\item Use case : \textbf{Retrieve ``solution''}

{}\noindent{}Classes/interfaces involved : {}\texttt{Client},
{}\texttt{Basic\-Iteration}, {}\texttt{Linear\-Problem\-Setup}

The final solution (or just the last candidate LHS if the solution was
not found) is obtained as shown in Figure
{}\ref{belos:fig:BelosSequence} and as follows:

{\scriptsize\begin{verbatim}
  bi->finalize();
  RefCountPtr<TSFCore::MultiVector<Scalar> > solution = bi->getProblem()->getLhs();
\end{verbatim}}

\end{enumerate}

\subsubsection*{Use cases involving the {}\textit{iterative solver implementation}}

All of the use cases involving the {}\textit{iterative solver
implementation} are wrapped in the above use case ``Iterate on linear
problem'' which is invoked using the function
{}\texttt{Linear\-Solver\-Implementation::\-iterate(...)}.  Pseudo
code for how this function might be implemented that is consistent
with Figure {}\ref{belos:fig:BelosInterfaces} and Figure
{}\ref{belos:fig:BelosSequence} is shown below:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void LinearSolverImplementation<Scalar>::iterate( const int maxNumIters )
  { 
    const int numTotalRhs = getProblem()->getTotalNumRhs();
    int numRhsSolved = 0;
    while( numRhsSolved < numTotalRhs ) {
      nextBlock(maxNumIters,&numRhsSolved);
    }
  }
\end{verbatim}}

Note that the fact that the function {}\texttt{nextBlock(...)} is
called iteratively is shown in Figure {}\ref{belos:fig:BelosSequence}
using an asterisk in {}\texttt{* nextBlock(...)} which is standard UML
notation for representing iteration in a UML sequence diagram
{}\cite{ref:uml_distilled_2nd_ed}.

These use cases are more complicated than those that just involved the
{}\textit{client} which where described above.  This is a good thing
since developers that write {}\textit{client} code are likely to be
less experienced C++ programmers.  Developers of
{}\texttt{Iterative\-Solver\-Implementation} subclasses are likely to
be more advanced C++ programmers but these interfaces should still try
to make the development of these subclasses as easy as possible.  To
help avoid mistakes, a minimal but complete interface to a linear
problem is presented to a {}\texttt{Iterative\-Solver\-Implementation}
through the {}\texttt{Linear\-Problem\-Iteration} interface.  This
interface allows the {}\texttt{Iterative\-Solver\-Implementation} to
setup the current RHS $\bar{B}$ and LHS $\bar{X}$ multi-vectors and
update the current estimate of the solution.  This interface, however,
does not allow a {}\texttt{Linear\-Problem\-Iteration} to accidentally
change the definition of the original RHS $B$, or the operator for the
matrix $\tilde{A}$ or $A$ or any of the preconditioners $P_L$ or
$P_R$.

\begin{enumerate}

{}\item Use case : \textbf{Setup to solve current block system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Linear\-Solver\-Implementation} and
{}\texttt{Linear\-Problem\-Iteration}

In this use case, the {}\texttt{Linear\-Solver\-Implementation} object
sets the linear problem object up for the next set of iterations on a
block of RHSs.  The {}\texttt{Linear\-Solver\-Implementation} object
tells the {}\texttt{Linear\-Problem\-Iteration} object {}\texttt{lpi}
which set of right-hand sides it will solve next and what block size
to use.  For a block linear solver that can gain from a multi-RHS
iteration, a non-unity block size will be set up.  For example, the
block size $b$ can be used to determine how many right-hand sides will
be iterated on next and what block size to use.

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void IterativeSolverImplementation<Scalar>::nextBlock( const int maxNumIters, int *numRhsSolved )
  {
    // Setup for next set of solves
    const int blockSize = lpi_->getBlockSize();
    const int firstRhsOffset = *numRhsSolved;  // Set the first column of next set of RHSs to solve.
    const int numRhsRemaining = lpi_->numTotalRhs()-numRhsSolved;
    const int numRhs = min(numRhsRemaining,blockSize); // Number of RHSs to solve next
    lpi_->setCurrSystem(firstRhsOffset,numRhs,blockSize,INITIALIZE_RHS_LHS);
    RefCountPtr<MultiVector<Scalar> >       currLhs = lpi_->getCurrLhs();
    RefCountPtr<const MultiVector<Scalar> > currRhs = lpi_->getCurrRhs();
    // Perform iterations
    for( int iter = 0; iter < numMaxIter; ++iter ) {
      doIteration();
    }
    // Copy current LHS into full LHS
    lpi_->setCurrToFullLhs();
    *numRhsSolved += numRhsRemaining;
  }
\end{verbatim}}

{}\noindent{}The {}\texttt{Linear\-Problem\-Iteration} {}\texttt{lpi}
object would be responsible for initializing {}\texttt{currRhs} and
{}\texttt{currLhs} multi-vectors with the appropriate columns from
{}\texttt{rhs} and {}\texttt{lhs} respectively inside of the call to
{}\texttt{set\-Curr\-System(...,\-INITIALIZE\_\-RHS\_\-LHS)}.  If
{}\texttt{set\-Curr\-System(...,\-NO\_\-INTIALIZE\_\-RHS\_\-LHS)} is
called then the solver would be responsible for initializing
{}\texttt{currRhs} and {}\texttt{currLhs}.  Above, if the block size
{}\texttt{blockSize} is larger than the number of right-hand sides
remaining {}\texttt{num\-Rhs\-Remaining}, then the {}\texttt{lpi}
object will by default pad the last {}\texttt{blockSize} -
{}\texttt{num\-Rhs\-Remaining} columns of the RHS and LHS with
arbitrary vectors as described in Section
{}\ref{sec:basic-block-solves}.

A {}\texttt{Linear\-Solver\-Implementation} that can only perform a
single-RHS iteration would ignore the block size and set the current
block size as 1 as:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void IterativeSolverImplementation<Scalar>::nextBlock(const int maxNumIters, int *numRhsSolved)
  {
    // Setup for next set of solves
    const int blockSize = 1;
    const int firstRhsOffset = *numRhsSolved;  // Set the first column of next set of RHSs to solve.
    const int numRhs = 1;
    lpi_->setCurrSystem(firstRhsOffset,numRhs,blockSize,INITIALIZE_RHS_LHS);
    RefCountPtr<MultiVector<Scalar> >       currLhs = lpi_->getCurrLhs();
    RefCountPtr<const MultiVector<Scalar> > currRhs = lpi_->getCurrRhs();
    // Perform iterations
    for( int iter = 0; iter < numMaxIter; ++iter ) {
      doIteration();
    }
    // Copy current solution into full solution
    lpi_->setCurrToFullsolution(*this);
    *numRhsSolved += 1;
  }
\end{verbatim}}

{}\item Use case : \textbf{Perform iteration(s) on current block
system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Linear\-Solver\-Implementation} and
{}\texttt{Linear\-Problem\-Iteration}

Really the only interaction between the
{}\texttt{Linear\-Solver\-Implementation} object and the
{}\texttt{Linear\-Problem\-Iteration} object needed in order to
perform a single iteration is in applying the operator and (optional)
preconditioners.  In order to insulate the
{}\texttt{Linear\-Solver\-Implementation} object from having to worry
about whether left and/or right preconditioning is being used the
function {}\texttt{Linear\-Problem\-State::\-apply\-Op(...)} is
provided that aggregates $\hat{A} = P_L \tilde{A} P_R$ into a single
operator application.

{}\noindent{}\textbf{Remark:} Consider defining a general aggregate
operator type for composed operators like $\hat{A} = P_L \tilde{A}
P_R$ and then simply expose that operator from the
{}\texttt{Linear\-Problem\-State} interface (calling it something like
{}\texttt{opAll}).  The only problem with this is that this might
suggest that this aggregate operator might be in TSFExtended which
would mean that TSFExtended could not depend on Belos.  This needs to
be worked out.

{}\item Use case : \textbf{Determine status of individual RHSs in 
current block system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Linear\-Solver\-Implementation}, {}\texttt{Status\-Test},
{}\texttt{Basic\-Iteration\-State}, {}\texttt{Linear\-Problem\-State}

This is one of the more complex use cases.  The goal of the design to
support this use case should be to make the development of
{}\texttt{Status\-Test} subclasses as easy as possible and to minimize
the mistakes that developers of {}\texttt{Status\-Test} subclasses can
make.  A variety of status tests can be developed ranging from the
very cheap (i.e.~no extra cost) to very expensive (i.e.~doubling or
more the cost of an iteration) without having to perform any dynamic
casting.

As shown in Figure {}\ref{belos:fig:BelosSequence}, after each
iteration of the iterative solver, the {}\texttt{Status\-Test} object
{}\texttt{st} is called as shown below:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void IterativeSolverImplementation<Scalar>::doIteration()
  {
    // Perform linear algebra for current iteration
    computeIteration();
    // Inform if the current solution is set or not
    lpi_->setSolutionUpdated(solutionUpdated_);
    // Check the status of current set of linear systems
    std::vector<StatusType> status(numCurrRhs_);
    lpi_->getStatusTest()->checkStatus(this,currNumRhs_,&status[0]);
    ...
  }
\end{verbatim}}

Before the status test is invoked, the
{}\texttt{Linear\-Solver\-Implementation} object informs the
{}\texttt{Linear\-Problem\-Iteration} object if the solution
multi-vector {}\texttt{currLhs} is currently up to date or not.  This
is performed by the call to
{}\texttt{lpi\_->\-set\-Solution\-Updated(\-solution\-Updated\-)} where
{}\texttt{solution\-Updated} is a {}\texttt{bool}ean that is
determined by the type of solver algorithm.  For example, GMRES would
set {}\texttt{solution\-Updated=false} since it can not cheaply
maintain the current solution while CG would set
{}\texttt{solution\-Updated=true} since CG does automatically maintain
the current solution.  In the scenario in Figure
{}\ref{belos:fig:BelosSequence}, the
{}\texttt{Linear\-Solver\-Implementation} object sets this to
{}\texttt{false}.

After the status of the current estimate of the solution is set, the
{}\texttt{Status\-Test} object {}\texttt{st} is invoked by calling its
virtual {}\texttt{checkStatus(...)} member function where the solver
passes itself as the first argument as shown above. By passing the
solver to the {}\texttt{Status\-Test} object, even the most
specialized status tests can be implemented through dynamic casting.

Once this {}\texttt{Status\-Test} object is activated, it calls back
on the {}\texttt{Basic\-Iteration\-State} and
{}\texttt{Linear\-Problem\-State} interfaces to determine the status
of the current linear systems being solved.  The status of any
iterative solver can be queried by invoking any of the methods on
{}\texttt{Basic\-Iteration\-State} and
{}\texttt{Linear\-Problem\-State} (which is returned from the
{}\texttt{Basic\-Iteration\-State\-::get\-Problem()} function).
Specifically, the member functions shown in Figures
{}\ref{fig:BasicIterationState-functions} and
{}\ref{fig:LinearProblemState-functions} return the the derived
attributes defined in Section {}\ref{sec:basic-block-solves}.

\begin{figure}

\fbox{
\begin{minipage}{\textwidth}

{\scriptsize{}\noindent{}\texttt{int getCurrNumIters() const}} \\
$\bullet$ Returns the total current number of iterative solver
iterations over all restarts.

{\scriptsize{}\noindent{}\texttt{int getCurrNumRestarts() const}} \\
$\bullet$ Returns the total current number of iterative solver
restarts (really only applicable to GMRES).

{\scriptsize{}\noindent{}\texttt{void getCurrNativeResiduals( Scalar
norms[], MultiVector<Scalar>** residuals = NULL ) const}} \\ $\bullet$
Returns the norms of the current native residual $n_j =
||\breve{R}_{(:,j)}||$ for each of the current RHSs $\bar{B}$ in the
array output argument {}\texttt{norms[]} (length $\bar{b}$) and
optionally a pointer to the native residual multi-vector in
{}\texttt{*residuals} if such a multi-vector is being maintained
(e.g.~CG will have this residual multi-vector while GMRES will not).
Note that all iterative solvers must be able to return the norms array
{}\texttt{norms[]}.

{\scriptsize{}\noindent{}\texttt{const LinearProblemState<Scalar>\&
getProblem() const}} \\ $\bullet$ Returns reference to the
{}\texttt{Linear\-Problem\-State} object {}\texttt{lps}.

\end{minipage}
} % \fbox

\caption{\label{fig:BasicIterationState-functions}
Derived attribute functions for {}\texttt{Basic\-Iteration\-State}
interface.  }

\end{figure}

\begin{figure}

\fbox{
\begin{minipage}{\textwidth}


{\scriptsize{}\noindent{}\texttt{int getTotalNumRhs() const}} \\
$\bullet$ Returns the total number of RHSs $m$.

{\scriptsize{}\noindent{}\texttt{const Vector<Scalar>* getRhsScaling()
const}} \\ $\bullet$ Returns pointer to optional scaling vector $s_R$.

{\scriptsize{}\noindent{}\texttt{const Vector<Scalar>* getLhsScaling()
const}} \\ $\bullet$ Returns pointer to optional scaling vector $s_L$.

{\scriptsize{}\noindent{}\texttt{int getCurrBlockSize() const}} \\
$\bullet$ Returns the current block size $\bar{b}$.

{\scriptsize{}\noindent{}\texttt{int getCurrNumRhs() const}} \\
$\bullet$ Returns the current number of RHSs $\bar{m}$.

{\scriptsize{}\noindent{}\texttt{void getCurrRhsIndexes( int
currRhsIndexes[] ) const}} \\ $\bullet$ Returns array
{}\texttt{curr\-Num\-Indexes[]} of length $\bar{b}$ of indexes that
define mapping matrix $\bar{Q}$.  Note that entires in
{}\texttt{curr\-Num\-Indexes[]} for artificial augmented columns are
given a negative value to distinguish these columns from columns in
the original RHS $B$.

{\scriptsize{}\noindent{}\texttt{const MultiVector<Scalar>\&
getCurrInitResidual() const}} \\ $\bullet$ Returns reference to
current initial residual multi-vector $\bar{R}_0$.

{\scriptsize{}\noindent{}\texttt{RefCountPtr<const MultiVector<Scalar>
> getCurrRhs() const}} \\ $\bullet$ Returns smart pointer to
non-mutable current RHS $\bar{B}$.

{\scriptsize{}\noindent{}\texttt{RefCountPtr<const MultiVector<Scalar>
> getCurrInitLhs() const}} \\ $\bullet$ Returns smart pointer to
non-mutable current initial LHS $\bar{X}_{0,r}$ for the current
restart.

{\scriptsize{}\noindent{}\texttt{RefCountPtr<MultiVector<Scalar> >
getCurrLhs() const}} \\ $\bullet$ Returns smart pointer to mutable
current LHS $\bar{X}$ for the current restart.

{\scriptsize{}\noindent{}\texttt{const MultiVector<Scalar>\&
getCurrResidual() const}} \\ $\bullet$ Returns reference to current
residual multi-vector $\bar{R}$.

\end{minipage}
} % \fbox

\caption{\label{fig:LinearProblemState-functions}
Derived attribute functions for {}\texttt{Linear\-Problem\-State}
interface.  }

\end{figure}

Note that all of the derived atrributes $\bar{R}_0$, $\bar{X}$ and
$\bar{R}$ that may require extra computation have boolean query
functions that return whether or not these derived attributes have
been updated or not yet.  This allows {}\texttt{Status\-Test} objects
to be fully informed when extra compuation will be performed or not
and may even adjust what status tests are performed based on this
information.  These query functions are shown in Figure
{}\ref{fig:LinearProblemState-bool-functions}.

\begin{figure}

\fbox{
\begin{minipage}{\textwidth}

{\scriptsize{}\noindent{}\texttt{bool isCurrInitResidualUpdated()
const}} \\ $\bullet$ Returns {}\texttt{true} if $\bar{R}_0$ is
currently updated.

{\scriptsize{}\noindent{}\texttt{bool isCurrLhsUpdated() const}} \\
$\bullet$ Returns {}\texttt{true} if $\bar{X}$ is currently updated.

{\scriptsize{}\noindent{}\texttt{bool isCurrResidualUpdated() const}}
\\ $\bullet$ Returns {}\texttt{true} if $\bar{R}$ is currently
updated.

\end{minipage}
} % \fbox

\caption{\label{fig:LinearProblemState-bool-functions}
Derived attribute boolean query functions for
{}\texttt{Linear\-Problem\-State} interface.  }

\end{figure}


The scenario in Figure {}\ref{belos:fig:BelosSequence} shows a
norm-based status test being used.  In this case, converged solutions
must satisfy

\[
||\bar{R}_{(:,j)}|| / ||(\bar{R}_0)_{(:,j)}|| \leq \eta_{l_{(j)}}, \;
\mbox{for} j = 1 \ldots \bar{m}.
\]

The following pseudo-code shows how this {}\texttt{Status\-Test}
subclass might implement this status test:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void ResidNormStatusTest<Scalar>::checkStatus(
    const BasicIterationState<Scalar>   &bis
    ,const int                          currNumRhs   // == bis.getProblem().getCurrNumRhs()
    ,StatusType                         status[]     // Array length currNumRhs
    )
  {
    const LinearProblemState<Scalar> &lps = bis.getProblem();
    // Force the computation of the current solution if it is not already available
    if(!lps.isCurrLhsUpdated()) bis.forceCurrLhsUpdate();
    // Get the initial and current residuals and their norms
    const MultiVector<Scalar> &R_bar_0 = lps.getCurrInitResidual(); // Is cached internally
    const MultiVector<Scalar> &R_bar  = lps.getCurrResidual();     // Is cached internally
    std::vector<Scalar> R_bar_0_nrms(currNumRhs), R_bar_nrms(currNumRhs);
    norms( *R_bar_0, &R_bar_0_nrms[0] ); 
    norms( *R_bar, &R_bar_nrms[0] );
    // Get the mapping of the current RHSs to the original full RHSs
    std::vector<int> currRhsIndexes(currNumRhs);
    lps.getCurrRhsIndexes(&currRhsIndexes[0]);
    // Enforce different tolerances for each original RHS
    for( int k = 0; k < numCurrRhs; ++k ) {
      const int origRhsIndex = currRhsIndexes[k];
      if( R_bar_nrm[k]/R_bar_0_nrm[k] < tols_[origRhsIndex] )  status[k] = STATUS_CONVERGED;
      else                                                     status[k] = STATUS_UNCONVERGED;
    }
  }
\end{verbatim}}

The above example status test function can match a particular column
in the current residual $\bar{R}$ with an original column in the full
RHS $B$ by calling the function
{}\texttt{Linear\-Problem\-State::\-getCurrRhsIndexes(...)}  which
returns an array of indexes mapping the current RHSs to the original
RHSs.  The returned integer array essentially defines the mapping
matrix $\bar{Q}$ defined in Section {}\ref{sec:basic-block-solves}.
These returned indexes (in the array {}\texttt{currRhsIndexes}) are
used to select potentially different tolerances from the private array
{}\texttt{tols\_} (where {}\texttt{tols\_} was setup by the client
before invoking the linear solver).

{}\texttt{Status\-Test} subclasses can also be easily setup that do
not require the current solution or unscaled unpreconditioned residual
but instead base the status test on the number of linear solver
iterations (by checking
{}\texttt{Basic\-Iteration\-State::\-get\-Curr\-Num\-Iters()}), the
number of restart iterations (i.e.~for GMRES by checking
{}\texttt{Basic\-Iteration\-State::\-get\-Curr\-Num\-Restarts()}), or
the native residual norms $n_j = ||\breve{R}_{(:,j)}||$ (returned by
calling
{}\texttt{Basic\-Iteration\-State::\-get\-Curr\-Native\-Residuals(...)}).
Every implementation of {}\texttt{Basic\-Iteration} (and therefore
{}\texttt{Basic\-Iteration\-State}) is required to maintain an
estimate of the norm(s) of the current block of linear systems.  The
native norms $n_j = ||\breve{R}_{(:,j)}||$ are returned by the
function
{}\texttt{Basic\-Iteration\-State::\-getCurrNativeResidual(...)}.  The
following function shows how to check the native residual norms for a
simple norm-based status test subclass that only compares to a single
tolerance:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void NativeNormStatusTest<Scalar>::checkStatus(
    const BasicIterationState<Scalar>   &bis
    ,const int                          currNumRhs   // == bis.getProblem().getCurrNumRhs()
    ,StatusType                         status[]     // Array length currNumRhs
    )
  {
    // Get the native norms
    std::vector<Scalar> R_native_nrms(currNumRhs);
    bis.getCurrNativeResiduals( &R_native_nrns[0] );
    // Enforce the same tolerance for all RHSs
    for( int k = 0; k < numCurrRhs; ++k ) {
      const int origRhsIndex = currRhsIndexes[k];
      if( R_native_nrm[k] < tol_ )  status[k] = STATUS_CONVERGED;
      else                          status[k] = STATUS_UNCONVERGED;
    }
  }
\end{verbatim}}

Note that the above {}\texttt{NativeNormStatusTest} subclass is
independent of the number of RHSs being solved and is likely to be a
very common type of status test in many cases.

{}\item Use case : \textbf{Deflate current block system removing
``converged'' RHSs}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Linear\-Solver\-Implementation} and
{}\texttt{Linear\-Problem\-Iteration}

After the {}\texttt{Status\-Test} object {}\texttt{st} has determined
which systems have been sufficiently converged then the
{}\texttt{Linear\-Solver\-Implementation} object can optionally remove
or deflate these systems from the current set of RHSs.  For some block
solvers, like block GMRES, it is not possible to deflate during an
iterative run but for others, like block CG, deflation is possible.
In any case, if the {}\texttt{Linear\-Solver\-Implementation} object
decides to remove some systems that have been converged, then it can
tell the {}\texttt{Linear\-Problem\-Iteration} object {}\texttt{lpi}
which RHSs these are and they will be removed as follows:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void IterativeSolverImplementation<Scalar>::doIteration(...)
  {
    ..
    // Deflate systems that are converged
    int numToRemove = 0;
    std::vector<int> indexesToRemove(lpi_->getCurrNumRhs());
    for( int k = 0; k < lpi_->getNumCurrRhs(); ++k )
      if(status[k]==STATUS_CONVERGED) indexesToRemove[numToRemove++] = currRhsIndexes[k];
    lpi_->deflate(*this,numToReomve,&indexesToRemove[0]);
    ..
  }
\end{verbatim}}

The above call to {}\texttt{deflate(...)} will result in a callback to
the {}\texttt{Basic\-Iteration\-State} interface to get the solution
for the converged and deflated RHSs.  The following is an
implementation of the {}\texttt{deflate(...)} function:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void LinearProblem<Scalar>::defalate( const BasicIterationState &bis
      ,const int numToRemove, const int indexesToRemove[]  )
  {
    // Get the current "conveged" LHSs
    RefCountPtr<MultiVector<Scalar> > currConvLhs;
    if( this->isCurrLhsUpdated() ) // Already updated?  Just grab them from a view!
      currConvLhs = this->getCurrLhs()->subView(numToRemove,indexesToRemove);
    else                           // Not already updated?  Force just the computation of these!  
      currConvLhs = bis.getCurrLhs(numToRemove,indexesToRemove);
    // Get the full indexes of converged LHSs
    std::vector<int> currRhsIndexes(currNumRhs);
    this->getCurrRhsIndexes(&currRhsIndexes[0]);
    std::vector<int> fullIndexesToRemove(numToRemove);
    for( int k = 0; k < numToRemove; ++k ) fullIndexesToRemove[k] = currRhsIndexes[indexesToRemove[k]];
    // Set the converged current LHS to full LHS
    const RefCountPtr<MultiVector<Scalar> > lhs = this->getLhs();
    assign( &*lhs->subView(numToRemove,&fullIndexesToRemove[0]), *currConvLhs );
  }
\end{verbatim}}

In the above function, if the current LHS solution $\bar{X}$ is not
updated then the function
{}\texttt{Basic\-Iteration\-State\-::get\-Curr\-Lhs(...)} with the
indexes of only the LHSs that are ``converged'' and not all the
current LHS.  Note that calling the function
{}\texttt{Basic\-Iteration\-State\-::force\-Curr\-Lhs\-Update()} would
result in unecessary compuations since it would also compute columns
for LHSs that are not converged and these current LHS would simply be
thrown away.

In addition, after the {}\texttt{deflate(...)} function the
{}\texttt{Linear\-Solver\-Implementation} would also have to deflate
its data structures for ``converged'' the RHSs being removed.

{}\item Use case : \textbf{Finalize computation of ``solution'' of
current block system}

{}\noindent{}Classes/interfaces involved :
{}\texttt{Linear\-Solver\-Implementation} and
{}\texttt{Linear\-Problem\-Iteration}

After the {}\texttt{Status\-Test} object determines that all of the
current linear systems are solved for, the
{}\texttt{Linear\-Solver\-Implementation} object would then update
those components of the final solution by simply calling the function

{\scriptsize\begin{verbatim}
   lpi_->setCurrToFullLhs(*this);
\end{verbatim}}

{}\noindent{}as shown in the pseudo code for the function
{}\texttt{nextBlock(...)} shown above.  This function calls back on
the {}\texttt{Basic\-Iteration\-State\-::force\-Curr\-Lhs\-Update()}
function to get the solution for whatever converged RHSs that have not
already been deflated out and then sets these into the full LHS.  An
implementation of the {}\texttt{set\-Curr\-To\-Full\-Lhs(...)} 
function is shown below:

{\scriptsize\begin{verbatim}
  template <class Scalar>
  void LinearProblem<Scalar>::setCurrToFullLhs( const BasicIterationState &bis )
  {
    // Get the current "conveged" LHSs
    bis.forceCurrLhsUpdate()
    const RefCountPtr<const MultiVector<Scalar> > currLhs = this->getCurrLhs();
    // Get the full indexes of converged LHSs
    const int currNumRhs = this->currNumRhs();
    std::vector<int> currRhsIndexes(currNumRhs);
    this->getCurrRhsIndexes(&currRhsIndexes[0]);
    // Set the converged current LHS to full LHS
    const RefCountPtr<MultiVector<Scalar> > lhs = this->getLhs();
    assign( &*lhs->subView(currNumRhs,&currRhsIndexes[0]), *currLhs );
  }
\end{verbatim}}

\end{enumerate}

\subsection{Concrete iterative solver implementations}

There are several iterative linear solver implementations that support
these interfaces:

\begin{enumerate}
\item Block flexible (and regular) GMRES (Heidi)
\item Block CG (Heidi)
\item Non-block flexible (and regular) GMRES (with only single RHS) (Ross/Heidi)
\item Non-block CG (with simple multiple RHS) (Ross)
\item Non-block BiCG (with simple multiple RHS ) (Ross)
\item Non-block BiCGStab (with only single RHS) (Kevin)
\end{enumerate}

\section{Summary}

The interfaces described in this document provide a very flexible and
efficient means to implement a wide range of iterative linear solvers
in such a way as to maximize reuse.

% ---------------------------------------------------------------------- %% References
%
\clearpage
\bibliographystyle{plain}
\bibliography{references}
\addcontentsline{toc}{section}{References}

% ---------------------------------------------------------------------- %
% Appendices should be stand-alone for SAND reports. If there is only
% one appendix, put \setcounter{secnumdepth}{0} after \appendix
%
%\appendix
%\input{apdx_TSFCoreClassDecl}

\begin{SANDdistribution}
% External
\SANDdistExternal{1}{} Carl Laird \\ Department Chemical Engineering\\Carnegie Mellon University\\5000 Forms Ave.\\Pittsburgh, PA 15213
\SANDdistExternal{1}{} Matthias Heinkenschloss \\ Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Bill Symes\\Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Tony Padula\\Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Mark Gockenbach \\ Department of Mathematical Sciences\\Michigan Technological University\\ 
1400 Townsend Drive\\Houghton, Michigan 49931-1295, U.S.A.
\SANDdistExternal{1}{} Paul Sexton \\ Box 1560 \\ St. John's University \\ Collegeville, MN 56321
\SANDdistExternal{1}{} Andreas Wachter \\  \\ IBM Watson Research Center \\
???Address???
% Sandia Line
%\SANDdistInternal{1}{0847}{Bill Camp}{9200}
%\SANDdistInternal{1}{0847}{Sudip Dosanjh}{9233}
% 9211
\SANDdistInternal{1}{0370}{Scott Mitchell}{9211}
\SANDdistInternal{1}{0370}{David Gay}{9211}
\SANDdistInternal{1}{0370}{Roscoe Bartlett}{9211}
\SANDdistInternal{1}{0370}{Scott Collis}{9211}
\SANDdistInternal{1}{0370}{Bart van Bloemen Waanders}{9211}
\SANDdistInternal{1}{0370}{Mike Eldred}{9211}
\SANDdistInternal{1}{0370}{Laura Swiler}{9211}
% 9214
\SANDdistInternal{1}{9159}{Mark Adams}{9214}
\SANDdistInternal{1}{1110}{Pavel Bochev}{9214}
\SANDdistInternal{1}{1110}{Todd Coffey}{9214}
\SANDdistInternal{1}{1110}{David Day}{9214}
\SANDdistInternal{1}{1110}{John Delaurentis}{9214}
\SANDdistInternal{1}{1110}{Michael Heroux}{9214}
\SANDdistInternal{1}{1110}{Ulrich Hetmaniuk}{9214}
\SANDdistInternal{1}{9217}{Jonathan Hu}{9214}
\SANDdistInternal{1}{1110}{Richard Lehoucq}{9214}
\SANDdistInternal{1}{1110}{Louis Romero}{9214}
\SANDdistInternal{1}{1110}{David Ropp}{9214}
\SANDdistInternal{1}{1110}{Mazio Sala}{9214}
\SANDdistInternal{1}{1110}{Kendall Stanley}{9214}
\SANDdistInternal{1}{1110}{Heidi Thornquist}{9214}
\SANDdistInternal{1}{9217}{Raymond Tuminaro}{9214}
\SANDdistInternal{1}{1110}{James Willenbring}{9214}
% 9215
\SANDdistInternal{1}{1110}{William Hart}{9215}
\SANDdistInternal{1}{1110}{Erik Boman}{9215}
% 9233
% 9210
%\SANDdistInternal{1}{1110}{David Womble}{9210}
% 8962
%\SANDdistInternal{1}{9159}{Steve Thomas}{8962}
\SANDdistInternal{1}{9159}{Paul Boggs}{8962}
\SANDdistInternal{1}{9159}{Kevin Long}{8962}
\SANDdistInternal{1}{9159}{Patricia Hough}{8962}
\SANDdistInternal{1}{9159}{Tamara Kolda}{8962}
\SANDdistInternal{1}{9159}{Monica Martinez-Canales}{8962}
\SANDdistInternal{1}{9159}{Pamela Williams}{8962}
\SANDdistInternal{1}{9159}{Victoria Howle}{8962}
% Sandia Misc
%\SANDdistInternal{1}{0847}{Steve Wojtkiewicz}{9124}
% Xyce developers
\SANDdistInternal{1}{0316}{Eric Keiter}{9233}
\SANDdistInternal{1}{0316}{Scott Hutchinson}{9233}
\SANDdistInternal{1}{0316}{Robert Hoekstra}{9233}
% Premo developers
\SANDdistInternal{1}{0316}{Curt Ober}{9233}
\SANDdistInternal{1}{0316}{Tom Smith}{9233}
\SANDdistInternal{1}{0316}{Russel Hooper}{9233}
% Main Sierra developers
\SANDdistInternal{1}{0382}{Carter Edwards}{9143}
\SANDdistInternal{1}{0382}{James Stewart}{9143}
\SANDdistInternal{1}{0316}{Alan Williams}{9143}
% Main Nevada developers
\SANDdistInternal{1}{0617}{Ricard Drake}{9231}
% NOX/LOCA developers
\SANDdistInternal{1}{0316}{Roger Pawlowski}{9233}
\SANDdistInternal{1}{0316}{Eric Phipps}{9233}
\SANDdistInternal{1}{1110}{Andrew Salinger}{9233}
\SANDdistInternal{1}{1110}{Brett Bader}{9233}
% Charon developers
\SANDdistInternal{1}{0316}{Gary Hennigan}{9233}
% Other Trilinos developers
% Housekeeping copies necessary for every unclassified report:
\SANDdistInternal{1}{9018}{Central Technical Files}{8945-1}
\SANDdistInternal{2}{0899}{Technical Library}{9610}
\SANDdistInternal{2}{0612}{Review \& Approval Desk}{4916}
% If report has a Patent Caution or Patent Interest, add this:
%\SANDdistInternal{3}{0161}{Patent and Licensing Office}{4916}
\end{SANDdistribution}

\end{document}
