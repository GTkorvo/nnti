\documentclass[pdf,ps2pdf,11pt]{SANDreport}
\usepackage{pslatex}

%Local stuff
\usepackage{graphicx}
\usepackage{latexsym}
\input{rab_commands}

% If you want to relax some of the SAND98-0730 requirements, use the "relax"
% option. It adds spaces and boldface in the table of contents, and does not
% force the page layout sizes.
% e.g. \documentclass[relax,12pt]{SANDreport}
%
% You can also use the "strict" option, which applies even more of the
% SAND98-0730 guidelines. It gets rid of section numbers which are often
% useful; e.g. \documentclass[strict]{SANDreport}

% ---------------------------------------------------------------------------- %
%
% Set the title, author, and date
%

\title{ Overview of Fundamental Thyra Operator/Vector Interfaces }
\author{
Roscoe A. Bartlett \\ Optimization/Uncertainty Estim \\ \\
Sandia National Laboratories\footnote{
Sandia is a multiprogram laboratory operated by Sandia Corporation, a
Lockheed-Martin Company, for the United States Department of Energy
under Contract DE-AC04-94AL85000.}, Albuquerque NM 87185 USA, \\
}
\date{}

% ---------------------------------------------------------------------------- %
% Set some things we need for SAND reports. These are mandatory
%
\SANDnum{SAND2005-xxx}
\SANDprintDate{??? 2005}
\SANDauthor{
Roscoe A. Bartlett \\ Optimization/Uncertainty Estim \\ \\
}

% ---------------------------------------------------------------------------- %
% The following definitions are optional. The values shown are the default
% ones provided by SANDreport.cls
%
\SANDreleaseType{Unlimited Release}
%\SANDreleaseType{Not approved for general release}

% ---------------------------------------------------------------------------- %
% The following definition does not have a default value and will not
% print anything, if not defined
%
%\SANDsupersed{SAND1901-0001}{January 1901}

% ---------------------------------------------------------------------------- %
%
% Start the document
%
\begin{document}

\maketitle

% ------------------------------------------------------------------------ %
% An Abstract is required for SAND reports
%

%
\begin{abstract}
%
Engineering and scientific applications are becoming increasingly modular,
utilizing publicly defined interfaces to integrate third party tools and
libraries for services such as mesh generation, data partitioning, equation
solvers and optimization.  As a result, it is important to understand and
model the interaction between these various modules, and to develop good
abstract interfaces between the primary modules.  One category of modules that
is becoming increasingly important is abstract numerical algorithms (ANAs).
ANAs such as linear and nonlinear equation solvers, methods for stability and
bifurcation analysis, uncertainty quantification methods and nonlinear
programming solvers for optimization are typically mathematically
sophisticated but have surprisingly little essential dependence on the details
of what computer system is being used or how matrices and vectors are stored
and computed.  As a result, using abstract interface capabilities in languages
such as C++, we can implement ANA software such that it will work, unchanged,
with a variety of applications and linear algebra libraries.

In this paper we present a package of minimal but complete (with respect to
basic required functionality and performance) object-oriented operator/vector
interfaces (implemented in C++) in the Thyra package which form the foundation
for the development many of these ANAs and simplifies the development of
interfaces to applications and linear algebra libraries.
%
\end{abstract}
%

% ------------------------------------------------------------------------ %
% An Acknowledgement section is optional but important, if someone made
% contributions or helped beyond the normal part of a work assignment.
% Use \section* since we don't want it in the table of context
%
\clearpage
\section*{Acknowledgement}
The authors would like to thank ...

The format of this report is based on information found
in~\cite{Sand98-0730}.

% ------------------------------------------------------------------------ %
% The table of contents and list of figures and tables
% Comment out \listoffigures and \listoftables if there are no
% figures or tables. Make sure this starts on an odd numbered page
%
\clearpage
\tableofcontents
\listoffigures
%\listoftables

% ---------------------------------------------------------------------- %
% An optional preface or Foreword
%\clearpage
%\section{Preface}
%Although muggles usually have only limited experience with
%magic, and many even dispute its existence, it is worthwhile
%to be open minded and explore the possibilities.

% ---------------------------------------------------------------------- %
% An optional executive summary
%\clearpage
%\section{Summary}
%Once a certain level of mistrust and scepticism has
%been overcome, magic finds many uses in todays science
%and engineering. In this report we explain some of the
%fundamental spells and instruments of magic and wizardry. We
%then conclude with a few examples on how they can be used
%in daily activities at national Laboratories.

% ---------------------------------------------------------------------- %
% An optional glossary. We don't want it to be numbered
%\clearpage
%\section*{Nomenclature}
%\addcontentsline{toc}{section}{Nomenclature}
%\begin{itemize}
%\item[alohomora]
%spell to open locked doors and containers
%\end{itemize}

% ---------------------------------------------------------------------- %
% This is where the body of the report begins; usually with an Introduction
%
\SANDmain % Start the main part of the report

\section{Introduction}

One area of steady improvement in large-scale engineering and
scientific applications is the increased modularity of application
design and development.  Specification of publicly-defined interfaces,
combined with the use of third-party software to satisfy critical
technology needs in areas such as mesh generation, data partitioning
and solution methods have been generally positive developments in
application design.  While the use of third party software introduces
dependencies from the application developer's perspective, it also
gives the application access to the latest technology in these areas,
amortizes library and tool development across multiple applications
and, if properly designed, gives the application easy access to more
than one option for each critical technology area, e.g., access to
multiple linear solver packages.

One category of modules that is becoming increasingly important is abstract
numerical algorithms (ANAs).  ANAs such as linear and nonlinear equation
solvers, methods for stability and bifurcation analysis, transient solvers,
uncertainty quantification methods and nonlinear programming solvers for
optimization are typically mathematically sophisticated but have surprisingly
little essential dependence on the details of what computer system is being
used or how matrices and vectors are stored and computed.  Thus, by using
abstract interface capabilities in languages such as C++, we can implement ANA
software such that it will work, unchanged, with a variety of applications and
linear algebra libraries.  Such an approach is often referred to as {\it
generic programming}~\cite{ref:boost_generic_programming}.

In this paper we describe a set of basic operator/vector interfaces provided
in the Trilinos package Thyra that form the foundation for (i) ANA
development, (ii) the integration of an ANA into an application (APP) and
(iii) providing services to the ANA from a linear algebra library (LAL).  By
agreeing on a simple minimal common interface layer such as the foundational
Thyra operator/vector interfaces, we eliminate the many-to-many dependency
problem of ANA/APP interfaces.  These fundamental Thyra interfaces is not
primarily designed to be the most convenient interface for the direct
development of ANAs but it can be used in direct ANA development.  Instead,
these interfaces are designed to make it easier for developers to provide the
basic functionality from APPs and LALs required for the implementation of
ANAs.

While these Thyra interfaces provide a mechanism to express all of the
functionality required to be directly used in ANA development it does not
attempt to provide a full collection of methods that directly support the
anticipated functionality needs of ANAs.  Instead they rely on a simple but
powerful reduction and transformation operator mechanism~\cite{ref:rtop_toms}
that can be used to express any element-wise vector reduction or
transformation operation.  Additional functionality to support both the
devleopment of ANAs and the implementation of the operator/vector interfaces
is being added to the Thyra package all the time but this is not the focus of
this discussion.

It is difficult to describe a set of linear algebra interfaces outside
of the context of some class of numerical problems.  For this purpose,
we will consider numerical algorithms where it is possible to
implement all of the required operations exclusively through well
defined interfaces to vectors, vector spaces and linear operators.
The interfaces described here are the common denominator of all
abstract numerical algorithms.

We assume that the reader has a basic understanding of vector
reduction/transformation operators (RTOp) (see
{}\cite{ref:rtop_toms}), is comfortable with object-orientation
{}\cite{ref:gama_et_al_1995} and C++, and knows how to read basic
Unified Modeling Language (UML) {}\cite{ref:uml_distilled_2nd_ed}
class diagrams.  We also assume that the reader has some background in
large-scale numerics and will therefore be able to appreciate the
challenges that are addressed by Thyra.

To motivate the fundamental Thyra operator/vector interfaces, we discuss the
context for Thyra in large-scale (both in lines of code and in problem
dimensionality) numerical software in
Section~\ref{tsfcore:sec:classification_of_lin_alg_itfc}.  The major
requirements for Thyra are spelled out in
Section~\ref{tsfcore:sec:Thyra_requirements}.  This is followed by an overview
of the Thyra linear algebra interfaces in
Section~\ref{tsfcore:sec:Thyra_core_overview} and a detailed discussion of the
design of the Thyra linear algebra interfaces in
Section~\ref{tsfcore:sec:Thyra_Details} including numerous examples.  A
discussion of some of the object-oriented and other general software design
concepts and principles that have gone into the development of Thyra is
deferred to Section~\ref{tsfcore:sec:general_software_concepts}.  Some of the
nonessential but convenient functionality that is useful to direct ANA
developers that is missing in Thyra is described in
Section~\ref{tsfcore:sec:convenience_functionality}.

Note that the online documentation for Thyra at
{}\texttt{http://software.sandia.gov/Trilinos/packages/thyra} should be the
definitive information source for Thyra.  This document only tries to discuss
some of the more significant issues associated with Thyra and discuss its
rational for existence.

%
\section{Classification of linear algebra interfaces}
\label{tsfcore:sec:classification_of_lin_alg_itfc}
%

Although we will discuss APPs, ANAs and LALs in detail later in this
section, we want to briefly introduce these terms here to make them
clear.  Also, although there are certainly other types of modules in a
large-scale application, we only focus on these three.
\begin{itemize}
\item Application (APP):  The modules of an application that are not
ANA or LAL modules.  Typically this includes the code that is unique
to the application itself such as the code that formulates and
generates the discrete problem.  In general it would also include
other third-party software that is not an ANA or LAL module.
\item Abstract Numerical Algorithm (ANA):  Software that drives a 
solution process, e.g., an iterative linear or nonlinear solver.  This
type of package provides solutions to and requires services from the
APP, and utilizes services from one or more LALs.  It can usually be
written so that it does not depend on the details of the computer
platform, or the details of how the APP and LALs are implemented, so
that an ANA can be used across many APPs and with many LALs.
\item Linear Algebra Library (LAL): Software that provides the 
ability to construct
concrete linear algebra objects such as matrices and vectors.  
A LAL can also be a specific linear solver or preconditioner.
\end{itemize}

An important focus of this paper is to clearly identify the interfaces
between APPs, ANAs and LALs for the purposes of defining the Thyra
interface.

The requirements for the linear algebra objects as imposed by an ANA
are very different from the requirements imposed by an APP code.  In
order to differentiate the various types of interfaces and the
requirements associated with each, consider Figure
{}\ref{tsfcore:fig:ANA_LAL_APP}.  This figure shows the three major
categories of software modules that make up a complete numerical
application.  The first category is application (APP) software in
which the underlying data is defined for the problem.  This could be
something as simple as the right-hand-side and matrix coefficients of
a single linear system or as complex as a finite-element method for a
3-D nonlinear PDE-constrained optimization problem.  The second
category is linear algebra library (LAL) software that implements
basic linear algebra operations {}\cite{ref:demmel_1997,
ref:anderson_1995, ref:blackford_et_al_1997, ref:aztec, ref:petsc,
ref:trilinos}. These types of software include primarily matrix-vector
multiplication, the creation of a preconditioner (e.g.~ILU), and may
even include several different types of direct linear solvers.  The
third category is ANA software that drives the main solution process
and includes such algorithms as iterative methods for linear and
nonlinear systems; explicit and implicit methods for ODEs and DAEs;
and nonlinear programming (NLP) solvers
{}\cite{ref:nocedal_wright_1999}.  There are many example software
packages {}\cite{ref:petsc,ref:aztec,ref:trilinos,ref:pvode,ref:tao}
that contain ANA software.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[bb= 0.245in 2.95in 10.85in 8.60in,angle=0,scale=0.50
]{analal}
%}
\end{center}
\caption{
\label{tsfcore:fig:ANA_LAL_APP}
UML {}\cite{ref:booch_et_al_1999} class diagram : Interfaces between abstract numerical algorithm
(ANA), linear algebra library (LAL), and application (APP) software.
}
\end{figure}
\esinglespace}

The types of ANAs described here only require operations like
matrix-vector multiplication, linear solves and certain types of
vector reduction and transformation operations.  All of these
operations can be performed with only a very abstract view of vectors,
vector spaces and linear operators.

An application code, however, has the responsibility of populating
vector and matrix objects and requires the passing of explicit
function and gradient value entries, sometimes in a distributed memory
parallel environment.  This is the purpose of a APP/LAL interface.
This involves a very different set of requirements than those
described above for the ANA/APP and ANA/LAL interfaces.  Examples of
APP/LAL interfaces include the FEI {}\cite{ref:fei} and much of the
current TSF.

Figure {}\ref{tsfcore:fig:ANA_LAL_APP} also shows a set of LAL/LAL
interfaces that allows linear algebra objects from one LAL to
collaborate with the objects from another LAL.  Theses interfaces are
very similar to the APP/LAL interfaces and the requirements for this
type of interface is also not addressed by Thyra.  The ESI
{}\cite{ref:esi_2001} and much of the current TSF contain examples of
LAL/LAL interfaces.

Thyra, as described in this paper, specifies only the
ANA/LAL interface.  Thyra-based ANA/APP interfaces are
described elsewhere (e.g. {}\cite{ref:Thyra::Nonlin}).

%
\section{Thyra: Basic Requirements}
\label{tsfcore:sec:Thyra_requirements}
%

Before describing the C++ interfaces for Thyra, some basic
requirements are stated.

\begin{enumerate}

\item
Thyra interfaces should be portable to all the ASC
{}\cite{ref:doe_asci} platforms where SIERRA {}\cite{ref:SIERRA} and
other ASC applications might run.  However, a platform where C++
templates are fundamentally broken will not be a supported platform
for Thyra.

\item
Thyra interfaces should provide for stable and accurate numerical
computations at a fundamental level.

\item
Thyra should provide a minimal, but complete, interface that
addresses all the basic efficiency needs (in both speed and storage)
which will result in near-optimal implementations of all of the linear
algebra objects and all of the above mentioned ANA algorithms that use
these objects.  All other types of nonessential but convenient
functionality (e.g.~Matlab-like syntax using operator overloading, see
Section~\ref{tsfcore:sec:operator_overloading}) will not be
addressed by Thyra.  This extra functionality can be built on top
the basic Thyra abstractions (e.g.~using TSF).

\item
ANAs developed with Thyra should be able to transparently utilize
different types of computing environments such as SPMD\footnote{Single
Program Multiple Data (SPMD): A single program running in a
distributed-memory environment on multiple parallel processors},
client/server\footnote{Client/Server: The ANA runs in a process on a
client computer and the APP and LAL run in processors on a server} and
out-of-core\footnote{Out-of-core: The data for the problem is stored
on disk and is read from and written to back disk as needed}
implementations.

\item
The work required to implement adapter subclasses (see the ``Adapter''
pattern in {}\cite{ref:gama_et_al_1995}) for and with Thyra should
be minimal and straightforward for all of the existing related linear
algebra and ANA interfaces (e.g.~the linear algebra interfaces in
MOOCHO {}\cite{ref:moochouserguide} and NOX {}\cite{ref:nox}).  This
requirement is facilitated by the fact that the Thyra interfaces are
minimal.

\end{enumerate}

A hand-coded program (e.g.~using Fortran 77 and MPI) should not
provide any significant gains in performance in any of the above
categories in any computing environment.  If a hand-coded algorithm in
Fortran 77 with MPI can significantly improvements in storage
requirements, computational speed or numerial stability.  There are
many numerical algorithms can can not be considered to be ``abstract''
and therefore Thyra and like abstract interfaces should not be used
for such algorithms.

%
\section{Thyra Operator/Vector Interfaces: Overview}
\label{tsfcore:sec:Thyra_core_overview}
%

The basic linear algebra abstractions that make up Thyra are shown
in Figure {}\ref{thyra:fig:basic_op_vec_itfc}.  Complete C++ class
declarations for these interfaces are given in Appendix
{}\ref{app:tsfcore_classes}.  The key abstractions include vectors,
vector spaces and linear operators.  All of the interfaces are
templated on the {}\texttt{Scalar} type (the UML notation for
templated classes is not used in the figure for the sake of improving
readability).

Vector space is the foundation for all other linear algebra
abstractions.  Vector spaces are abstracted through the
{}\texttt{\textit{Vector\-Space\-Base}} interface.  A
{}\texttt{\textit{Vector\-Space\-Base}} object acts primarily as an ``Abstract
Factory'' {}\cite{ref:gama_et_al_1995} that creates vector objects
(which are the ``products'' in the ``Abstract Factory'' design
pattern).

Vectors are abstracted through the {}\texttt{\textit{Vector\-Base}}
interface.  The {}\texttt{\textit{Vector\-Base}} interface is very minimal
and really only defines one nontrivial function
{}\texttt{\textit{applyOp(\-...)}}.  The
{}\texttt{\textit{applyOp(\-...)}} function accepts user-defined
(i.e.~ANA-defined) reduction/transformation operator (RTOp) objects
through the templated RTOp C++ interface
{}\texttt{\textit{RTOpPack::RTOpT}}.  A set of standard vector
operations is provided as nonmember functions using standard RTOp
subclasses (see Section~\ref{tsfcore:sec:vector}).  The set of
operations is also easily extensible.  Every
{}\texttt{\textit{Vector\-Base}} object provides access to its
{}\texttt{\textit{Vector\-Space\-Base}} (that was used to create the
{}\texttt{\textit{Vector\-Base}} object) through the function
{}\texttt{space()} (shown in Figure {}\ref{thyra:fig:basic_op_vec_itfc} as
the role name {}\texttt{space} on the association connecting the
{}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Vector\-Space\-Base}}
classes).

The {}\texttt{\textit{Vector\-Space\-Base}} interface also provides the
ability to create {}\texttt{\textit{Multi\-Vector\-Base}} objects through
the {}\texttt{\textit{createMembers(numMembers)}} function.  A
{}\texttt{\textit{Multi\-Vector\-Base}} is a tall thin dense matrix where
each column in the matrix is a {}\texttt{\textit{Vector\-Base}} object which
is accessible through the {}\texttt{\textit{col(...)}} function.
{}\texttt{\textit{Multi\-Vector\-Base}}s are needed for near-optimal
processor cache performance (in serial and parallel programs) and to
minimize the number of global communications in a distributed parallel
environment.  The {}\texttt{\textit{Multi\-Vector\-Base}} interface is
useful in many different types ANAs as described later.  The interface
class {}\texttt{\textit{Vector\-Base}} is derived from
{}\texttt{\textit{Multi\-Vector\-Base}} so that every
{}\texttt{\textit{Vector\-Base}} is a {}\texttt{\textit{Multi\-Vector\-Base}}.
This simplifies the development of ANAs in that any ANA that can
handle {}\texttt{\textit{Multi\-Vector\-Base}} objects should automatically
be able to handle {}\texttt{\textit{Vector\-Base}} objects as well.  The
somewhat complex relationship between {}\texttt{\textit{Vector\-Base}} and
{}\texttt{\textit{Multi\-Vector\-Base}} is described in Section ???.

{}\texttt{\textit{Vector\-Space\-Base}} also declares a virtual function
called {}\texttt{\textit{scalarProd(x,y)}} which computes the scalar product
$<x,y>$ for the vector space. This function has a default implementation based
on the dot product $x^T y$.  Subclasses can override the
{}\texttt{\textit{scalarProd(x,y)}} function for other, more specialized,
application-specific definitions of the scalar product. There is also a
{}\texttt{\textit{Multi\-Vector\-Base}} version
{}\texttt{\textit{Vector\-Space\-Base\-::scalarProds(...)}} (not shown in the
figure).  Finally, {}\texttt{\textit{Vector\-Space\-Base}} also includes the
ability to determine the compatibility of vectors from different vector spaces
through the function {}\texttt{\textit{isCompatible(vecSpc)}} (see
Section~\ref{tsfcore:sec:vec_spc_compatibility}).  The concepts behind the
design of the {}\texttt{\textit{Vector\-Space\-Base}},
{}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Multi\-Vector\-Base}}
interfaces are discussed later in Section~\ref{tsfcore:sec:vec_space},
Section~\ref{tsfcore:sec:vector} and Section~\ref{tsfcore:sec:multi_vec}
respectively.

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[bb= 0.0in 0.0in 3.3in 4.4in,scale=0.40
]{UML1}
%}%fbox
%\fbox{
\includegraphics*[scale=0.65]{ThyraOperatorVector}
%}%fbox
\end{center}
\caption{
\label{thyra:fig:basic_op_vec_itfc}
UML class diagram : Major components of the TSF
interface to linear algebra
}
\end{figure}
\esinglespace}

Another important type of linear algebra abstraction is a linear
operator which is represented by the interface class
{}\texttt{\textit{Linear\-Op\-Base}}.  The {}\texttt{\textit{Linear\-Op\-Base}}
interface is used to represent quantities such as a Jacobian matrix. A
{}\texttt{\textit{Linear\-Op\-Base}} object defines a linear mapping from
vectors in one vector space (called the {}\texttt{domain}) to vectors
in another vector space (called the {}\texttt{range}).  Every
{}\texttt{\textit{Linear\-Op\-Base}} object provides access to these vector
spaces through the functions {}\texttt{domain()} and {}\texttt{range()}
(shown as the role names {}\texttt{domain} and {}\texttt{range} on the
associations linking the {}\texttt{\textit{OpBase}} and
{}\texttt{\textit{Vector\-Space\-Base}} classes).  The exact form of this
mapping, as implemented by the function
{}\texttt{\textit{apply(\-...)}}, is
%
\begin{equation}
y = \alpha \, op(M) \, x + \beta y
\label{tsfcore:equ:apply_vec}
\end{equation}
%
where $M$ is a {}\texttt{\textit{Linear\-Op\-Base}} object; $x$ and $y$ are
{}\texttt{\textit{Vector\-Base}} objects; and $\alpha$ and $\beta$ are
{}\texttt{Scalar} objects.  Note that the linear operator in
(\ref{tsfcore:equ:apply_vec}) is shown as $op(M)$ where $op(M) = M$ or $M^T$
(depending on the argument {}\texttt{M\_trans}). This implies that both the
non-transposed and transposed (i.e.~adjoint) linear mappings can be performed.
However, support for transposed (adjoint) operations by a
{}\texttt{\textit{Linear\-Op\-Base}} object are only optional.  If an
operation is not supported then the function
{}\texttt{\textit{opSupported(M\_trans)}} will return {}\texttt{false} (see
Section~\ref{tsfcore:sec:linear_op_adjoints}).  Note that when $op(M) = M^T$,
then $x$ and $y$ must lie in the {}\texttt{range} and {}\texttt{domain} spaces
respectively which is the opposite for the case where $op(M) = M$.

In addition to implementing linear mappings for single
{}\texttt{\textit{Vector\-Base}} objects, the {}\texttt{\textit{Linear\-Op\-Base}}
interface also provides linear mappings of
{}\texttt{\textit{Multi\-Vector\-Base}} objects through an overloaded function
{}\texttt{\textit{apply(\-...)}} which performs
%
\begin{equation}
Y = \alpha \, op(M) \, X + \beta Y
\label{tsfcore:equ:apply_multi_vec}
\end{equation}
%
where $X$ and $Y$ are {}\texttt{\textit{Multi\-Vector\-Base}} objects.  The
{}\texttt{\textit{Multi\-Vector\-Base}} version of the
{}\texttt{\textit{apply(\-...)}} function has a default implementation based
on the {}\texttt{\textit{Vector\-Base}} version.  The
{}\texttt{\textit{Vector\-Base}} version {}\texttt{\textit{apply(\-...)}}  is
a pure virtual function and therefore must be overridden by subclasses.  The
issues associated with supporting the {}\texttt{\textit{Multi\-Vector\-Base}}
version verses the {}\texttt{\textit{Vector\-Base}} version of this function
are described in Section~\ref{tsfcore:sec:vector_vs_multivector}.

Section~\ref{tsfcore:sec:Thyra_Details} goes into much more detail behind the
design philosophy for the core interfaces and the use of these interfaces by
both clients and subclass developers.

%
\section{Thyra Operator/Vector Interfaces: Details and Examples}
\label{tsfcore:sec:Thyra_Details}
%

A basic overview of the interface classes shown in Figure
{}\ref{thyra:fig:basic_op_vec_itfc} was provided in
Section~\ref{tsfcore:sec:Thyra_core_overview}.  In the following sections, we
go into more detail about the design of these interfaces and give examples of
the use of these classes.  Note that in all the below code examples it is
assumed that the code is in a source file which include the appropriate header
files.

%
\subsection{A motivating example linear sub-ANA : Compact limited-memory BFGS}
\label{tsfcore:sec:LBFGS}
%

{\bsinglespace
\begin{figure}[t]
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.60]{LBFGS}
%}%fbox
\end{center}
\caption{
\label{tsfcore:fig:LBFGS}
A compact limited-memory representation of the inverse of a BFGS matrix.
}
\end{figure}
\esinglespace}

To motivate the following discussion and to provide examples, we
consider the issues involved in using Thyra to implement an ANA for
the compact limited-memory BFGS (LBFGS) method described in
{}\cite{ref:byrd_et_all_lbfgs_1994}.  BFGS and other variable-metric
quasi-Newton methods are used to approximate a Hessian matrix
$B\in\RE^{n \times n}$ of second derivatives.  This approximation is
then used to generate search directions for various types of
optimization algorithms.  The Hessian matrix $B$ and/or its inverse $H
= B^{-1}$ is approximated using only changes in the gradient $y =
\nabla f(x_{k+1}) - \nabla f(x_k) \in \RE^n$ of some multi-variable scalar
function $f(x)$ for changes in the variables $s = x_{k+1} - x_k \in
\RE^n$.  A set of matrix approximations $B_k$ are formed using rank-2
updates where each update takes the form
%
\begin{equation}
B_{k+1} = B_k - \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k} + \frac{y_k y_k^T}{y_k^T s_k}.
\end{equation}

In a limited-memory BFGS method, only a fixed maximum number
$m_{\tiny\mbox{max}}$ of updates are stored
%
\begin{eqnarray}
S & = & {\bmat{cccc} s_1 & s_2 & \ldots & s_{m} \emat} \label{tsfcore:eqn:LBSFGS_S} \; \in \; \RE^{n \times m}\\
Y & = & {\bmat{cccc} y_1 & y_2 & \ldots & y_{m} \emat} \label{tsfcore:eqn:LBSFGS_Y} \; \in \; \RE^{n \times m}
\end{eqnarray}
%
where $m \le m_{\tiny\mbox{max}}$ is the current number of stored
updates and $S$ and $Y$ are multi-vectors (note that the subscripts in
(\ref{tsfcore:eqn:LBSFGS_S})--(\ref{tsfcore:eqn:LBSFGS_Y}) correspond
to column indexes in the multi-vector objects, not iteration counters
$k$).  When an optimization algorithm begins, $m=0$ and $m$
incremented each iteration until $m = m_{\tiny\mbox{max}}$ after which
the method starts dropping older update pairs $(s,y)$ to make room for
newer ones.  In a compact LBFGS method, the inverse $H$ (shown in
Figure {}\ref{tsfcore:fig:LBFGS}) of the quasi-Newton matrix $B$
(where when the index $k$ is dropped, it implicitly refers to the
current iteration $B_k$) on is approximated using the tall thin
multi-vectors $S$ and $Y$ along with a small (serial) coordinating
matrix $Q$ (which is computed and updated from $S$ and $Y$).  The
scalar $\gamma$ is chosen for scaling reasons and $H_0 = B_0^{-1} =
\gamma I$ represents the initial matrix approximation from which the
updates are performed.  A similar compact formula also exists for $B$
which involves the same matrices (and requires solves with $Q$).  In
an SPMD configuration, the multi-vectors $Y$ and $S$ may contain
vector elements spread over many processors.  However, the number of
columns $m$ in $S$ and $Y$ is usually less than $40$.  Because of the
small number of columns in $S$ and $Y$, all of the linear algebra
performed with the matrix $Q$ is performed serially using dense
methods (i.e.~BLAS and LAPACK).  A parallel version of the compact
LBFGS method is implemented, for example, as an option in MOOCHO.
Thyra supports efficient versions of all of the operations needed
for a near-optimal parallel implementation of this LBFGS method.

The requirements for this sub-ANA will be mentioned in several of the
following sections along with example code.

%
\subsection{\texttt{\textit{Vector\-Space\-Base}}}
\label{tsfcore:sec:vec_space}
%

The basic design of the {}\texttt{\textit{Vector\-Space\-Base}} interface was
taken directly from the Hilbert Class Library (HCL) {}\cite{ref:hcl}
which is also used in {}\textit{AbstractLinAlgPack} (the basic linear
algebra interfaces in MOOCHO [???]).

We now show a simple code example as to the use of the
{}\texttt{\textit{Vector\-Space\-Base}} and {}\texttt{\textit{Vector\-Base}}
interfaces.  The following code snippet shows a function that performs
several types of tasks:

{\scriptsize\begin{verbatim}
temaplate<class Scalar>
void Thyra::foo0( const VectorSpaceBase<Scalar>& vecSpc, const LinearOpBase<Scalar>& M )
{
  TEST_FOR_EXCEPTION(!vecSpc.isCompatible(*M.domain()),std::logic_error,"Error!"); // Check compatibility
  Teuchos::RefCountPtr<VectorBase<Scalar> > x = vecSpc.createMember();             // Create new vector x
  Teuchos::RefCountPtr<VectorBase<Scalar> > y = M.range()->createMember();         // Create new vector y
  assign(x.get(),1.0);                                                             // x = 1.0
  M.apply(NOTRANS,*x,y.get());                                                     // y = M*x
  M.apply(TRANS,*y,x.get(),0.5,0.1);                                               // x = 0.5*M*y + 0.1*x
}
\end{verbatim}}

{}\noindent{}The above code snippet shows how memory management in Thyra is
handled -- through the templated smart reference-counted pointer class
{}\texttt{Teuchos\-::RefCountPtr<>} (see
Section~\ref{tsfcore:sec:general_software_concepts}).  The vector objects
pointed to by the objects {}\texttt{x} and {}\texttt{y} are accessed in
various ways in the last three lines.  For instance, in the statement

{\scriptsize\begin{verbatim}
  assign(x.get(),1.0);
\end{verbatim}}

{}\noindent{}the raw C++ pointer (of type {}\texttt{VectorBase<Scalar>*}) to the
underlying vector object is returned using the function
{}\texttt{RefCountPtr<>\-::get()}.  The function {}\texttt{assign(...)} is
implemented through an RTOp object and its implementation is shown in
Section~\ref{tsfcore:sec:vec_apply_op}.  The next statement

{\scriptsize\begin{verbatim}
  M.apply(NOTRANS,*x,y.get());
\end{verbatim}}

{}\noindent{}shows the created vectors being passed into the
{}\texttt{apply(\-...)}  function of a {}\texttt{\textit{Linear\-Op\-Base}}
object.  The expression {}\texttt{*x} invokes the function
{}\texttt{RefCountPtr<>\-::operator*()} which returns a reference (of
type {}\texttt{VectorBase<Scalar>\&}) to the underlying vector object.

%
\subsubsection{Creation of {}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Multi\-Vector\-Base}} objects}
\label{tsfcore:sec:vec_spc_create}
%

As stated above, one of the major roles of a
{}\texttt{\textit{Vector\-Space\-Base}} object is as an abstract factory for
{}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Multi\-Vector\-Base}}
objects.  The primary creational functions are:

{\scriptsize\begin{verbatim}
template<class Scalar>
class VectorSpaceBase {
public:
  ...
  virtual Teuchos::RefCountPtr< VectorBase<Scalar> > createMember() const = 0;
  virtual Teuchos::RefCountPtr< MultiVectorBase<Scalar> > createMembers(int numMembers) const;
  ...
};
\end{verbatim}}

These creational functions return smart reference-counted pointers to
the created {}\texttt{\textit{Vector\-Base}} and
{}\texttt{\textit{Multi\-Vector\-Base}} objects.  Note that the multi-vector creational function
{}\texttt{\textit{create\-Members(...)}} takes an argument {}\texttt{num\-Members} that determines
the number of columns in the mulit-vector object.

%
\subsubsection{Creation of {}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Multi\-Vector\-Base}} objects
from in-core views of data}
\label{tsfcore:sec:vec_spc_create_view}
%

In very rare occasions in order to achieve near-optimal performance it
is necessary that {}\texttt{\textit{Vector\-Base}} and
{}\texttt{\textit{Multi\-Vector\-Base}} objects be created as views of raw
data that is owned by the client.  The functions that allow this are:

{\scriptsize\begin{verbatim}
template<class Scalar>
class VectorSpaceBase {
public:
  ...
  virtual Teuchos::RefCountPtr<VectorBase<Scalar> > createMemberView(
            const RTOpPack::MutableSubVectorT<Scalar> &raw_v ) const;
  virtual Teuchos::RefCountPtr<const VectorBase<Scalar> > createMemberView(
            const RTOpPack::SubVectorT<Scalar> &raw_v ) const;
  virtual Teuchos::RefCountPtr<MultiVectorBase<Scalar> > createMembersView(
            const RTOpPack::MutableSubMultiVectorT<Scalar> &raw_mv ) const;
  virtual Teuchos::RefCountPtr<const MultiVectorBase<Scalar> > createMembersView(
            const RTOpPack::SubMultiVectorT<Scalar> &raw_mv ) const;
  ...
};
\end{verbatim}}

These functions create both mutable and non-mutable views of raw data.
Note that efficient implementations of such views are only possible
for vector and multi-vectors that have all data stored locally or
in-core.  Such views can be created efficiently for serial and SPMD
vectors and multi-vectors.  Serial and SPMD subclasses should overide
these functions the create the views in an efficient way.

These view functions all have default implementations that create temporary
{}\texttt{\textit{Vector\-Base}} or {}\texttt{\textit{Multi\-Vector\-Base}}
objects (using the using the basic {}\texttt{\textit{create\-Member()}} and
{}\texttt{\textit{create\-Members()}} functions respectively), then copy in
data (using the explicit element access functions described in Section ??? and
Section ???) and then for mutable views (just before the vector or
multi-vector is destroyed) copy the data in the temporary vector and
multi-vector objects back into the raw data arrays.  Because of these default
implemenations, these functions are supported automatically by every vector
and multi-vector implementation and these default implementations my not be a
performance problem in many different use cases.

%
\subsubsection{General compatibility of {}\texttt{\textit{Vector\-Base}} objects}
\label{tsfcore:sec:vec_spc_compatibility}
%

There is one important aspect that distinguishes
{}\texttt{Thyra\-::\textit{Vector\-Space\-Base}} from vector space interfaces
in HCL and TSF for instance.  In HCL 1.0, the compatibility of vector spaces
is tested with a virtual {}\texttt{operator==(...)}  function.  This implies
that vector spaces will be compatible only if they are of the same concrete
type and have the same setup.  Ideally, however, we do not want to require
that only vectors and vector spaces with the same {\em concrete} type to be
compatible but instead we would like to allow vectors and vector spaces of the
same {\em general} type be compatible.  To see the difference, consider
parallel programs running in an SPMD configuration where vector elements are
partitioned across processors and communication is handled using MPI
{}\cite{ref:mpi}.  There are several different linear algebra libraries that
are designed to work in such an environment such as Aztec {}\cite{sd:aztec},
Epetra {}\cite{ref:Epetra} and PETSc {}\cite{ref:petsc}.  Thyra adapter
subclasses would be created for vectors and vector spaces for each of these
packages.  In principle, all implementations of SPMD MPI vectors that have the
same partitioning of elements to processors should be compatible, regardless
of which underlying libraries are involved.  The RTOp design, given the
appropriate {}\texttt{\textit{Vector\-Space\-Base}} and
{}\texttt{\textit{Vector\-Base}} interfaces, allows the seamless integration
of vectors of different {\em concrete} types given the same {\em general}
type.  If all of these adapter subclasses inherited from the node interface
classes {}\texttt{\textit{MPIVectorSpaceBase}} and
{}\texttt{\textit{MPIVectorBase}} (see the Doxygen documentation) which
include an appropriate set of abstract functions (like determining
compatibility of maps and access to local vector data), then Epetra vectors
should be transparently compatible with PETSc and Aztec vectors and so on.
This type of interoperability is demonstrated for serial vectors and vector
spaces in Section~\ref{tsfcore:sec:serial_vecs}

%
\subsection{\texttt{\textit{Vector\-Base}}}
\label{tsfcore:sec:vector}
%

The core design principles behind the {}\texttt{\textit{Vector\-Base}}
interface and the {}\texttt{\textit{applyOp(\-...)}} function (which
accepts RTOp objects) are described in {}\cite{ref:rtop_toms}.  The
benefits of the RTOp approach can be summarized as follows.

\begin{enumerate}
\item
LAL developers need only implement one operation ---
{}\textit{\texttt{applyOp(\-...)}} --- and not a large collection of
primitive vector operations.
\item
ANA developers can implement {}\textit{specialized} vector operations
without needing any support from LAL maintainers.
\item
ANA developers can optimize time consuming vector operations on their
own for the platforms they work with.
\item
Reduction/transformation operators are more efficient than using
primitive operations and temporary vectors.
\item
ANA-appropriate vector interfaces that desire built-in standard vector
operations (i.e.~axpy and norms) can use RTOp operators for the
implementations of these operations (for example, see
{}\textit{TSFExtended\-::\texttt{Vector\-Base}}).
\end{enumerate}

{\bsinglespace
\begin{figure}[p]
\begin{minipage}{\textwidth}
{\scriptsize\begin{verbatim}
----------------------------------------------------------------------------------------------------
// ThyraVectorStdOpsDecl.hpp
...
namespace Thyra {
template<class Scalar> Scalar sum( const VectorBase<Scalar>& v );                 // result = sum(v(i))
template<class Scalar> Scalar norm( const VectorBase<Scalar>& v );                // result = sqrt(<v,v>)
template<class Scalar> Scalar norm_1( const VectorBase<Scalar>& v );              // result = ||v||1
template<class Scalar> Scalar norm_2( const VectorBase<Scalar>& v );              // result = ||v||2
template<class Scalar> Scalar norm_inf( const VectorBase<Scalar>& v_rhs );        // result = ||v||inf
template<class Scalar> Scalar dot( const VectorBase<Scalar>& x
                                   ,const VectorBase<Scalar>& y );                // result = x'*y
template<class Scalar> Scalar get_ele( const VectorBase<Scalar>& v, Index i );    // result = v(i)
template<class Scalar> void set_ele( Index i, Scalar alpha
                                     ,VectorBase<Scalar>* v );                    // v(i) = alpha
template<class Scalar> void assign( VectorBase<Scalar>* y, const Scalar& alpha ); // y = alpha
template<class Scalar> void assign( VectorBase<Scalar>* y
                                    ,const VectorBase<Scalar>& x );               // y = x
template<class Scalar> void Vp_S( VectorBase<Scalar>* y, const Scalar& alpha );   // y += alpha
template<class Scalar> void Vt_S( VectorBase<Scalar>* y, const Scalar& alpha );   // y *= alpha
template<class Scalar> void Vp_StV( VectorBase<Scalar>* y, const Scalar& alpha
                                    ,const VectorBase<Scalar>& x );               // y = alpha*x + y
template<class Scalar> void abs( VectorBase<Scalar>* y, const VectorBase<Scalar>& x );// y(i) = abs(x(i))
template<class Scalar> void reciprocal( VectorBase<Scalar>* y
                                        ,const VectorBase<Scalar>& x );           // y(i) = 1/x(i)
template<class Scalar> void ele_wise_prod( const Scalar& alpha
    ,const VectorBase<Scalar>& x, const VectorBase<Scalar>& v, VectorBase<Scalar>* y );// y(i)+=alpha*x(i)*v(i)
template<class Scalar> void ele_wise_divide( const Scalar& alpha
    ,const VectorBase<Scalar>& x, const VectorBase<Scalar>& v, VectorBase<Scalar>* y );// y(i)=alpha*x(i)/v(i)
template<class Scalar> void linear_combination( const int m                       // y(i) = beta*y(i)
                             ,const Scalar alpha[], const VectorBase<Scalar>* x[] // + alpha[0]*x[0](i)+...
                             const Scalar &beta, VectorBase<Scalar> *y );         // +.alpha[m-1]*x[m-1](i)
template<class Scalar> void seed_randomize( unsigned int );                   // Seed for randomize()
template<class Scalar> void randomize( Scalar l, Scalar u, VectorBase<Scalar>* v );// v(i) = random(l,u)
} // end namespace Thyra
----------------------------------------------------------------------------------------------------
\end{verbatim}}
\end{minipage}
\caption{
\label{tsfcore:fig:std_vec_ops}
Some standard vector operations declared in the header file
{}\texttt{Thyra\-Vector\-Std\-Ops\-Decl.hpp} and defined in the
{}\texttt{Thyra\-Vector\-Std\-Ops.hpp} header file. 
}
\end{figure}
\esinglespace}

The {}\texttt{\textit{applyOp(\-...)}}  function is described in more detail
in Section~\ref{tsfcore:sec:vec_apply_op}.  Note that this approach does not
hinder the development of convenience functions in any way.  In fact, a set of
basic operations is already available in the header file
{}\texttt{Thyra\-Vector\-Std\-Ops\-Decl.hpp}.  The declarations for the
functions in this file are shown in Figure {}\ref{tsfcore:fig:std_vec_ops}.
Note, to use these template functions you should include the definitions from
{}\texttt{Thyra\-Vector\-Std\-Ops.hpp} (never directly {}\texttt{\#include} a
{}\texttt{xxxDecl.hpp} file unless you know what you are doing, instead,
include the {}\texttt{xxx.hpp} file for all of the Thyra code).  Using one of
these non-member vector functions is transparently obvious and there is not
even one hint that the function {}\texttt{\textit{Vector::applyOp(\-...)}} is
involved.

%
\subsubsection{\texttt{\textit{Vector::applyOp(\-...)}}}
\label{tsfcore:sec:vec_apply_op}
%

Several important issues regarding the specification of the
{}\texttt{\textit{Vector::applyOp(\-...)}} function were not discussed
in {}\cite{ref:rtop_toms}.  Before describing these issues, note that
the {}\texttt{\textit{Vector\-::applyOp(\-...)}} function is not
directly called by a client (it is protected) but instead is called
through a non-member (friend) function of the same name.  This is done
to provide a uniform way to deal with all of the allowed permutations
of the number and types of vector arguments to this function when the
function is called by the client.  Therefore, we will only consider
the prototype for the non-member function
{}\texttt{Thyra::appyOp(...)}  which is

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::applyOp(
  const RTOpPack::RTOpT<Scalar> &op
  ,const size_t num_vecs, const VectorBase<Scalar>* vecs[]
  ,const size_t num_targ_vecs , VectorBase<Scalar>* targ_vecs[]
  ,RTOpPack::ReductTarget *reduct_obj
  ,const Index first_ele = 1, const Index sub_dim = 0, const Index global_offset = 0
  );
\end{verbatim}}

{}\noindent{}and has nine arguments: the RTOp object that defines the
reduction/transformation operation to be performed {}\texttt{op}; the
non-mutable input vectors specified by {}\texttt{num\_vecs} and
{}\texttt{vecs[]} (\texttt{num\_vecs==0} and {}\texttt{vecs==NULL}
allowed); the mutable input/output vectors specified by
{}\texttt{num\_targ\_vecs} and {}\texttt{targ\-\_vecs[]}
(\texttt{num\_targ\_vecs==0} and {}\texttt{targ\_vecs==NULL} allowed);
the input/output opaque reduction target object {}\texttt{reduct\_obj}
(must be set to {}\texttt{NULL} if no reduction is defined); the range
of elements defining the sub-vector to apply the operator to specified
by {}\texttt{first\_ele} and {}\texttt{sub\_dim}; and the global
offset {}\texttt{global\_offset} to use when applying
coordinate-variant operators.

The role of the first five arguments in
{}\texttt{Thyra::applyOp(\-...)}  should be clear from the
discussion in {}\cite{ref:rtop_toms}.  However, the special handling
of the object {}\texttt{reduct\_obj} and the use cases where the last
three arguments are important need to be carefully explained since
they are critical to the success of this design.  In short, what this
specification allows is the ability to take {}\texttt{\textit{Vector\-Base}}
objects and then be able to put together abstract compositions of them
to create new (logical) vector {}\texttt{\textit{Vector\-Base}} objects.
There are primarily four use cases that this specification is designed
to support: (a) treating all of the elements in a
{}\texttt{\textit{Vector\-Base}} object a a single logical vector, (b)
targeting an RTOp operator to a specific element or range of elements,
(c) creating a sub-view of an existing vector and treating it as a
vector in its own right, and (d) creating a new, larger composite
(i.e.~block, or product) abstract vector out of a collection of other
vector objects.

The first use case (a), where all of the elements in a
{}\texttt{\textit{Vector\-Base}} object are treated as a single logical
vector, is the most common one.  Here, the default argument values of
{}\texttt{first\_ele=1}, {}\texttt{sub\_dim=0} (the value {}\texttt{0}
is a flag to indicate that all of the remaining elements should be
included) and {}\texttt{global\_offset=0} are used and
{}\texttt{Thyra::applyOp(\-...)} is called with the vector
arguments.  For example, consider the invocation of an
assignment-to-scalar transformation operator in the following
function.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::assign( VectorBase<Scalar>* y, const Scalar& alpha )
{
  TEST_FOR_EXCEPTION(y==NULL,std::logic_error,"assign(...), Error!");  // Validate input
  RTOpPack::TOpAssignScalar<Scalar> assign_scalar_op(alpha);           // Create the operator
  VectorBase<Scalar>* targ_vecs[] = { y };                             // Set up vector args
  applyOp<Scalar>(assign_scalar_op,0,NULL,1,targ_vecs,NULL);           // Invoke operator
}
\end{verbatim}}

{}\noindent{}In the above function, the operator
{}\texttt{assign\_scalar\_op} of type
{}\texttt{RTOpPack::RTOpAssignScalar} only performs a transformation
which does not require a reduction object.  In these cases a
{}\texttt{NULL} pointer is passed in for the reduction object
{}\texttt{reduct\_obj}.

If a reduction is being performed, the reduction object is initialized
prior to a single call to {}\texttt{Thyra::applyOp(\-...)} and then
the reduction value is extracted.  The following function shows an
example where the norm $||.||_2$ is computed

{\scriptsize\begin{verbatim}
template<class Scalar>
Scalar Thyra::norm_2( const VectorBase<Scalar>& v )
{
  RTOpPackROpNorm2<Scalar> norm_2_op;                       // Create the RTOp operator object
  Teuchos::RefCountPtr<RTOpPack::ReductTarget>
    norm_2_targ = norm_2_op.reduct_obj_create();            // Create (init) reduction object
  const VectorBase<Scalar>* vecs[] = { &v };                // Set up non-mutable vector args
  applyOp<Scalar>(norm_2_op,1,vecs,0,NULL,&*norm_2_targ);   // Invoke the reduction operator
  return norm_2_op(*norm_2_targ);                           // Extract reduction value
}
\end{verbatim}}

{}\noindent{}A great many implementations of {}\texttt{RTOp} operator
subclasses are already available and wrapper functions to several of
the more standard operations, including the above functions
{}\texttt{assign( y, alpha )} and {}\texttt{norm\_2(v)}, are defined
in the header file {}\texttt{Thyra\-Vector\-Std\-Ops.hpp} shown in
Figure {}\ref{tsfcore:fig:std_vec_ops}.

The second use case (b) is where the client targets an RTOp operator
for a specific element or set of elements in a {}\texttt{Vector\-Base}
object.  Two important examples are getting and setting individual
vector elements.  This can be accomplished without having to write
specialized RTOp subclasses for these cases.  For example, getting an
element can be performed using a standard RTOp subclass as is done in
the following function.

{\scriptsize\begin{verbatim}
template<class Scalar>
Scalar Thyra::get_ele( const VectorBase<Scalar>& v, Index i )
{
  RTOpPack::ROpSum<Scalar> sum_op;                      // Create RTOp operator object
  Teuchos::RefCountPtr<RTOpPack::ReductTarget>
    sum_targ = sum_op.reduct_obj_create();              // Create (init) reduction object
  const VectorBase<Scalar>* vecs[1] = { &v };           // Set up non-mutable vector args
  applyOp<Scalar>(sum_op,1,vecs,0,NULL,&*sum_targ,i,1); // Invoke the reduction operator
  return sum_opt(*sum_targ);                            // Extract reduction value
}
\end{verbatim}}

{}\noindent{}In the above call to {}\texttt{Thyra::applyOp(\-...)},
the argument {}\texttt{global\_offset} is left at its default value of
{}\texttt{0}, since this argument is ignored by the RTOp object
{}\texttt{sum\_op} anyway (the sum operator is coordinate invariant).

Setting a vector element is performed in a similar manner using the
same transformation RTOp operator subclass for assigning the elements
of a vector that was used in the {}\texttt{assign(...)} function shown
above.  The following function shows how setting a vector element is
performed using this transformation operator.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::set_ele( Index i, Scalar alpha, VectorBase<Scalar>* v )
{
  TEST_FOR_EXCEPTION(v==NULL,std::logic_error,"set_ele(...), Error!"); // Validate input
  RTOpPack::TOpAssignScalar<Scalar> assign_scalar_op(alpha);           // Create op object
  VectorBase<Scalar>* targ_vecs[1] = { v };                            // Set up vector args
  applyOp<Scalar>(assign_scalar_op,0,NULL,1,targ_vecs,NULL,i,1);       // Invoke operator
}
\end{verbatim}}

{}\noindent{}Again, since the assignment operator is also coordinate
invariant, the {}\texttt{assign\_scalar\_op} object ignores the
{}\texttt{global\_offset} argument so {}\texttt{global\_offset} is
left at its default value in the call to
{}\texttt{Thyra::applyOp(\-...)}.

For an example of the third use case (c), where a sub-view of an
existing vector is treating as a vector in its own right, consider an
optimization algorithm where the state $y$ and design $u$ variables
are physically concatenated into a single serial vector $x^T =
{\bmat{cc} y^T & u^T \emat}$.  For example, if $n_y = 10$ and $n_u =
5$, then the dimension of the vector $x$ would be $n_x = 15$.  There
are parts of the algorithm where it is most convenient to treat all of
the variables $x$ the same and there are others where access to the
individual state $y$ and design $u$ sub-vectors of $x$ is required.
Now suppose that a {}\texttt{\textit{Vector\-Base}} object {}\texttt{x} is
directly used by an optimization algorithm.  When the optimization
algorithm needs to apply an RTOp operator to the state variables $y$,
it sets {}\texttt{first\_ele=1} and {}\texttt{sub\_dim=10} and then
calls {}\texttt{Thyra::applyOp(\-...)} (leaving the default value of
{}\texttt{global\_offset=0}).  When the algorithm needs to apply an
RTOp operator to the design variables $u$, it sets
{}\texttt{first\_ele=11} and {}\texttt{sub\_dim=5} and then calls
{}\texttt{Thyra::applyOp(\-...)} (also leaving the default value of
{}\texttt{global\_offset=0}).  In each case, if a reduction is being
performed, the reduction object is initialized prior to a single call
to {}\texttt{Thyra::applyOp(\-...)} and then the reduction value is
extracted just as in the first use case (a).  For example, the
following function computes the $||.||_2$ norms for the state and
design sub-vectors given the vector object {}\texttt{x}.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::compute_norm_2( const VectorBase<Scalar>& x, Index ny, Scalar* nrm_2_y, Scalar* nrm_2_u )
{
  const Index  nx = x.space()->dim(), nu = nx - ny;                 // Get dimensions
  RTOpPack::ROpNorm2<Scalar> norm_2_op;                             // Create op object
  Teuchos::RefCountPtr<RTOpPack::ReductTarget>
    norm_2_targ = norm_2_op.reduct_obj_create();                    // Create (init) reduction object
  const VectorBase<Scalar>* vecs[1] = { &x };                       // Set up non-mutable vector args
  applyOp<Scalar>(norm_2_op,1,vecs,0,NULL,&*norm_2_targ,1,ny);      // Invoke the operator for y
  *nrm_2_y = norm_2_op(*norm_2_targ);                               // Extract the value of ||y||2
  norm_2_op.reduct_obj_reinit(&*norm_2_targ);                       // Reinitialize reduction object
  applyOp<Scalar>(norm_2_op,1,vecs,0,NULL,&*norm_2_targ,ny+1,ny+nu);// Invoke operator for u
  *nrm_2_u = norm_2_op(*norm_2_targ);                               // Extract the value of ||u||2
}
\end{verbatim}}

{}\noindent{}Finally, as an example of the fourth use case (d), where
a new larger composite (i.e.~block) abstract vector is created out of
a collection of other abstract vectors, we use the same optimization
example as above, except this time the vector $x$ is actually
represented as two separate {}\texttt{\textit{Vector\-Base}} objects
{}\texttt{y} and {}\texttt{u}.  In this case, a new composite blocked
or product vector
%
\[
x = {\bmat{c} y \\ u \emat}
\]
%
is abstractly created which lies in a new product vector space
$\mathcal{X} = \mathcal{Y} \times \mathcal{U}$.  With that said,
consider how the element with the maximum absolute value and its index
can be determined for the full vector $x$ given separate
{}\texttt{Vector\-Base} objects for the state $y$ and design $u$ variables.
This can be done with the predefined RTOp subclass
{}\texttt{ROpMax\-AbsEle} which is applied in the following function.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::compute_max_abs_ele( const VectorBase<Scalar>& y, const VectorBase<Scalar>& u
    ,Scalar* x_max, Index* x_i )
{
  const Index ny = y.space()->dim(), nu = u.space()->dim();       // Get dimensions
  RTOpPack::ROpMaxAbsEle<Scalar> max_abs_ele_op;                  // Create op object
  Teuchos::RefCountPtr<RTOpPack::ReductTarget>
    max_abs_ele_targ = max_abs_ele_op.reduct_obj_create();        // Create (init) reduction object
  const VectorBase<Scalar>* vecs[1];                              // Declare array
  vecs[0] = &y;                                                   // Set pointer to y
  applyOp<Scalar>(max_abs_ele_op,1,vecs,0,NULL,&*max_abs_ele_targ,1,0,0);// Reduce over y
  vecs[0] = &u;                                                   // Set pointer to u
  applyOp(max_abs_ele_op,1,vecs,0,NULL,&*max_abs_ele_targ,1,0,ny);// Combine with reduction over u
  *x_max = max_abs_ele_op(*max_abse_ele_targ).x_max();            // Extract reduction values
  *x_i   = max_abs_ele_op(*max_abse_ele_targ).x_i();              // ...
}
\end{verbatim}}

{}\noindent{}The above reduction operation is not coordinate invariant
and therefore the value of {}\texttt{global\_offset} is critical in
the calls to {}\texttt{Thyra\-::applyOp(\-...)}.

Note that optimization algorithms are not the only ANAs that require
the (logical) composition of individual {}\texttt{\textit{Vector\-Base}}
objects into a single vector.  For example, SFE methods form a large
blocked SFE system out of several smaller deterministic systems
{}\cite{ref:sfe}.  There can also be multiple levels of blocking such
as embedding a blocked SFE set of state vectors $y^T = \bmat{cccc}
\tilde{y}_1^T & \tilde{y}_2^T & \ldots & \tilde{y}_N^T \emat$ into the blocked set of
optimization variables $x^T = \bmat{cc} y^T & u^T \emat$.  The basic
functionality in {}\texttt{\textit{Vector\-::applyOp(\-...)}} supports
all of these examples through the above use cases.

%
\subsubsection{Explicit access to {}\texttt{\textit{Vector\-Base}} elements}
\label{tsfcore:sec:explicit_vec_access}
%

Another important feature of the {}\texttt{\textit{Vector\-Base}} interface
regards the functions that can be used to gain explicit access to the
vector elements (which are not shown in the UML diagram in Figure
{}\ref{thyra:fig:basic_op_vec_itfc}).  First, it should be noted that
requesting explicit access to vector elements is ill-advised in
general (especially in an SPMD or client-server environment).
However, there are instances where this is perfectly appropriate.

One use case where explicit vector element access may be required is when the
vector lies in the domain space of a {}\texttt{\textit{Multi\-Vector\-Base}}
object.  This, for example, is needed in the implementation of the compact
LBFGS method described in Section~\ref{tsfcore:sec:LBFGS} above.  For the
implementation of this compact LBFGS matrix, it is critical to be able to
explicitly access elements in the domain space of $Y$ and $S$ in order to
compute and update the coordinating matrix $Q$.  Another situation when
explicit access to vector elements is appropriate and needed is when the
vector is in a small dimensional design space in an optimization problem and
where the ANA uses dense quasi-Newton methods to approximate the reduced
Hessian of the Lagrangian (e.g.~this is one option in MOOCHO).

Another use case where explicit element access is critical is when a vector is
``in-core'' and this allows the seamless integration of all serial vectors
(see Section~\ref{tsfcore:sec:serial_vecs}).

The functions in {}\texttt{\textit{Vector\-Base}} support three different
types of use cases with respect to explicit element access: (a)
extracting a non-mutable view of the vector elements; (b) extracting a
mutable view of the vector elements and then committing the changes
back to the vector object; and finally, (c) explicitly setting the
elements in the vector.  The prototypes for these functions are shown
below.

{\scriptsize\begin{verbatim}
namespace Thyra {

teamplate<class Scalar>
class VectorSpaceBase {
public:
  ...
  virtual bool isInCore() const;
  ...
};

namespace Thyra {
teamplate<class Scalar>
class Vector {
public:
  ...
  virtual void getSubVector( const Range1D& rng, RTOpPack::SubVectorT<Scalar>* sub_vec ) const;
  virtual void freeSubVector( RTOpPack::SubVectorT<Scalar>* sub_vec ) const;
  virtual void getSubVector( const Range1D& rng, RTOpPack::MutableSubVectorT<Scalar>* sub_vec );
  virtual void commitSubVector( RTOpPack::MutableSubVectorT<Scalar>* sub_vec );
  virtual void setSubVector( const RTOpPack::SparseSubVectorT<Scalar>& sub_vec );
  ...
};

} // namespace Thyra
\end{verbatim}}

{}\noindent{}All of these functions have reasonably efficient default
implementations based on fairly sophisticated RTOp subclasses and
{}\texttt{\textit{Vector::applyOp(\-...)}}.  The default implementations of
the {}\texttt{\textit{getSubVector(...)}} functions require dynamic memory
allocation.  For most use cases, {}\texttt{\textit{Vector\-Base}} subclasses
usually do not need to override these functions for the sake of efficiency but
may need to override them for other reasons (see the subclass
{}\texttt{SerialVector} in Section~\ref{tsfcore:sec:serial_vecs} and the
interface {}\texttt{\textit{MPI\-Vector\-Base}} in the Doxygen documentation).
The {}\texttt{\textit{Vector\-Space\-Base}} function
{}\texttt{\textit{isInCore()}} returns true if all of the vector's elements
are easily accessible is all of the calling processes and therefore these
explicit vector access functions are an efficient way to get at the explicit
elements.  This function should not generally be called by typical client code
but instead is designed to be used by more specialized types of purposes
(e.g.~see the class {}\texttt{\textit{MPI\-Vector\-Space\-Base}} in the
Doxygen documentation).

In the first use case (a) -- extracting and releasing a non-mutable
view of the vector elements -- involves calling the {}\texttt{const}
functions {}\texttt{get\-Sub\-Vector(...)} and
{}\texttt{free\-Sub\-Vector(...)}  respectively.  These functions use
the C++ class {}\texttt{RTOp\-Pack::\-Sub\-VectorT<>} that is build
into the C++ interfaces for RTOp and was therefore a natural choice
for this purpose.  To demonstrate the use of these functions the
following example function copies the elements from a
{}\texttt{\textit{Vector\-Base}} object into a raw C++ array.

{\scriptsize\begin{verbatim}
teamplate<class Scalar>
void foo1( const VectorBase<Scalar>& x, Scalar v[] )
{
  RTOpPack::SubVectorT<Scalar> sub_vec;           // Create (int) subvector view object
  x.getSubVector(Range1D(),&sub_vec);             // Initialize the view object
  for( Index i = 0; i < sub_vec.subDim(); ++i )   // Loop through the explicit elements
    v[i] = sub_vec(i+1);                          //     Extract values
  x.freeSubVector(&sub_vec);                      // Free the view of the vector x
}
\end{verbatim}}

{}\noindent{}In the statement

{\scriptsize\begin{verbatim}
  x.getSubVector(Range1D(),&sub_vec);
\end{verbatim}}

{}\noindent{}the constructed {}\texttt{Range1D()} object represents
the full range of vector elements (this is similar to the colon
'\texttt{:}' syntax in Matlab).  Note that this function call may
require dynamic memory allocation in order to create a strided view of
the vector elements that is represented in the output argument
{}\texttt{sub\_vec}.  The data pointed to by
{}\texttt{sub\_vec.values()} may be dynamically allocated which is why
it is necessary to call

{\scriptsize\begin{verbatim}
  x.freeSubVector(&sub_vec);
\end{verbatim}}

{}\noindent{}after the view in {}\texttt{sub\_vec} is no longer needed
in order to possibly free dynamically allocated memory.

The process of extracting, modifying and committing a mutable view of
vector elements, in the second use case (b), involves the
non-\texttt{const} functions {}\texttt{getSubVector(...)} and
{}\texttt{commit\-Sub\-Vector(...)} respectively.  These functions use
the C++ class {}\texttt{RTOpPack::\-Mutable\-Sub\-VectorT<>}.  As an
example, consider the following function that accepts a raw C++ array
of values and then adds them to a {}\texttt{\textit{Vector\-Base}} object's
elements.

{\scriptsize\begin{verbatim}
template<class Scalar>
void foo2( const Scalar v[], VectorBase<Scalar>* x )
{
  RTOpPack::MutableSubVectorT<Scalar> sub_vec;    // Create (init) subvector view object
  x->getSubVector(Range1D(),&sub_vec);            // Initialize the view object
  for( Index i = 0; i < sub_vec.subDim(); ++i )   // Loop through the explict elements
    sub_vec[i] += v[i];                           //      add v[] to elements
  x->commitSubVector(&sub_vec);                   // Commit and free the view of x
}
\end{verbatim}}

The last use case (c) is where a client simply wants to set elements
without creating a view.  This is accomplished through the
non-\texttt{const} function {}\texttt{set\-Sub\-Vector(...)}.  This
function uses yet another built-in RTOp C++ class called
{}\texttt{RTOpPack::\-Sparse\-Sub\-VectorT<>}.  This class is
different from the {}\texttt{RTOpPack::\-SubVectorT<>} and
{}\texttt{RTOpPack::\-Mutable\-Sub\-VectorT<>} classes in that
{}\texttt{RTOpPack::\-Sparse\-Sub\-VectorT<>} also allows the
representation of sparse vectors.  This is very useful for quickly and
efficiently setting up sparse {}\texttt{\textit{Vector\-Base}} objects.  For
example, one way to initialize a {}\texttt{\textit{Vector\-Base}} object to
represent a column of identity (i.e.~an ``eta'' vector $e_i$) is to
use a function like the following.

{\scriptsize\begin{verbatim}
template<class Scalar>
void set_eta_vec( Index i, VectorBase<Scalar>* e_i )
{
  const Scalar av[] = { 1.0 };               // Create array for the values
  const Index  ai[] = { i   };               // Create array for the indexes
  RTOpPack::SparseSubVectorT<Scalar>         // Initialize sub_vec with sparse ele arrays
    sub_vec(0,e_i->dim(),1,av,1,ai,1,0,1);   // ...
  x->setSubVector(sub_vec);                  // Set all x = 0 except x(i) = 1.0
}
\end{verbatim}}

%
\subsubsection{Serial vectors and vector spaces}
\label{tsfcore:sec:serial_vecs}
%

One of the remarkable features of the design of the
{}\texttt{\textit{Vector\-Space\-Base}} and {}\texttt{\textit{Vector\-Base}}
interfaces is that they allow, in principle, for all serial vectors of
the same dimension to be automatically compatible with little work.
Here we use the term serial to mean that all of the vector elements
are stored in core in the same process where the ANA is running.
While this may not sound remarkable at first thought consider the fact
that there exist numerous C++ classes libraries that contain some
concept of a serial vector {}\cite{ref:lumsdaine_and_siek_1998,
ref:tnt, ref:roberts_et_al_1996, ref:math++_1996} which are all
largely incompatible (except perhaps through explicit element access
using {}\texttt{operator[]} or {}\texttt{operator()} but certainty
only through compile time polymorphism (i.e.~C++ templates)).  With
Thyra, these incompatibilities are not an issue.  The way that this
works is exemplified by the subclasses {}\texttt{SerialVectorSpace}
and {}\texttt{SerialVector} which are derived from the node subclasses
{}\texttt{Serial\-VectorSpace\-Base} and {}\texttt{SerialVectorBase}
respectively.

The first step is for every serial {}\texttt{\textit{Vector\-Space\-Base}}
subclass to implement the {}\texttt{\textit{isCompatible(\-...)}}
function in the same way as shown below (using
{}\texttt{SerialVectorSpaceBase} as the example).

{\scriptsize\begin{verbatim}
template<class Scalar>
bool SerialVectorSpaceBase<Scalar>::isCompatible( const VectorSpaceBase<Scalar>& aVecSpc ) const
{
  return this->dim() == aVecSpc.dim() && this->isInCore() && aVecSpc.isInCore();
}
\end{verbatim}}

{}\noindent{}The above implementation makes the assumption that if the
dimensions of the vector spaces are the same and both vectors are stored in
core, then the vectors themselves should also be compatible (through the
efficient use of the explicit sub-vector element access functions, first
introduced in Section~\ref{tsfcore:sec:explicit_vec_access}, as described
below).

The second critical step is to have every serial
{}\texttt{\textit{Vector\-Base}} subclass override the explicit sub-vector
access functions {}\texttt{getSubVector(...)} (both the {}\texttt{const}
and non-\texttt{const} versions), {}\texttt{free\-Sub\-Vector(...)} 
and {}\texttt{commit\-Sub\-Vector(...)} to perform these operations
without calling the {}\texttt{applyOp(\-...)} function (see the subclass
{}\texttt{SerialVector}).

The third step is to have every serial {}\texttt{Vector\-Base} subclass
override and implement the function {}\texttt{applyOp(\-...)} in the
same way as shown below (using the {}\texttt{SerialVectorBase} node
subclass as the example).

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::SerialVectorBase::applyOp(
  const RTOpPack::RTOpT<Scalar> &op, const size_t num_vecs, const VectorBase<Scalar>* vecs[]
  ,const size_t num_targ_vecs, VectorBase<Scalar>* targ_vecs[]
  ,RTOpPack::ReductTarget *reduct_obj
  ,const Index first_ele, const Index sub_dim, const Index global_offset
  ) const
{
  ...
  in_applyOp_ = true;
  Thyra::apply_op_serial(
    op,num_vecs,vecs,num_targ_vecs,targ_vecs,reduct_obj
    ,first_ele,sub_dim,global_offset
    );
  in_applyOp_ = false;
}
\end{verbatim}}

{}\noindent{}The implementation of the above {}\texttt{applyOp(\-...)}
function is really quite simple and it uses a helper function
{}\texttt{apply\_op\_serial(...)}  that takes care of all of the
details of calling the sub-vector extraction functions on the
{}\texttt{Vector\-Base} objects.  No dynamic casting is performed during
this process and in the case of {}\texttt{SerialVector}, no dynamic
memory allocation is performed either.  Therefore, for sufficiently
large serial vectors, the overhead of these function calls will be
swamped by computation in the RTOp operators, yielding near-optimal
performance.

There are cases where it can not be determined until runtime whether a
vector is serial or not.  In these cases the concrete subclasses can
not simply derive from the {}\texttt{Serial\-VectorSpace\-Base} and
{}\texttt{SerialVectorBase} node subclasses but must instead implement
this this functionality themselves to be used when it is determined
that the vectors are indeed serial (see the Epetra Thyra adapter
subclasses {}\texttt{Thyra::EpetraVectorSpace} and
{}\texttt{Thyra::EpetraVector} for instance).

By using this simple approach to developing serial
{}\texttt{\textit{Vector\-Space\-Base}} and {}\texttt{\textit{Vector\-Base}}
subclass, the details of putting together many different types of
numerical algorithms becomes much easier.

%
\subsection{\texttt{\textit{Linear\-Op\-Base}}}
\label{tsfcore:sec:linear_op}
%

This section continues the discussion started in
Section~\ref{tsfcore:sec:Thyra_core_overview} for the
{}\texttt{\textit{Linear\-Op\-Base}} interface and includes some examples.

%
\subsubsection{\texttt{\textit{LinearOpBase::apply(\-...)}}}
\label{tsfcore:sec:linear_op_apply}
%

The C++ prototype for the {}\texttt{\textit{Vector\-Base}} version of
{}\texttt{\textit{LinearOp\-::apply(\-...)}} and
{}\texttt{\textit{LinearOp\-::apply\-Transpose(\-...)}} is

{\scriptsize\begin{verbatim}
namespace Thyra{
template<class RangeScalar, class DomainScalar>
class LinearOp : public virtual Teuchos::Describable {
public:
  ...
  virtual void apply(
    EConj conj, const MultiVectorBase<DomainScalar> &X, MultiVectorBase<RangeScalar> *Y
    ,RangeScalar alpha = Teuchos::ScalarTraits<RangeScalar>::one()
    ,RangeScalar beta = Teuchos::ScalarTraits<RangeScalar>::zero()
    ) const = 0;
  virtual void applyTranspose(
    EConj conj, const MultiVectorBase<RangeScalar> &X, MultiVectorBase<DomainScalar> *Y
    ,DomainScalar alpha = Teuchos::ScalarTraits<RangeScalar>::one()
    ,DomainScalar beta = Teuchos::ScalarTraits<RangeScalar>::zero()
    ) const = 0;
  ...
};
} // namespace Thyra
\end{verbatim}}

{}\noindent{}where the type {}\texttt{EConj} is the C++ {}\texttt{enum}

{\scriptsize\begin{verbatim}
enum EConj { NONCONJ_ELE, CONJ_ELE };
\end{verbatim}}

Two version of a apply function are needed since the range and domain scalar
types may be different.  Examples of operators where the range and domain
scalar types include real-to-complex DFT and double-to-extended-precision
operators.

The use of an {}\texttt{enum} instead of a {}\texttt{char} (i.e.\ BLAS) for
the {}\texttt{conj} argument is very important.  The use of an {}\texttt{enum}
disallows the implicit conversion from other types like {}\texttt{bool},
{}\texttt{int}, and {}\texttt{double}.  Using {}\texttt{enum}s requires more
typing but greatly helps to avoid introducing bugs into the program that are
extremely difficult to track down.

Note that most software for handling complex data types can not handle the
{}\texttt{CONJ\_ELE} value with the
{}\texttt{\textit{LinearOp\-::apply(\-...)}} function.  For example, LAPACK
only handles {}\texttt{'notranspose'}, {}\texttt{'transpose'}, and
{}\texttt{'conjugate transpose'} and has not concept of a non-transposed
conjugate matrix-vector product.  However, the concept of a non-transposed
conjugate application was added since it may come up in certain strange
situations and a {}\texttt{\textit{Linear\-Op\-Base}} implementation is always
free to not support a particular apply mode by returning false from
{}\texttt{\textit{applySupports(EConj)}} or
{}\texttt{\textit{applyTransposeSupports(EConj)}}.

In the above prototype, the scalars $\alpha$ and $\beta$ default to $1$ and
$0$ respectively.  Therefore, by leaving the default values, the default
operation becomes
%
\[
Y = op(M) X
\]
%
which is the same form that is declared in some other operator interfaces.
However, the scalars $\alpha$ and $\beta$ provide direct calls to BLAS
functions and remove the need to create temporaries when performing long
operations (see Section~\ref{tsfcore:sec:multi_vec_linear_op}).  For example,
consider the following long expression
%
\[
Y = A U + \gamma B^T V + \eta C W
\]
%
where $A$, $B$ and $C$ are {}\texttt{\textit{Linear\-Op\-Base}} objects and
$Y$, $U$, $v$ and $W$ are {}\texttt{\textit{Multi\-Vector\-Base}} objects.
Using Thyra, this long operation can be performed as follows

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::long_expression(
  const LinearOpBase<Scalar>& A, const MultiVectorBase<Scalar>& U
  ,Scalar gamma, const LinearOpBase<Scalar>& B, const MultiVectorBase<Scalar>& V
  ,Scalar eta, const LinearOpBase<Scalar>& C, const MultiVectorBase<Scalar>& W
  ,MultiVectorBase<Scalar>* Y
  )
{
  A.apply(NOTRANS,U,Y);              // Y  =  A*U
  B.apply(TRANS,V,Y,gamma,1.0,1.0);  // Y +=  gamma*B'*V
  C.apply(NOTRANS,w,y,eta,1.0,1.0);  // Y +=  eta*C*W
}
\end{verbatim}}

{}\noindent{}where no temporary multi-vectors are required.  Note that if the
arguments {}\texttt{alpha=1.0} and {}\texttt{beta=0.0} where fixed (as they
are in HCL for instance), the above operation would have to be implemented as:

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::bad_long_expression(
  const LinearOpBase<Scalar>& A, const MultiVectorBase<Scalar>& U
  ,Scalar gamma, const LinearOpBase<Scalar>& B, const MultiVectorBase<Scalar>& V
  ,Scalar eta, const LinearOpBase<Scalar>& C, const MultiVectorBase<Scalar>& W
  ,VectorBase<Scalar>* y
  )
{
  Teuchos::RefCountPtr<MultiVectorBase<Scalar> >
    T = createMembers(A.range(),Y->domain()->dim()); // Create a temporary to store the intermediates
  A.apply(NOTRANS,U,Y);            // Y  =  A*U
  B.apply(TRANS,V,&*T);            // T  =  B'*V
  axpy(gamma,*T,Y);                // Y +=  gamma*T
  C.apply(NOTRANS,W,&*T);          // T  =  C*W
  axpy(eta,*T,Y);                  // Y +=  eta*T
}
\end{verbatim}}

Not only is the function {}\texttt{bad\-\_long\-\_expression(\-...)}
slightly less efficient than {}\texttt{long\-\_expression(\-...)} but
it is also longer and more difficult to write.  The arguments
{}\texttt{alpha} and {}\texttt{beta} are important to achieve a
near-optimal implementation and for ease of use.

Note that some implementations of {}\texttt{\textit{Linear\-Op\-Base}} may not
be able to apply the operator with a value of $\beta {}\ne 0$ without creating
at least one temporary vector (or multi-vector).  However, this is a minor
performance issue in most use cases and if $\beta {}\ne 0$ is required then a
temporary will have to be created by someone anyway there there is really no
significant performance hit.

%
\subsubsection{Optional support for adjoints}
\label{tsfcore:sec:linear_op_adjoints}
%

The {}\texttt{\textit{Linear\-Op\-Base}} interface only optionally supports
transposed (adjoint) matrix-vector multiplications.  If the function
{}\texttt{\textit{applyTransposeSupports(conj)}} returns {}\texttt{false},
then the argument {}\texttt{conj}, when passed to
{}\texttt{\textit{apply\-Transpose(\-...)}}, will result in an
{}\texttt{Op\-Not\-Supported} exception being thrown.  This specification,
while not ideal from an object-orientation purest point of view, does satisfy
the basic principles outlined in
Section~\ref{tsfcore:sec:general_software_concepts} in that the preconditions
are known by all clients since they are given by the interface.

%
\subsection{\texttt{\textit{Multi\-Vector\-Base}}}
\label{tsfcore:sec:multi_vec}
%

While the concepts of a {}\texttt{\textit{Vector\-Space\-Base}} and
{}\texttt{\textit{Vector\-Base}} are well established, the concept of a
multi-vector is fairly new.  The idea of a multi-vector was motivated
by the library Epetra {}\cite{ref:Epetra} which contains mostly
concrete implementations of distributed-memory linear algebra classes
using MPI {}\cite{ref:mpi}.  A key issue is how multi-vectors and
vectors relate to each other.  In Epetra, the vector class is a
specialization of the multi-vector class.  This make sense from an
implementation point of view.  The Epetra approach takes the view that
a vector {\em is a} type of multi-vector.  An arguably more natural
view from an abstract mathematical perspective is that multi-vectors
are composed out of a set of vectors where each vector represents a
column of the multi-vector.  This is the view that multi-vectors {\em
have} or {\em contain} vectors and this is the approach that has been
adopted for Thyra as shown in Figure {}\ref{thyra:fig:basic_op_vec_itfc}.

Note that a multi-vector is not the same thing as a blocked or product vector.
In fact, multi-vectors and product vectors are orthogonal concepts and it is
possible to have product multi-vectors.  Product vectors and vector spaces are
discussed in Section~\ref{tsfcore:sec:vec_apply_op} and
Section~\ref{tsfcore:sec:composite_abstractions}.

All of the below examples will involve the compact LBFGS implementation
described above in Section~\ref{tsfcore:sec:LBFGS}.  For these examples we
will consider interactions with the two principle
{}\texttt{\textit{Multi\-Vector\-Base}} objects {}\texttt{Y\_store} and
{}\texttt{S\_store} which each have $m_{\tiny\mbox{max}}$ columns.

%
\subsubsection{Accessing columns of a {}\texttt{\textit{Multi\-Vector\-Base}}
as {}\texttt{\textit{Vector\-Base}} objects}
%

The columns of a {}\texttt{\textit{Multi\-Vector\-Base}} object can be
accessed using the {}\texttt{const} or non-\texttt{const}
{}\texttt{\textit{col(j)}} functions which return
{}\texttt{RefCountPtr<>} objects which points to an abstract
{}\texttt{\textit{Vector\-Base}} view of a column.  The prototypes for these
functions are shown below.

{\scriptsize\begin{verbatim}
namespace Thyra{
template<class Scalar>
class MultiVector : virtual public LinearOpBase<Scalar> {
public:
  ...
  virtual Teuchos::RefCountPtr<VectorBase<Scalar> >        col(const Index j) = 0;
  virtual Teuchos::RefCountPtr<const VectorBase<Scalar> >  col(const Index j) const;
  ...
};
} // namespace Thyra
\end{verbatim}}

{}\noindent{}Actually, the non-\texttt{const} version of
{}\texttt{\textit{col(...)}}  is the only pure virtual function in
{}\texttt{\textit{Multi\-Vector\-Base}} and therefore the only function that
must be overridden in order to create a concrete (but suboptimal)
{}\texttt{\textit{Multi\-Vector\-Base}} subclass.  All of the other virtual
functions in {}\texttt{\textit{Multi\-Vector\-Base}} have default
implementations based on this function and
{}\texttt{\textit{Vector\-::applyOp(\-...)}}.

The following example function copies the most recent update vectors
{}\texttt{s} and {}\texttt{y} into the multi-vectors
{}\texttt{S\_store} and {}\texttt{Y\_store} and increments the counter
{}\texttt{m} for a compact LBFGS implementation.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::update_S_Y( const VectorBase<Scalar>& s, const VectorBase<Scalar>& y
                          ,MultiVectorBase<Scalar>* S_store, MultiVectorBase<Scalar>* Y_store, int* m )
{
  const int m_max = S_store->domain()->dim(); // Get the maximum number of updates allowed
  if(*m < m_max) {
    ++(*m);                                   // Increment the number of updates
    assign(S_store->col(*m).get(),s);         // Copy in s into S(:,m)         
    assign(Y_store->col(*m).get(),y);         // Copy in y into Y(:,m)
  }
  else {
    // We must drop the oldest pair (s,y) and copy in the newest pair
    ...
  }
}
\end{verbatim}}

{}\noindent{}Note that the {}\texttt{\textit{Multi\-Vector\-Base}} object
that {}\texttt{\textit{col(...)}} is called on is not guaranteed to be
updated until the returned {}\texttt{\textit{Vector\-Base}} object is
destroyed when the {}\texttt{RefCountPtr<>} object returned from
{}\texttt{\textit{col(...)}} goes out of scope.  The use in the above
function guarantees that this happens after each call to the
{}\texttt{assign(...)} function.

%
\subsubsection{\texttt{\textit{Multi\-Vector\-Base}} sub-views}
%

In addition to being able to access the columns of a
{}\texttt{\textit{Multi\-Vector\-Base}} object one column at a time, a client
can also create {}\texttt{const} and non-\texttt{const}
{}\texttt{\textit{Multi\-Vector\-Base}} views of the columns
using one of the {}\texttt{\textit{subView(...)}} functions shown below.

{\scriptsize\begin{verbatim}
namespace Thyra {
template<class Scalar>
class MultiVector : virtual public LinearOpBase<Scalar> {
public:
  ...
  virtual Teuchos::RefCountPtr<MultiVectorBase<Scalar> >       subView(const Range1D& col_rng);
  virtual Teuchos::RefCountPtr<const MultiVectorBase<Scalar> > subView(const Range1D& col_rng) const;
  virtual Teuchos::RefCountPtr<MultiVectorBase<Scalar> >       subView(const int numCols
                                                                        ,const int cols[]);
  virtual Teuchos::RefCountPtr<const MultiVectorBase<Scalar> > subView(const int numCols
                                                                        ,const int cols[]) const;
  ...
};
} // namespace Thyra
\end{verbatim}}

{}\noindent{}The ability to extract a {}\texttt{\textit{Multi\-Vector\-Base}}
sub-view of a contiguous set of columns of a
{}\texttt{\textit{Multi\-Vector\-Base}} object, which is supported by the
first two functions, is required in order to implement certain types of
numerical methods.  For example, the implementation of the compact LBFGS
method described above in Section~\ref{tsfcore:sec:LBFGS} requires this
functionality.  The following example function shows how the contiguous
{}\texttt{\textit{subView(...)}} function is used in an LBFGS implementation
where {}\texttt{\textit{Multi\-Vector\-Base}} storage objects
{}\texttt{S\_store} and {}\texttt{Y\_store} are used to create
{}\texttt{\textit{Multi\-Vector\-Base}} view objects {}\texttt{S} and
{}\texttt{Y} for only the number of updates currently stored.  These sub-view
objects are used in later example code.

{\scriptsize\begin{verbatim}
template<class Scalar>
Teuchos::RefCountPtr<const Thyra::MultiVectorBase<Scalar> >
Thyra::get_updated( const MultiVectorBase<Scalar>& Store, int m )
{
  return Store.subView(Range1D(1,m));
}
\end{verbatim}}

The second form of the {}\texttt{\textit{subView(...)}} function takes a
list of (possibly unsorted but unique) column indexes
{}\texttt{cols[]} and returns a {}\texttt{\textit{Multi\-Vector\-Base}} view
object of those columns.  This functionality is very useful in the
development of some types of ANAs (e.g.~block Krylov iterative linear
equation solvers).

Note that both forms of the {}\texttt{\textit{subView(...)}} function
have (suboptimal) default implementations based on the
{}\texttt{MultiVectorCols} utility subclass.  This
{}\texttt{MultiVectorCols} class, coincidentally, is also used to
provide a general (but suboptimal) implementation of
{}\texttt{\textit{Multi\-Vector\-Base}} just given an implementation of
{}\texttt{\textit{Vector\-Base}}.  This utility subclass is also used to
provide default implementations for many of the
{}\texttt{\textit{Multi\-Vector\-Base}}-related functions which includes the
default implementation of the
{}\texttt{\textit{Vector\-Space\-Base\-::createMembers(numMembers)}} function.

%
\subsubsection{\texttt{\textit{Multi\-Vector\-Base}} support for {}\texttt{\textit{applyOp(\-...)}}}
\label{tsfcore:sec:multi_vec_apply_op}
%

RTOp operators can be applied to the columns of a
{}\texttt{\textit{Multi\-Vector\-Base}} object one column at a time using
the {}\texttt{\textit{col(...)}} function.  However, a potentially more
efficient approach is to allow the {}\texttt{\textit{Multi\-Vector\-Base}}
object to apply the {}\texttt{RTOp} operator itself.  This is
supported by the {}\texttt{\textit{applyOp(\-...)}} functions on
{}\texttt{\textit{Multi\-Vector\-Base}}.  The
{}\texttt{\textit{applyOp(\-...)}} functions are not called directly
(they are protected) but instead are called by non-member (friend)
functions {}\texttt{\textit{applyOp(\-...)}} which then invoke the
member functions.  This approach allows a more natural way to invoke a
reduction/transformation operation in line with the mathematical
description in {}\cite{ref:rtop_toms}.

There are two versions of
{}\texttt{\textit{Multi\-Vector\-::applyOp(\-...)}}: one that returns
a list of reduction objects (one for each column of the multi-vector)
and another that uses two {}\texttt{RTOp} operators to reduce all of
the reduction objects over each column into single reduction object
which is returned.  Both versions of the
{}\texttt{\textit{Multi\-Vector\-::applyOp(\-...)}} have default
implementations that are based on
{}\texttt{\textit{Multi\-Vector\-::col(...)}} and
{}\texttt{\textit{Vector\-::applyOp(\-...)}}.

Below, two example operations, which are defined in the header
{}\texttt{Thyra\-Multi\-Vector\-Std\-Ops.hpp}, are shown that are
needed by various ANAs.

The first example is the update operator $\alpha U + V \rightarrow V$
and is implemented in the following function.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::update( Scalar alpha, const MultiVectorBase<Scalar>& U, MultiVectorBase<Scalar>* V )
{
  TEST_FOR_EXCEPTION(V==NULL,std::logic_error,"axpy(...), Error!"); // Validate input
  RTOpPack::TOpAxpy<Scalar> axpy_op(alpha);                         // Create (init) op object
  const MultiVectorBase<Scalar>* multi_vecs[]       = { &U };       // Set up non-mutable mv args
  MultiVectorBase<Scalar>*       targ_multi_vecs[]  = { V  };       // Set up mutable mv args
  applyOp<Scalar>(axpy_op,1,multi_vecs,1,targ_multi_vecs,NULL);     // Invoke the transformation operator
}
\end{verbatim}}

{}\noindent{}In the above call to {}\texttt{applyOp(\-...)}, a
{}\texttt{NULL} pointer is passed in for the array of reduction
objects which is allowed since this RTOp operator does not perform a
reduction.

The second example is a column-wise dot product operation and is
implemented in the following function.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::dot( const MultiVectorBase<Scalar>& V1, const MultiVectorBase<Scalar>& V2, Scalar dot[] )
{
  const int m = V1.domain()->dim();                                      // Get the num cols
  RTOpPack::ROpDot<Scalar> dot_op;                                       // Create op object
  std::vector<Teuchos::RefCountPtr<RTOpPack::ReductTarget> >
   rcp_dot_targs(m);                                                     // Array of reduct objects
  std::vector<RTOpPack::ReductTarget*>
   dot_targs(m);                                                         // Array of reduct object ptrs
  for( int kc = 0; kc < m; ++kc ) {                                      // For each column:
    rcp_dot_targs[kc] = dot_op.reduct_obj_create();                      //   Create reduct object
    dot_targs[kc] = &*rcp_dot_targs[kc];                                 //   Set raw pointer
  }
  const MultiVectorBase<Scalar>* multi_vecs[] = { &V1, &V2 };            // Set up non-mutable mv args
  applyOp(dot_op,2,multi_vecs,0,NULL,&dot_targs[0]);                     // Invoke the reduction operator
  for( int kc = 0; kc < m; ++kc ) {                                      // For each column:
    dot[kc] = dot_op(*dot_targs[kc]);                                    //   Extract dot product val
  }
}
\end{verbatim}}

{}\noindent{}Note that the above reduction operation will be performed
with a single global reduction when performed on a distributed-memory
parallel computer (using MPI).  Without the concept of a
{}\texttt{\textit{Multi\-Vector\-Base}} or support for the
{}\texttt{\textit{applyOp(\-...)}} function, this type of multi-vector
reduction operation would require $m$ separate global reductions,
where $m$ is the number of columns in the multi-vector.  The presence
of this function is critical for a near-optimal implementation with
respect to minimizing communication in a distributed memory program.

%
\subsubsection{\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Multi\-Vector\-Base}} correspondence}
\label{tsfcore:sec:vector_vs_multivector}
%

The interface class {}\texttt{\textit{Linear\-Op\-Base}} takes the perspective
that most subclasses will naturally prefer to implement the
{}\texttt{\textit{Vector\-Base}} version of the function
{}\texttt{\textit{apply(\-...)}} and let the default implementation of
the {}\texttt{\textit{Multi\-Vector\-Base}} version of this function deal with
{}\texttt{\textit{Multi\-Vector\-Base}} objects.  There are many cases where
there is no way to provide more specialized implementations of these
operations for multi-vectors.  For example, while the BLAS and LAPACK
are designed from the ground up to be more efficient with multiple
right-hand-side vectors, many implementations of sparse direct linear
solvers unfortunately only support the solution of single linear
systems (e.g.~the Harwell solvers such as MA47 and MA48
{}\cite{ref:hsl_1995}).  This realization provides the motivation for
choosing the {}\texttt{\textit{Vector\-Base}} versions of these functions as
the default functions for subclasses to override.  With that said, if a
{}\texttt{\textit{Linear\-Op\-Base}} subclass can provide an optimized
implementation of the {}\texttt{\textit{Multi\-Vector\-Base}} version of the
{}\texttt{\textit{apply(\-...)}} function, does such a subclass also
have to provide a completely independent implementation of the
{}\texttt{\textit{Vector\-Base}} version of this function?  The answer is no
since {}\texttt{\textit{Vector\-Base}} is derived from
{}\texttt{\textit{Multi\-Vector\-Base}}.  Therefore, providing a vector
implementation of the {}\texttt{\textit{apply(\-...)}} function
is trivial and looks like:

{\scriptsize\begin{verbatim}
namespace Thyra {
template<class Scalar>
class MyLinearOp : public LinearOpBase<Scalar> {
public:
  ...
  void apply( ETransp M_trans, const MultiVectorBase<Scalar> &X, MultiVectorBase<Scalar> *Y, Scalar alpha
              ,Scalar beta ) const
  {
    // Optimized implementation for multi-vectors
    ...
  }
  void apply( ETransp M_trans, const VectorBase<Scalar> &x, VectorBase<Scalar> *y, Scalar alpha
             ,Scalar beta ) const
  {
    // Call MultiVector version
    apply(alpha,M_trans,static_cast<const MultiVectorBase<Scalar>&>(x),static_cast<MultiVectorBase<Scalar>*>(y),beta);
  }
  ...
};
} // namespace Thyra
\end{verbatim}}

Above, the use of {}\texttt{static\_\-cast<>} to
{}\texttt{Multi\-Vector\-Base} is necessary to insure that the
{}\texttt{Multi\-Vector\-Base} version of {}\texttt{\textit{apply(\-...)}}
is called and not the {}\texttt{Vector\-Base} version (which it would be
otherwise and would setup an infinite call recursion).

%
\subsubsection{\texttt{\textit{Multi\-Vector\-Base}} acting as a {}\texttt{\textit{Linear\-Op\-Base}}}
\label{tsfcore:sec:multi_vec_linear_op}
%

The last issues to discuss with regard to
{}\texttt{\textit{Multi\-Vector\-Base}} relate to where it fits in the class
hierarchy.  The decision adopted for Thyra was to make
{}\texttt{\textit{Multi\-Vector\-Base}} specialize
{}\texttt{\textit{Linear\-Op\-Base}}.  In other words, a
{}\texttt{\textit{Multi\-Vector\-Base}} object can also act as a
{}\texttt{\textit{Linear\-Op\-Base}} object.

As an example where this is needed, consider using the LBFGS inverse
matrix $H$ shown in Figure {}\ref{tsfcore:fig:LBFGS} as a linear
operator which acts on multi-vector arguments $U\in\RE^{n \times p}$
and $V\in\RE^{n \times p}$ in an operation of the form

\begin{eqnarray*}
U & = & \alpha B^{-1} V \\
  & = & \alpha H V \\
  & = & \alpha g V + \alpha
                            {\bmat{cc} S & \gamma Y \emat}
                            {\bmat{cc} Q_{ss} & Q_{sy} \\ Q_{sy}^T & Q_{yy} \emat}
                            {\bmat{c} S^T \\ \gamma Y^T \emat} V
\end{eqnarray*}

where the matrices $Q_{ss}$, $Q_{ys}$ and $Q_{yy}$ are stored as small
{}\texttt{\textit{Multi\-Vector\-Base}} objects.  A multi-vector solve using
the inverse $H = B^{-1}$ might be used, for instance, in an active-set
optimization algorithm where $V\in\RE^{n \times p}$ represents the $p$
gradient vectors of the active constraints.  This is an important
operation, for instance, in the formation of a Schur complement of the
KKT system in the QP subproblem of an reduced-space SQP method
{}\cite{RABartlett_2001}.  This multi-vector operation using $H$ can
be performed with the following atomic operations

\begin{eqnarray*}
T_1 & = & S^T V \\
T_2 & = & Y^T V \\
T_3 & = & Q_{ss} T_1 + \gamma Q_{sy} T_2 \\
T_4 & = & Q_{sy}^T T_1 + \gamma Q_{yy} T_2 \\
U   & = & \alpha \gamma V + \alpha S T_3 + \alpha \gamma Y T_4
\end{eqnarray*}

{}\noindent{}where $T_1$, $T_2$, $T_3$ and $T_4$ are all temporary
{}\texttt{\textit{Multi\-Vector\-Base}} objects of dimension $m \times p$.
The following function shows how the above operations are performed in
order to implement the overall multi-vector operation.

{\scriptsize\begin{verbatim}
template<class Scalar>
void Thyra::LBFGS_solve(
  int m, Scalar g, const MultiVectorBase<Scalar>& S_store, const MultiVectorBase<Scalar>& Y_store
  ,const MultiVectorBase<Scalar>& Q_ss, const MultiVectorBase<Scalar>& Q_sy, const MultiVectorBase<Scalar>& Q_yy
  ,const MultiVectorBase<Scalar>& V, MultiVectorBase<Scalar>* U, Scalar alpha = 1.0, Scalar = beta = 0.0
  )
{
  // validate input
  ...
  const int p = V.domain()->dim();               // Get number of columns in V and U
  Teuchos::RefCountPtr<const MultiVectorBase<Scalar> >
    S = get_updated(S_store,m),                  // Get view of only stored columns in S_store
    Y = get_updated(Y_store,m);                  // Get view of only stored columns in Y_store
  Teuchos::RefCountPtr<MultiVectorBase<Scalar> >
    T_1 = S->domain()->createMembers(p),         // Create the tempoarary multi-vectors
    T_2 = Y->domain()->createMembers(p),         // ...
    T_3 = S->domain()->createMembers(p),         // ...
    T_4 = Y->domain()->createMembers(p);         // ...
  S->apply(TRANS,V,T_1->get());                  // T_1  =  S'*V
  Y->apply(TRANS,V,T_2->get());                  // T_2  =  Y'*V
  Q_ss.apply(NOTRANS,*T_1,T_3->get());           // T_3  =  Q_ss*T_1
  Q_sy.apply(NOTRANS,*T_2,T_3->get(),gamma,1.0); // T_3 +=  gamma*Q_sy*T_2
  Q_sy.apply(TRANS,  *T_1,T_4->get());           // T_4  =  Q_sy'*T_1
  Q_yy.apply(NOTRANS,*T_2,T_4->get(),gamma,1.0); // T_4 +=  gamma*Q_yy*T_2
  S->apply(NOTRANS,*T_3,U,alpha);                // U    =  alpha*S*T_3
  Y->apply(NOTRANS,*T_4,U,alpha*gamma,1.0);      // U   +=  alpha*gamma*Y*T_4
  axpy(alpha*g,V,U);                             // U   +=  alpha*g*V
}
\end{verbatim}}

{\bsinglespace
\begin{figure}
\begin{center}

%\fbox{
\includegraphics*[angle=0,scale=0.60]{SPMD_Dist_MVs_P4}
%}%fbox

a) Disturbed-memory multi-vectors \\[3ex]

%\fbox{
\includegraphics*[angle=0,scale=0.60]{SPMD_Locally_Replicated_MVs_P4}
%}%fbox

b) Locally replicated multi-vectors

\end{center}
\caption{
\label{tsfcore:fig:SPMD_MVs_P4}
Carton of disturbed and locally replicated multi-vectors which are
used in the example compact LBFGS sub-ANA when run in SPMD mode on
four processors.  The process boundaries are shown as dotted lines.
The numbers for rows and columns of each multi-vector are also shown.}
\end{figure}
\esinglespace}

Consider the use of the above function in an SPMD environment where
the ANA runs in duplicate and in parallel on each processor.  Here,
the elements for the multi-vector objects {}\texttt{S\_store} (and
view {}\texttt{S}) , {}\texttt{Y\_store} (and view {}\texttt{Y}),
{}\texttt{V} and {}\texttt{U} are distributed across many different
processors as Figure {}\ref{tsfcore:fig:SPMD_MVs_P4} shows.  The case
shown\footnote{The aspect ratio of the number of rows to number of
columns in Figure {}\ref{tsfcore:fig:SPMD_MVs_P4} is exaggerated in
that in a realistic case the number of rows usually numbers in the
tens to hundreds of thousands while the number of columns usually
number in only the tens.  This was done for illustrative purposes.  If
the true aspect ratio where shown in Figure
{}\ref{tsfcore:fig:SPMD_MVs_P4} then all of these multi-vectors would
appear to be just vertical lines and would not show a distiction
between different multi-vectors.} in Figure
{}\ref{tsfcore:fig:SPMD_MVs_P4} is for the situation where $p < m$.
In SPMD mode, all of the elements in the multi-vector objects
{}\texttt{Q\_ss}, {}\texttt{Q\_sy}, {}\texttt{Q\_yy}, {}\texttt{T\_1},
{}\texttt{T\_2}, {}\texttt{T\_3} and {}\texttt{T\_4} are stored
locally and in duplicate (i.e.~locally replicated) on each processor
as shown\footnote{The same unrealistic aspect ratio shown in Figure
{}\ref{tsfcore:fig:SPMD_MVs_P4} is the same as shown in Figure
{}\ref{tsfcore:fig:SPMD_MVs_P4}.a, again for illustrative purposes.} 
in Figure {}\ref{tsfcore:fig:SPMD_MVs_P4}.b.  Now let us consider the
performance of this set of operations in this context.  Note that
there are principally three different types of operations with
multi-vectors that are performed through the
{}\texttt{\textit{Multi\-Vector\-::apply(\-...)}} function.

The first type of operation performed by
{}\texttt{\textit{Multi\-Vector\-::apply(\-...)}} is the
parallel/parallel matrix-matrix products performed in the lines

{\scriptsize\begin{verbatim}
  S->apply(TRANS,V,T_1->get());
  Y->apply(TRANS,V,T_2->get());
\end{verbatim}}

{}\noindent{}where the results are stored in the local multi-vectors
{}\texttt{T\_1} and {}\texttt{T\_2}.  The operation $T_1 = S^T V$ is
shown in Figure {}\ref{tsfcore:fig:SPMD_Block_Dot_Prod_P4} for the
SPMD mode on four processors.  This type of operation is also known as
a block dot product [???].  These two operations only require a single
global reduction each, independent of the number of updates $m$
represented in $S$ and $Y$ or columns $p$ in $V$.  Note that if there
was no concept of a multi-vector and these matrix-matrix products had
to be performed one set of vectors at a time, then these two parallel
matrix-matrix products would require a whopping $2 m p$ global
reductions.  For $m = 40$ and $p = 20$ this would result in $2 m p =
2(40)(20) = 1600$ global reductions!  Clearly this many global
reductions would destroy the parallel scalability of the overall ANA
any many cases.  It is in this type of operation that the concept of a
{}\texttt{\textit{Multi\-Vector\-Base}} is most critical for near-optimal
performance in parallel programs.  In addition to mimimizing
communication overhead, the {}\texttt{\textit{Multi\-Vector\-Base}}
implementation can utilize level-3 BLAS to perform the local processor
matrix-matrix multiplications yielding near-optimal cache performance
on most systems.

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.60]{SPMD_Block_Dot_Prod_P4}
%}%fbox
\end{center}
\caption{
\label{tsfcore:fig:SPMD_Block_Dot_Prod_P4}
Carton of distributed-memory matrix-matrix product (i.e.~block dot
product) $T_1 = S^T V$ run in SPMD mode on four processors.  This
operation first performs local matrix-matrix multiplication with the
entries of $S^T$ and $V$ on each processor using level-3 BLAS and then
a global reduction summation operation is performed (using MPI) to
produce $T_1$ which is returned to all of the processors.}
\end{figure}
\esinglespace}

The second type of operation performed by
{}\texttt{\textit{Multi\-Vector\-::apply(\-...)}} is the local/local
matrix-matrix products of small local
{}\texttt{\textit{Multi\-Vector\-Base}} objects in the lines

{\scriptsize\begin{verbatim}
  Q_ss.apply(NOTRANS,*T_1,T_3->get());
  Q_sy.apply(NOTRANS,*T_2,T_3->get(),g,1.0);
  Q_sy.apply(TRANS,  *T_1,T_4->get());
  Q_yy.apply(NOTRANS,*T_2,T_4->get(),g,1.0);
\end{verbatim}}

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.60]{SPMD_Local_Matrix_Matrix_Prod_P4}
%}%fbox
\end{center}
\caption{
\label{tsfcore:fig:SPMD_Local_Matrix_Matrix_Prod_P4}
Carton of local matrix-matrix product $T_3 = Q_{ss} T_1$ involving
locally replicated multi-vectors run in SPMD mode on four processors.
In SPMD mode this operation involves no processor-to-processor
communciation at all.}
\end{figure}
\esinglespace}

{}\noindent{}where the operation $T_3 = Q_{ss} T_1$ is shown, for
example, in Figure
{}\ref{tsfcore:fig:SPMD_Local_Matrix_Matrix_Prod_P4}.  Note that these
types of local computations classify as serial overhead and therefore
it is critical that the cost of these operations be kept to a minimum
or they could cripple the parallel scalability of the overall ANA.
Each of these four matrix-matrix multiplications involve only one
virtual function call and the matrix-matrix multiplication itself can
be performed with level-3 BLAS, achieving the fastest possible flop
rate attainable on most processors {}\cite{ref:demmel_1997}.

The third type of operation performed by
{}\texttt{\textit{Multi\-Vector\-::apply(\-...)}} is local/parallel
matrix-matrix multiplications performed in the lines

{\scriptsize\begin{verbatim}
  S->apply(NOTRANS,*T_3,U,alpha);
  Y->apply(NOTRANS,*T_4,U,alpha*g,1.0);
\end{verbatim}}

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.60]{SPMD_Dist_Local_Matrix_Matrix_Prod_P4}
%}%fbox
\end{center}
\caption{
\label{tsfcore:fig:SPMD_Dist_Local_Matrix_Matrix_Prod_P4}
Carton of distributed-local matrix-matrix product $U = S T_3$
involving both distributed and locally multi-vectors run in SPMD mode
on four processors.  To perform this operation, the local elements in
the distributed multi-vector $S$ are multiplied with the locally
replicated multi-vector $T_3$ and the result of the matrix-matrix
product are set to the local elements of the distributed multi-vector
$U$.  In SPMD mode this operation requires no processor-to-processor
communication at all.}
\end{figure}
\esinglespace}

{}\noindent{}where the operation $U = S T_3$ is shown, for
example, in Figure
{}\ref{tsfcore:fig:SPMD_Dist_Local_Matrix_Matrix_Prod_P4}.  This type of
operation involves fully scalable work with no communication or
synchronization required.  Here, a vector-by-vector implementation
will not be a bottleneck from a standpoint of global communication.
However, this operation will utilize level-3 BLAS and yield
near-optimal local cache performance where a vector-by-vector
implementation would not.

The last type of operation performed in the above
{}\texttt{LBFGS\_solve(...)}  function does not involve
{}\texttt{\textit{Multi\-Vector\-::apply(\-...)}} and is shown in the
line

{\scriptsize\begin{verbatim}
  axpy(alpha*g,V,U);
\end{verbatim}}

{}\noindent{}The implementation of this function uses an RTOp
transformation operator with the
{}\texttt{\textit{Multi\-Vector\-::applyOp(\-...)}}  function.  Note
that this function only involves transformation operations (i.e.~no
communication) which are fully scalable.

%
\subsubsection{Explicit access to {}\texttt{\textit{Multi\-Vector\-Base}} elements}
\label{tsfcore:sec:explicit_multi_vec_access}
%

Certain use cases require explicit access to the elements in
{}\texttt{\textit{Multi\-Vector\-Base}} objects is required just as with
{}\texttt{\textit{Vector\-Base}} objects (see
Section~\ref{tsfcore:sec:explicit_vec_access}).  The operations on
{}\texttt{\textit{Multi\-Vector\-Base}} that allow explicit access to elements
are shown below.

{\scriptsize\begin{verbatim}
namespace Thyra {
template<class Scalar>
class MultiVector : virtual public LinearOpBase<Scalar> {
public:
  ...
  virtual void getSubMultiVector( const Range1D &rowRng, const Range1D &colRng
    ,RTOpPack::SubMultiVectorT<Scalar> *sub_mv ) const;
  virtual void freeSubMultiVector( RTOpPack::SubMultiVectorT<Scalar>* sub_mv ) const;
  virtual void getSubMultiVector( const Range1D &rowRng, const Range1D &colRng
    ,RTOpPack::MutableSubMultiVectorT<Scalar> *sub_mv	);
	virtual void commitSubMultiVector( RTOpPack::MutableSubMultiVectorT<Scalar>* sub_mv );
  ...
};
} // namespace Thyra
\end{verbatim}}

The above {}\texttt{\textit{Multi\-Vector\-Base}} functions support two of the
same use cases as the corresponding {}\texttt{\textit{Vector\-Base}}
function: (a) extracting a non-mutable view of a contiguous sub-matrix;
and (b) extracting a mutable view of a contiguous sub-matrix and then
committing the changes back again.  Note that the third use case,
explicitly setting the elements (without creating a view first), which
supported by {}\texttt{\textit{Vector\-Base}}, is not supported by
{}\texttt{\textit{Multi\-Vector\-Base}}.

The main difference between the explicit element access functions in
{}\texttt{\textit{Multi\-Vector\-Base}} and {}\texttt{\textit{Vector\-Base}} is
that the RTOp classes {}\texttt{RTOpPack::\-Sub\-Multi\-Vector\-T<>}
and {}\texttt{RTOpPack::\-Mutable\-Sub\-Multi\-Vector\-T<>} are used
instead of {}\texttt{RTOpPack::\-Sub\-Vector\-T<>} and
{}\texttt{RTOpPack::\-Mutable\-Sub\-Vector\-T<>}.  The classes
{}\texttt{RTOpPack::\-Sub\-Multi\-Vector\-T<>} and
{}\texttt{RTOpPack::\-Mutable\-Sub\-Multi\-Vector\-T<>} are used to
represent column-oriented Fortran (i.e.~BLAS) style dense rectangular
matrices.  Such a dense matrix $A$ is represented by a pointer to the
first element in the first column {}\texttt{Scalar *A}, the number of
rows {}\texttt{Index A\_nrows}, the number of columns {}\texttt{Index
A\_ncols} and the leading dimension between consecutive columns
{}\texttt{A\_ld} (see BLAS documentation).

The first use case (a) where a {}\texttt{const} view of sub-matrix is
created and used requires calling the {}\texttt{const} functions
{}\texttt{get\-Sub\-Multi\-Vector(...)} and
{}\texttt{free\-Sub\-Multi\-Vector(...)}  respectively.  The following
example function shows how a sub-matrix of an input
{}\texttt{\textit{Multi\-Vector\-Base}} {}\texttt{Y} can be copied in a
column-wise Fortran(BLAS)-style matrix {}\texttt{A} in one atomic
operation.

{\scriptsize\begin{verbatim}
teamplate<class Scalar>
void foo5(
  const MultiVectorBase<Scalar> &Y, const Index firstRowOff, const Index firstColOff
  ,const Index A_nrows, const Index A_ncols, const Index A_ld, Scalar A[]
  )
{
  RTOpPack::SubMultiVectorT<Scalar> sub_mv;          // Create (init) submultivector view object
  Y.getSubMultiVector(                               // Initialize the view object
    Range1D(firstRowOff+1,firstRowOff+A_nrows)
    Range1D(firstColOff+1,firstColOff+A_ncols)
   ,&sub_mv );
  for( Index j=0; j < sub_mv.numSubCols(); ++j ) {   // Loop over colunmns
    for( Index i=0; i < sub_mv.subDim(); ++i ) {     //   Loop over elements in a column
      A[i+j*A_ld]                                    //     Copy elements
        =sub_mv.values()[i+j*sub_mv.leadingDim()];
    }
  }
  Y.freeSubMultiVector(&sub_mv);                     // Free the view of Y
}
\end{verbatim}}

In the above function, we could have used the overloaded operator
function
{}\texttt{RTOpPack::\-Sub\-Multi\-VectorT<>::\-operator()(Index i,
Index j)} to access the elements in the sub-view as
{}\texttt{sub\_mv(i+1,j+1} (where the addition {}\texttt{+1} is needed
to convert from zero-based to one-based) but the above function shows
how raw memory access is achieved.  Note that the above function
should only be expected to be efficient if
{}\texttt{Y.range()->isInCore()==true} but should work in any case.

The second use case (b) involving the utilization of a
non-{}\texttt{const}\ sub-matrix view of a
{}\texttt{\textit{Multi\-Vector\-Base}} object requires the use of the
non-{}\texttt{const} functions {}\texttt{get\-Sub\-Multi\-Vector(...)}
and {}\texttt{commit\-Sub\-Multi\-Vector(...)}.  The following
function demonstrates this use case by showing how to add elements in
an input dense Fortran(BLAS) style matrix {}\texttt{A} to a sub-matrix
in a {}\texttt{\textit{Multi\-Vector\-Base}} object {}\texttt{Y}.

{\scriptsize\begin{verbatim}
teamplate<class Scalar>
void foo6(
	const Scalar A[], const Index A_nrows, const Index A_ncols, const Index A_ld
  ,const Index firstRowOff, const Index firstColOff, MultiVectorBase<Scalar> *Y
  )
{
  RTOpPack::MutableSubMultiVectorT<Scalar> sub_mv;  // Create (init) submultivector view object
  Y->getSubMultiVector(                             // Initialize the view object
    Range1D(firstRowOff+1,firstRowOff+A_nrows)
    Range1D(firstColOff+1,firstColOff+A_ncols)
   ,&sub_mv );
  for( Index j=0; j < sub_mv.numSubCols(); ++j ) {  // Loop over colunmns
    for( Index i=0; i < sub_mv.subDim(); ++i ) {    //   Loop over elements in a column
      sub_mv.values()[i+j*sub_mv.leadingDim()]      //     Add to the elements
        += A[i+j*A_ld];
    }
  }
  Y->commitSubMultiVector(&sub_mv);                 // Commit changes back to Y
}
\end{verbatim}}

Note that in the above function that the underlying
{}\texttt{\textit{Multi\-Vector\-Base}} object {}\texttt{Y} is not
guaranteed to be modified until the function

{\scriptsize\begin{verbatim}
  Y->commitSubMultiVector(&sub_mv);
\end{verbatim}}

{}\noindent{}is called.  Of course, no functions on the
{}\texttt{\textit{Multi\-Vector\-Base}} object {}\texttt{Y} should be
performed (except perhaps to access its {}\texttt{range()} and
{}\texttt{domain()} spaces) should be called between the time that a
non-\texttt{const} view is extracted and when it is committed back
with a call to {}\texttt{commit\-Sub\-Multi\-Vector(...)}.

The types of explicit element access to multi-vectors described above is
critical in block GMRES algorithms and in a compact limited memory sub-ANA
first introduced in Section~\ref{tsfcore:sec:LBFGS} as well as in a number of
other ANAs.

%
\subsection{Miscellaneous Issues}
%

In the following subsections, we discuss various miscellaneous issues that are
not specific to any single interface yet are worth covering.

%
\subsubsection{Handling of the Index (i.e.\ Ordinal) Type}
%

While all of the Thyra ANA interfaces are template on the {}\texttt{Scalar}
type, some may find it strange that the interfaces are not also templated on
the {}\texttt{Index} (or {}\texttt{Ordinal}) type.  The type {}\texttt{Index}
directly used in the interfaces {}\textit{\texttt{Vector\-Space\-Base}},
{}\textit{\texttt{Multi\-Vector\-Base}} and {}\textit{\texttt{Vector\-Base}}
is a typedef to some type determined at configure time.  All uses of the type
{}\texttt{Index} are related in one way or another to the
{}\textit{\texttt{Vector\-Space\-Base\-::dim()}} function.  {}\texttt{Index}
must be a signed integer capable of holding the largest global dimension of
any vector space that will be created.  On 32 bit systems this will typically
be a 32 bit integer (i.e.\ {}\texttt{int}) and on 64 bit systems this will
typically be a 32 or a 64 bit integer (i.e.\ {}\texttt{long int}).  This is a
globally defined and consistent typedef that is used by all code which is
compiled and linked against the Thyra ANA interfaces.

A common concern is that globalally using a 64 bit integer when only 32 bit
smaller integer may be needed will result in wasted storage space and degraded
runtimes.  The goal of this section is to address these concerns and to show
that in the context of the Thyra ANA interfaces, this is not the case.

The following discussion assumes that conversions from {}\texttt{Index} to and
from any smaller integer type are well defined.  The C++ standard for integral
conversions [???] guarantees that as long as the same value can be represented
using any two integral types {}\texttt{int\-\_type\-\_1} and
{}\texttt{int\-\_type\-\_2} then the following function will return true:

{\scriptsize\begin{verbatim}
template <class int_type_2, class int_type_1>
bool conversionCheck( int_type_1 val1 )
{
  int_type_2 val2   = val1;
  int_type_1 val12  = val2;
  return val12 == val1;
}
\end{verbatim}}

The standard also guarantees that the conversions
%
{\scriptsize\begin{verbatim}
signed char -> signed short int -> signed int -> signed long int
\end{verbatim}}
%
{}\noindent{}are always ``value preserving'' (see ???).  Therefore, any
conversion from a {}\texttt{signed short int} to a {}\texttt{signed long int}
and back will give the same {}\texttt{signed short int} number.  This is the
key behavior of C++ that allows the definition only a single {}\texttt{Index}
type at the interface level and also allows the use of smaller integral types
at lower implementation levels.

The type {}\texttt{Index} is also used in the aggregate type
{}\texttt{Range\-Pack\-::Range1D} which represents a range of integers.  The
type {}\texttt{Range1D} is used in many of the Thyra ANA interfaces.

Now let us look all of the functions that involve the types {}\texttt{Index}
or {}\texttt{Range1D} and consider some use cases that demonstrate various
integral type conversions.  The functions using {}\texttt{Index} or
{}\texttt{Range1D} are:

{\scriptsize\begin{verbatim}
namespace Thyra {

template<class Scalar>
class VectorSpaceBase {
public:
  ...
  virtual Index dim() const = 0;
  ...
};

template<class Scalar>
class MultiVectorBase : virtual public LinearOpBase<Scalar> {
public:
  ...
  virtual Teuchos::RefCountPtr<const VectorBase<Scalar> > col(Index j) const;
  virtual Teuchos::RefCountPtr<VectorBase<Scalar> > col(Index j) = 0;
  virtual Teuchos::RefCountPtr<const MultiVectorBase<Scalar> > subView( const Range1D& col_rng ) const;
  virtual Teuchos::RefCountPtr<MultiVectorBase<Scalar> > subView( const Range1D& col_rng );
  virtual Teuchos::RefCountPtr<const MultiVectorBase<Scalar> > subView( const int numCols, const int cols[] ) const;
  virtual Teuchos::RefCountPtr<MultiVectorBase<Scalar> > subView( const int numCols, const int cols[] );
  virtual void applyOp( const RTOpPack::RTOpT<Scalar> &primary_op, const size_t num_multi_vecs
    ,const MultiVectorBase<Scalar>* multi_vecs[], const size_t num_targ_multi_vecs
    ,MultiVectorBase<Scalar>* targ_multi_vecs[], RTOpPack::ReductTarget* reduct_objs[], const Index primary_first_ele
    ,const Index primary_sub_dim,const Index primary_global_offset, const Index secondary_first_ele
    ,const Index secondary_sub_dim ) const;
  virtual void applyOp( const RTOpPack::RTOpT<Scalar> &primary_op, const RTOpPack::RTOpT<Scalar> &secondary_op
    ,const size_t num_multi_vecs, const MultiVectorBase<Scalar>* multi_vecs[], const size_t num_targ_multi_vecs
    ,MultiVectorBase<Scalar>* targ_multi_vecs[], RTOpPack::ReductTarget* reduct_obj, const Index primary_first_ele
    ,const Index primary_sub_dim, const Index primary_global_offset, const Index secondary_first_ele
    ,const Index secondary_sub_dim ) const;
  virtual void getSubMultiVectorBase( const Range1D &rowRng, const Range1D &colRng
    ,RTOpPack::SubMultiVectorBaseT<Scalar> *sub_mv ) const;
  virtual void getSubMultiVectorBase( const Range1D &rowRng, const Range1D &colRng
    ,RTOpPack::MutableSubMultiVectorBaseT<Scalar> *sub_mv );
  ...
};

template<class Scalar>
class VectorBase : virtual public MultiVectorBase<Scalar> {
public:
  ...
  virtual void applyOp( const RTOpPack::RTOpT<Scalar> &op, const size_t num_vecs
    ,const VectorBase<Scalar>* vecs[], const size_t num_targ_vecs ,VectorBase<Scalar>* targ_vecs[]
    ,RTOpPack::ReductTarget *reduct_obj ,const Index first_ele ,const Index sub_dim
    ,const Index global_offset ) const = 0;
  virtual void getSubVectorBase( const Range1D& rng, RTOpPack::SubVectorBaseT<Scalar>* sub_vec ) const;
  virtual void getSubVectorBase( const Range1D& rng, RTOpPack::MutableSubVectorBaseT<Scalar>* sub_vec );
  virtual void setSubVectorBase( const RTOpPack::SparseSubVectorBaseT<Scalar>& sub_vec );
  ...
};

} // namespace Thyra
\end{verbatim}}

The use of {}\texttt{Index} directly or indirectly in all of the above
functions can be categorized into one of the following general use cases:

\begin{itemize}
%
\item Returning the dimension of a space.
%
\item Selecting an offset into a vector or multivector.
%
\item Selecting a range (or a single element) in a vector or multivector.
%
\end{itemize}

Let us consider an example where a distributed-memory parallel vector space is
being used where local processor indexing uses {}\texttt{int} but the global
indexing uses {}\texttt{long int} which is typedefed to {}\texttt{Index}.

{}\textbf{ToDo: show an example class for the MPI vector space!  It may be a
good idea to add a smaller templated type to the SimpleMPIVectorSpace and
SimpleMPIVector classes to show how this is done. }

In the first use case, the local number of elements {}\texttt{int localDim} on
each processor would be globaly reduced in order to determine the global
dimension {}\texttt{long int globalDim} which is returned by the function
{}\texttt{dim()}.  Before {}\texttt{MPI\-\_All\-\_reduce(...)} is called the
local {}\texttt{localDim} values would be converted into {}\texttt{long int}
types and then the global reduction would be preformed using {}\texttt{long
int}.

Related to the second use case, a global offset {}\texttt{globalOffset} can be
converted into a local offset by subtracting the processor's element's offset
into the global vector.  The result of this subtraction is guaranteed to fit
into the smaller type {}\texttt{small int}.

The third use case of setting a range of global elements and mapping to local
elements is the same as the second use case of mapping from a global to a
local offset.

%
\subsubsection{Aliasing of {}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Multi\-Vector\-Base}} arguments}
\label{tsfcore:sec:aliasing}
%

It has not been stated specifically yet but in all
{}\texttt{\textit{Vector\-Base}}, {}\texttt{\textit{Multi\-Vector\-Base}} and
{}\texttt{\textit{Linear\-Op\-Base}} functions where a
{}\texttt{\textit{Vector\-Base}} or {}\texttt{\textit{Multi\-Vector\-Base}}
object may be modified, it is strictly forbidden for any of the mutable
objects to alias any of the other objects of the same type in the same
function.  For example, code like the following is strictly forbidden.

{\scriptsize\begin{verbatim}
template<class Scalar>
void foo3( const LinearOp& M, ETransp M_trans, VectorBase<Scalar>* x )
{
  M.apply(M_trans,*x,x);  // Error!!!!!!!!!!
}
\end{verbatim}}

{}\noindent{}Note that typically the above function would not even get
to the numerics (where it would most likely compute the wrong results)
because {}\texttt{M.range()->isCompatible(*M.domain())==false} in
general.  Instead, this operation must be implemented as follows.

{\scriptsize\begin{verbatim}
template<class Scalar>
void foo4( const LinearOp& M, ETransp M_trans, VectorBase<Scalar>* x )
{
  Teuchos::RefCountPtr<VectorBase<Scalar> > x_tmp = x->clone(); // Create a copy
  M.apply(M_trans,*x_tmp,x);                                    // Okay!
}
\end{verbatim}}

{}\noindent{}Allowing client code to pass in aliased arguments would
greatly complicate the implementation of most RTOp,
{}\texttt{\textit{Multi\-Vector\-Base}} and {}\texttt{\textit{Linear\-Op\-Base}}
subclasses and would introduce the possibility of many different types
of bugs that would be extremely difficult to track down.  This is an
issue that is usually not well defined in most linear algebra
interfaces but it is a very important issue.  Allowing ANA developers
to alias objects in these functions does not provide any new
functionality and is considered to be only nonessential but convenient
functionality and is therefore not included in Thyra.  In general,
it is not possible to determine, from the abstract interfaces for the
objects themselves, if objects alias each other.  To perform this type
of test would require special functions be added to the
{}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Multi\-Vector\-Base}}
interfaces and implementing these test functions would complicate the
development of these types of subclasses greatly.

Note that aliasing of input data with output data is not strictly
forbidden, and is allowd as long as this is built into the operation.
For example, in the {}\texttt{\textit{LinearOp\-::apply(\-...)}}
function, the vector $y$ both supplies data for the operation (if $\beta
\ne 0$) and stores the output for the operation as shown in
(\ref{tsfcore:equ:apply_vec}).  The same applies to several of the
RTOp-based vector operations shown in Figure
{}\ref{tsfcore:fig:std_vec_ops} (i.e.~\texttt{Vp\_S(...)},
{}\texttt{Vt\_S(...)}, {}\texttt{Vp\_S(...)}, {}\texttt{Vp\_StV(...)}
and {}\texttt{ele\_wise\_prod(...)}).  Allowing vectors and
multi-vectors to both supply data for an operation and store output
from an operation is fine as long as the operation has been
specifically designed to handle this as the above mentioned operations
have.

In summary, do not alias output arguments with each other or with
other input arguments in any of the Thyra interface functions.

%%
%\section{An Example Abstract Numerical Algorithm : An Iterative Linear Solver}
%\label{tsfcore:sec:ANA_iter_solver_example}
%%
%
%In this section we describe how Thyra can be directly used to build ANAs and
%while this is not the primary role Thyra is designed for, this example shows
%that Thyra provides all of the needed functionality for near-optimaly
%performing implementations.  Code for a partial ANA in the form of a compact
%LBFGS method was described in Section~\ref{tsfcore:sec:LBFGS}.  In this
%section, we will describe the implementation of a simple block BiCG
%{}\cite{ref:tmpls_for_iter_systems} method.  BiCG was chosen for this example
%was because it requires adjoints and is fairly simple.  Other types of block
%iterative linear solvers such as methods as CG, BiCGStab, GMRES and QMR
%{}\cite{ref:tmpls_for_iter_systems} can be implemented in a similar manner.
%
%The subclass {}\texttt{BiCG\-Solver} implements a simple block BiCG
%method.  A listing for a single-vector version of the BiCG method is
%shown in Figure {}\ref{tsfcore:fig:BiCG}.  This listing is identical
%to the listing in {}\cite{ref:tmpls_for_iter_systems} except for the
%substitutions $A = op(M)$, $M = op(\tilde{M})$ and $b =a y$ (where $a$
%is a scalar multiplier).  The multi-vector version, as implemented
%using Thyra in code, follows in a straightforward manner.  This
%implementation does not take advantage of any potential linear
%dependence in the right-hand-side vectors in an attempt to accelerate
%the method such as is described in [???].  Such an enhanced
%multi-vector version could be implemented in a similar manner.
%
%\begin{figure}
%\begin{center}
%\fbox{
%\begin{minipage}{\textwidth}
%{\bsinglespace
%\begin{tabbing}
%\hspace{4ex}\=\hspace{4ex}\=\hspace{4ex}\=\hspace{4ex} \\
%\>	Compute $r^{(0)} = a y - op(M) x^{(0)}$ for the initial guess $x^{(0)}$.\hspace{4ex} \\
%\>	Choose $\tilde{r}^{(0)}$ (for example, $\tilde{r}^{(0)} = \mbox{randomize}(-1,+1)$).\hspace{4ex} \\
%\>	\textbf{for} $i = 1, 2, \ldots$ \\
%\>	\>	solve $op(\tilde{M}) z^{(i-1)} = r^{(i-1)}$ \\
%\>	\>	solve $op(\tilde{M})^T \tilde{z}^{(i-1)} = \tilde{r}^{(i-1)}$ \\
%\>	\>	$\rho_{i-1} = z^{{(i-1)}^T} \tilde{r}^{(i-1)}$ \\
%\>	\>	\textbf{if} $\rho_{i-1} = 0$, \textbf{method fails} \\
%\>	\>	\textbf{if} $i = 1$ \\
%\>	\>	\>	$p^{(i)} = z^{(i-1)}$ \\
%\>	\>	\>	$\tilde{p}^{(i)} = \tilde{z}^{(i-1)}$ \\
%\>	\>	\textbf{else} \\
%\>	\>	\>	$\beta_{i-1} = \rho_{i-1}/\rho_{i-2}$ \\
%\>	\>	\>	$p^{(i)} = z^{(i-1)} + \beta_{i-1} p^{(i-1)}$ \\
%\>	\>	\>	$\tilde{p}^{(i)} = \tilde{z}^{(i-1)} + \beta_{i-1} \tilde{p}^{(i-1)}$ \\
%\>	\>	\textbf{endif} \\
%\>	\>	$q^{(i)} = op(M) p^{(i)}$ \\
%\>	\>	$\tilde{q}^{(i)} = op(M)^T \tilde{p}^{(i)}$ \\
%\>	\>	$\gamma_{i} = \tilde{p}^{{(i)}^T} q^{(i)}$ \\
%\>	\>	$\alpha_{i} = \rho_{i-1}/\gamma_{i}$ \\
%\>	\>	$x^{(i)} = x^{(i-1)} + \alpha_{i-1} p^{(i)}$ \\
%\>	\>	$r^{(i)} = r^{(i-1)} - \alpha_{i-1} q^{(i)}$ \\
%\>	\>	$\tilde{r}^{(i)} = \tilde{r}^{(i-1)} - \alpha_{i-1} \tilde{q}^{(i)}$ \\
%\>	\>	check convergence; continue if necessary \\
%\>	\textbf{end}
%\end{tabbing}
%\esinglespace}
%\end{minipage}
%}%fbox
%\end{center}
%\caption{
%\label{tsfcore:fig:BiCG}
%A single-vector version of the preconditioned bi-conjugate gradient method (BiCG).
%}
%\end{figure}
%
%Figure {}\ref{tsfcore:fig:BiCG_code} shows a partial listing for the
%{}\texttt{BiCGSolver\-::doIteration(...)} function (which implements a
%single iteration of the BiCG method) as implemented in the file
%{}\texttt{Thyra\-Solvers\-BiCG\-Solver.hpp}.
%%
%{\bsinglespace
%\begin{figure}
%\begin{minipage}{\textwidth}
%{\scriptsize\begin{verbatim}
% 00273 template<class Scalar>
% 00274 void BiCGSolver<Scalar>::doIteration(
% 00275   const LinearOpBase<Scalar> &M, ETransp opM_notrans, ETransp opM_trans, MultiVectorBase<Scalar> *X, Scalar a
% 00276   ,const LinearOpBase<Scalar> *M_tilde_inv, ETransp opM_tilde_inv_notrans, ETransp opM_tilde_inv_trans
% 00277   ) const
% 00278 {
% 00285   const Index m = currNumSystems_;
% 00286   int j;
% 00287   if( M_tilde_inv ) {
% 00288     M_tilde_inv->apply( opM_tilde_inv_notrans, *R_,       Z_.get()       );
% 00289     M_tilde_inv->apply( opM_tilde_inv_trans,   *R_tilde_, Z_tilde_.get() );
% 00290   }
% 00291   else {
% 00292     assign( Z_.get(),       *R_        );
% 00293     assign( Z_tilde_.get(), *R_tilde_  );
% 00294   }
% 00299   dot( *Z_, *R_tilde_, &rho_[0] );
% 00303   for(j=0;j<m;++j) {
% 00304     TEST_FOR_EXCEPTION(
% 00305       rho_[j] == 0.0, Exceptions::SolverBreakdown
% 00306       ,"BiCGSolver<Scalar>::solve(...): Error, rho["<<j<<"] = 0.0, the method has failed!"
% 00307         );
% 00308   }
% 00309   if( currIteration_ == 1 ) {
% 00310     assign( P_.get(),       *Z_       );
% 00311     assign( P_tilde_.get(), *Z_tilde_ );
% 00312   }
% 00313   else {
% 00314     for(j=0;j<m;++j) beta_[j] = rho_[j]/rho_old_[j];
% 00315     update( *Z_,       &beta_[0], 1.0, P_.get()       );
% 00316     update( *Z_tilde_, &beta_[0], 1.0, P_tilde_.get() );
% 00317   }
% 00322   M.apply(opM_notrans, *P_,       Q_.get()       );
% 00323   M.apply(opM_trans,   *P_tilde_, Q_tilde_.get() );
% 00328   dot( *P_tilde_, *Q_, &gamma_[0] );
% 00329   for(j=0;j<m;++j) alpha_[j] = rho_[j]/gamma_[j];
% 00334   for(j=0;j<m;++j) {
% 00335     TEST_FOR_EXCEPTION(
% 00336       alpha_[j] == 0.0 || RTOp_is_nan_inf(alpha_[j]), Exceptions::SolverBreakdown
% 00337       ,"BiCGSolver<Scalar>::solve(...): Error, rho["<<j<<"] = 0.0, the method has failed!"
% 00338       );
% 00339   }
% 00340   update( &alpha_[0], +1.0, *P_, X );
% 00341   update( &alpha_[0], -1.0, *Q_, R_.get() );
% 00342   update( &alpha_[0], -1.0, *Q_tilde_, R_tilde_.get() );
% 00348 }
%\end{verbatim}}
%\end{minipage}
%\caption{
%\label{tsfcore:fig:BiCG_code}
%Implementation of an iteration of a multi-vector version of BiCG.
%}
%\end{figure}
%\esinglespace}
%%
%All of the functions called in the C++ code shown in Figure
%{}\ref{tsfcore:fig:BiCG_code} have already been described except for
%the non-member functions {}\texttt{assign(...)} (lines 292, 293, 310
%and 311) and {}\texttt{update(...)} (lines 315, 316 and 340--342)
%which are defined in the header
%{}\texttt{Thyra\-Multi\-Vector\-Std\-Ops.hpp}.  There are two
%assignment functions {}\texttt{assign(...)}: one that assigns a
%{}\texttt{\textit{Multi\-Vector\-Base}} object to a {}\texttt{Scalar}, and
%another that assigns one {}\texttt{\textit{Multi\-Vector\-Base}} object to
%another.  Both of these functions are implemented through
%{}\texttt{\textit{Multi\-Vector\-::applyOp(\-...)}} and use
%already-defined RTOp operators.  The two versions of the
%{}\texttt{update(...)} function used in this code, however, can not use
%{}\texttt{\textit{Multi\-Vector\-::applyOp(\-...)}} and instead are
%implemented column-by-column as, for instance
%%
%\[
%(\alpha_{(j)} \beta) U_{(:,j)} + V_{(:,j)} \rightarrow V_{(:,j)}, \; \mbox{for} \; j = 1 \ldots m
%\]
%%
%in the function
%
%{\scriptsize\begin{verbatim}
%template<class Scalar>
%void Thyra::update( Scalar alpha[], Scalar beta, const MultiVectorBase<Scalar>& U, MultiVectorBase<Scalar>* V )
%{
%  ...
%  const int m = U.domain()->dim();
%  for( int j = 1; j <= m; ++j )
%    Vp_StV( V->col(j).get(), alpha[j-1]*beta, *U.col(j) );
%}
%\end{verbatim}}
%
%{}\noindent{}where the {}\texttt{Vp\_StV(...)} function is the axpy
%operation for vectors and is declared in the header
%{}\texttt{Thyra\-Vector\-StdOps\-Decl.hpp}.  Note that when running
%the above BiCG method in an SPMD configuration (where the ANA runs in
%parallel and in duplicate in each process) this implementation of
%{}\texttt{update(...)} does not involve any communication or require
%any synchronization and therefore will not affect the performance of
%the algorithm for a communication point of view.  However, when
%running in a master-slave configuration (where the ANA runs on the
%master and the linear algebra runs in the $N_p$ slave process) every
%function invocation of a function on a nonlocal Thyra object involves
%communication, including each call to
%{}\texttt{\textit{Multi\-Vector\-::col(j)}}.  While the number of
%function invocations on Thyra objects for all of the other operations
%shown in Figure {}\ref{tsfcore:fig:BiCG_code} are independent of the
%number of right-hand-sides $m$, this is not true for the above
%implementation of the {}\texttt{update(...)} function.  However, from
%a local cache performance point of view, note that this is a level-1
%BLAS operation so there is no real performance motivation for
%providing a multi-vector version.
%
%The reason that this operation is performed column-by-column is that
%it is not well supported by the functions
%{}\texttt{\textit{Multi\-Vector\-::applyOp(\-...)}} or
%{}\texttt{\textit{Multi\-Vector\-::apply(\-...)}}.  The problem is
%that in the current design of RTOp and
%{}\texttt{\textit{Multi\-Vector\-::applyOp(\-...)}}, an RTOp operator
%object does not have any way to distinguish between different columns
%of a multi-vector in order to apply different values of $\alpha_{(j)}$
%for each column $j$.  To allow this would require changing the design
%of RTOp to deal with multi-vectors directly instead of just individual
%vectors.
%
%This operation could be implemented with the
%{}\texttt{\textit{Multi\-Vector\-::apply(\-...)}} function using a
%{}\texttt{\textit{Multi\-Vector\-Base}} object
%%
%\[
%A = {\bmat{cccc} \alpha_{(1)} \beta \\ & \alpha_{(2)} \beta \\ & & \ddots \\ & & & \alpha_{(m)} \beta \emat}
%\]
%%
%and then performing
%%
%\[
%U A + V \rightarrow V.
%\]
%%
%But, since it would generally be assumed that the local multi-vector
%$A$ is dense, this would likely cost $O(n m^2)$ flops instead of the
%$O(n m)$ flops of the actual update operation (where $n$ is the global
%number of unknowns in each linear system).
%
%To yield a near-optimal implementation in all computing environments,
%this type of update operation would have to be added directly to the
%{}\texttt{\textit{Multi\-Vector\-Base}} interface.  However, it is not clear
%that this is justified since iterative linear solvers such as this
%BiCG method are likely to only run in SPMD mode.
%
%With that said, assuming that the BiCG method shown if Figure
%{}\ref{tsfcore:fig:BiCG_code} is run in SPMD mode, the entire
%algorithm only involves three global reductions per BiCG iteration --
%independent of the number of linear systems $m$ that are being solved.
%These three global reductions include the two multi-vector dot
%products on lines 299 and 328 along with a multi-vector norm
%calculation for the convergence check which is performed in a calling
%function.  The two preconditioner solves on lines 288--289 and the two
%multi-vector operator applications in lines 322--323 likely involve
%global communication also, so in general there will be a total of
%seven parallel synchronizations per BiCG iteration (or only five is no
%preconditioner is used) --- independent of the number of linear
%systems being solved.  Therefore, this implementation allows for
%near-optimal performance both in terms of minimizing the number of
%global synchronizations and in local cache performance (because of the
%use of block operations with multi-vectors).

%
\section{General Object-Oriented Software Design Concepts and Principles}
\label{tsfcore:sec:general_software_concepts}
%
 
In this section we discuss some of the basic C++ idioms and design
patterns that have been used to construct the Thyra C++ classes.
The primary issues relate to modern approaches to general memory
management for object-oriented programming in C++ and to object
allocation verses initialization.  There is also a short discussion of
proper object-oriented design principles.

%
\subsection{General C++ idioms used by Thyra}
\label{tsfcore:sec:tsfcore-c++-idioms}
%

Thyra uses the following general C++ idioms:

\begin{enumerate}

{}\item[a)] Objects are allocated through ``abstract factory'' interfaces
that return {}\texttt{Ref\-Count\-Ptr}-wrapped objects.

{}\item[b)] Details of object deallocation are handled through
{}\texttt{Ref\-Count\-Ptr}.

{}\item[c)] Objects can be optionally copied through {}\texttt{clone()}
functions.

{}\item[d)] Concrete subclasses use the ``separate construction and
initialization'' idiom for maximum flexibility and reusability.

{}\item[e)] Error handling is performed through the C++ exception
handling mechanism and all exceptions thrown are derived from
{}\texttt{std\-::exception()} and are thrown using the macro
{}\texttt{TEST\-\_FOR\-\_EXCEPTION(...)}.

\end{enumerate}

a) The basic design patterns used for memory management in Thyra are
the ``abstract factory'' and the ``prototype'' patterns as described
in the well known ``gang-of-four'' book {}\cite{ref:gama_et_al_1995}.
When combined with the C++ idiom of smart reference-counted pointers
for automatic garbage collection (see {}\cite[Items
28-29]{ref:meyers_1996}) these design patterns become very powerful
and greatly help C++ developers to dodge many of the pitfalls of
dynamic memory allocation in C++.  The basic memory management
infrastructure is defined in a namespace called {}\textit{Teuchos}
which is external to Thyra.  By far the most important class in
{}\textit{Teuchos} (see {}\cite{ref:moochodevguide}) is the templated
smart reference-counted pointer class {}\texttt{RefCountPtr<>}.  This
templated class is very close to the templated class
{}\texttt{shared\_ptr<>} that is provided in the {}\texttt{boost}
library {}\cite{ref:boost}.  The use of the class
{}\texttt{RefCountPtr<>} is described very well in
{}\cite{ref:RefCountPtr} and in the Doxygen documentation so it will
not be described here.  However, example C++ code that uses this class
was shown in the above sections.

b) All memory management issues associated with abstract objects, which
include instantiations of all of the classes shown in Figure
{}\ref{thyra:fig:basic_op_vec_itfc}, are handled using
{}\texttt{RefCountPtr<>}.  In this way, a client never needs to
explicitly delete any of these objects.  An object will be
automatically deleted once all of the {}\texttt{RefCountPtr<>} objects
that point to the object go out of scope.  The functions
{}\texttt{\textit{Vector\-Space\-Base\-::createMember()}} and
{}\texttt{\textit{Vector\-Space\-Base\-::createMembers(...)}}, as well as may
others that (may) have to allocate new objects, all return pointers to
these objects embedded in {}\texttt{RefCountPtr<>} objects.  Note that
there are many types of C++ client code, such as functions and
functions, that simply collaborate with preallocated objects for a short
period of time and do not need to assume any responsibilities for
memory management.  In these cases, the reference or raw pointer to
the underlying object can be extracted from the
{}\texttt{RefCountPtr<>} object which is then passed on to C++ code
that accepts only references or raw pointers.  There are several
examples of this type of usage in the code examples in the previous
sections.

c) The ``abstract factory'' design pattern (as implemented by
{}\texttt{\textit{Vector\-Space\-Base}} for instance) enabled with
{}\texttt{RefCountPtr<>} effectively relieves clients from having to
deal with how objects are created and destroyed but there is another
type of memory management task that is also required in some use
cases.  To describe the problem, suppose that a C++ client has a
handle to a {}\texttt{\textit{Linear\-Op\-Base}} object (either through a
smart or raw pointer) and that client wants to copy the object so that
some other client will not modify the object before said client is
finished with the current {}\texttt{\textit{Linear\-Op\-Base}} object.  This
is a classical problem with the use of objects with {\em reference}
(or {\em pointer}) semantics which does not occur with objects that
use {\em value} semantics {}\cite{ref:stroustrup_1997}.  This use case
requires the ability to ``clone'' an object which is the basis of the
``prototype'' design pattern.  Every abstract interface shown in
Figure {}\ref{thyra:fig:basic_op_vec_itfc} defines some type of
{}\texttt{\textit{clone()}} function which return
{}\texttt{RefCountPtr<>} objects pointing to the cloned (or copied)
object.  In some cases the concrete subclass does not have to override
the {}\texttt{\textit{clone()}} function in order achieve this
functionality (i.e.~\texttt{\textit{Vector\-Base}} and
{}\texttt{\textit{Multi\-Vector\-Base}}) while in other cases it does
(i.e.~\texttt{\textit{Linear\-Op\-Base}}).  In cases where a meaningful
default implementation for the {}\texttt{\textit{clone()}} function can
not be provided, a default implementation returning a null
{}\texttt{RefCountPtr<>} object is provided.  The implication of this
approach is that while the {}\texttt{\textit{clone()}} function is a
useful feature, it is considered an optional feature where subclasses
are not required to provide an implementation.  However, every good
subclass implementation should provide an implementation of the
{}\texttt{\textit{clone()}} function since it makes the work of the
client much easier in some use cases.
	
d) Another set of issues that are related to the memory management
issues described above are issues concerning object allocation verses
object initialization.  Scott Myers {}\cite{ref:meyers_1996} and
others advocate the ``object initialization on construction'' style of
developing subclasses on the basis that is makes the subclasses easier
to write.  However, this approach is not optimal for the reusability
of a subclass in different use cases from the ones for which the
subclass was originally designed.  To maximize ease of use by clients
and maximize reusability, another style of developing subclasses
``independent object allocation and initialization'' is to be
preferred.  This latter style of developing subclasses is the approach
that is adopted by all of the Thyra concrete subclasses.  To support
this, every concrete subclass has a default constructor (which
constructs to an uninitialized state) and a set of
{}\texttt{initialize(...)}  functions that are used to actually
initialize the object.  In order to also support the ``object
initialization on construction'' style (which is useful in many
different cases) there are also a corresponding set of constructors
that call these {}\texttt{initialize(...)} functions using the same
arguments.  For an example of this style, see the concrete subclass
{}\texttt{MultiVectorCols} in the Doxygen documentation.

e) Error handling in Thyra uses built-in exception handling in C++.
All exceptions thrown by Thyra code are derived from
{}\texttt{std::exception}.  Exceptions are thrown using the macro
{}\texttt{TEST\-\_FOR\-\_EXCEPTION(...)} which results in the
{}\texttt{std::exception::what()} function containing an error message
with the file name and line number from where the exception was
thrown.  This type of information is very helpful in debugging.  In
many cases, armed with just this information and a good
programmer-developed error message, a bug can be found, diagnosed and
fixed without even needing to run a debugger.  The use of the macro
{}\texttt{TEST\-\_FOR\-\_EXCEPTION(...)} was shown in several of the
above example code snippets.

%
\subsection{General object-oriented design concepts used by Thyra}
\label{tsfcore:sec:good-oo-design}
%

Finally, a few comments on proper object-oriented design are described
here that used in the design of Thyra.  These concepts are:

\begin{enumerate}

{}\item[a)] {}\underline{Every} operation should be implementable by
{}\underline{every} concrete subclass.

{}\item[b)] If a) is not possible, then {}\underline{all} preconditions
that need to be satisfied in order for an operation to be called
sucessfuly must be reasonably knowable by the client.

{}\item[c)] If a postcondition for an operation can not be met then
an exception should be thrown.

{}\item[e)] An interface should include {}\underline{all} operations
needed for near-optimal performance in every reasonable use case.

{}\item[d)] But, reasonable default implementations should be provided
for as many operations in an interface as possible in order to allow
for faster prototyping efforts.

\end{enumerate}

a) It is generally accepted that object-oriented interfaces should be
minimal and every function in an interface should be implementable by
every concrete implementation {}\cite[Section
24.4.3]{ref:stroustrup_1997}.  However, there are some cases where the
goals of simplicity and strict conformance to this principle of ideal
object-oriented design are at odds.  Finding the proper balance of
simplicity and strict object-oriented correctness requires knowledge,
experience and taste.  In all but one case, the Thyra interfaces
strictly conform to this ideal principle of object-oriented design.
The one exception is the support of transposed (adjoint) operations.
If an operation may not be supportable by an implementation then the
interface should provide a way for the client to discern this without
having to actually invoke the operation.


b) The principle in a) is related to another principle of proper
object-oriented design that absolutely every interface and function in
Thyra adheres to and this is the principle that every function should
have its preconditions (see {}\cite{ref:uml_distilled_2nd_ed} for a
decision of pre- and postconditions) clearly stated and the client
should be able to check the preconditions before the function is called.
Failure to use this principle makes the use of such software very
difficult and results in a lot of unexpected runtime errors.  If an
operation can not be performed by an object because of the violation
of a precondition, then a good way to handle this is for the function to
throw an exception.  However, proper object-oriented design does not
require this since it is the responsibility of the client to ensure
that preconditions are satisfied (see
{}\cite{ref:uml_distilled_2nd_ed}).  In practice, however, defensive
programming practices (see {}\cite{ref:stroustrup_1997}) dictate that
clients should be considered to be unreliable and therefore all
preconditions should be checked by every major function implementation
(at least in a debug build) and if a precondition is found to be
violated then an exception should be thrown which contain a detailed
error message that describes the problem (i.e.~as returned from
{}\texttt{std::exception::what()}).

c) If the preconditions are met before the function is called and the
function can not satisfy the postconditions for some reason then the
function should throw an exception in general.  This latter type of
exception is the primary reason that exception handling was added to
the C++ standard in the first place {}\cite{ref:design_evol_cpp}.

d) Another desirable principle of object-oriented design is that an
interface should provide declarations for all important functions for
which if specialized implementations for all of these functions were
provided, then the resulting overall software implementation would be
near-optimal with respect to storage and runtime efficiency.  Again,
knowledge, experience and taste are required in the selection of the
appropriate set of functions.  However, there is conflict between the
goals of declaring many functions for the sake of near-optimal
performance and the desire to keep the number of functions to a minimum
to ease subclass development.  This brings us to our next principle.

e) The approach that each Thyra interface takes to the issue in d)
is that the (nearly) full set of functions needed for a near-optimal
implementation are declared in the interface but reasonable
(suboptimal) default implementations are provided for as many of the
functions as possible.  Examples of the application of this principle
are mentioned for every major Thyra interface (for example, the
default implementation of the {}\texttt{\textit{Multi\-Vector\-Base}}
version of the function {}\texttt{\textit{LinearOp\-::apply(\-...)}} 
which is based on the {}\texttt{\textit{Vector\-Base}} version).

%%
%\section{Nonessential but Convenient Functionality}
%\label{tsfcore:sec:convenience_functionality}
%%
%
%While the basic Thyra interfaces described in this paper provide all
%of the functionality required to be directly used in ANA development
%these interfaces lack much of the nonessential but convenient
%functionality that is very helpful in developing ANA code.  This
%nonessential but convenient functionality can be built on top of the
%core functionality which is precisely the type of extra functionality
%that Thyra/utilities and TSFExtended provide.  In this section,
%several different examples of nonessential but convenient
%functionality are given along with references to where this
%functionality exists in TSF and {}\textit{AbstractLinAlgPack}.
%
%%
%\subsection{Sub-vector views as {}\texttt{\textit{Vector\-Base}} objects}
%%
%
%In Section~\ref{tsfcore:sec:vec_apply_op}, the use case where the sub-vectors
%of a {}\texttt{\textit{Vector\-Base}} object are treated as logical vector was
%discussed.  The example in that section got the job done but a better approach
%to providing access to sub-vectors is to create a sub-view decorator subclass
%(see the ``decorator'' pattern in {}\cite{ref:gama_et_al_1995}) that allows
%the creation of a {}\texttt{Vector\-Base} view object of a contiguous range of
%elements in another {}\texttt{Vector\-Base} object.  Such a subclass is
%included in {}\textit{AbstractLinAlgPack} (see {}\texttt{VectorSubView} and
%{}\texttt{Vector\-Mutable\-Sub\-View}) and is very useful for high-level ANA
%code.  These ``sub-view'' subclasses can be easily implemented through the
%{}\texttt{\textit{Vector\-::applyOp(\-...)}}  function.
%
%%
%\subsection{Composition of {}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Linear\-Op\-Base}} objects}
%\label{tsfcore:sec:composite_abstractions}
%%
%
%The ideal way to represent composite blocked or product vector objects, such
%as described in Section~\ref{tsfcore:sec:vec_apply_op}, is to create a
%composite blocked or product vector subclass.  Interfaces and implementations
%of such product objects are provided in Thyra/utilites (see the classes
%{}\texttt{Product\-Vector\-Space}, {}\texttt{Product\-Vector} and
%{}\texttt{Product\-Multi\-Vector}).  These types of composite product
%{}\texttt{\textit{Vector\-Base}} and {}\texttt{\textit{Vector\-Space\-Base}}
%subclasses are easy to develop because of the specification of
%{}\texttt{\textit{Vector\-::applyOp(\-...)}}.
%
%Note that a product vector such as
%
%\[
%\tilde{x} = {\bmat{c} x_1 \\ x_2 \\ \vdots \\ x_N \emat}
%\]
%
%{}\noindent{}with $N$ block vectors is distictly different from a
%multi-vector
%
%\[
%Y = {\bmat{cccc} y_1 & y_2 & \ldots & y_N \emat}
%\]
%
%{}\noindent{}with $N$ colunns.  In the multi-vector $Y$, each of the
%column vectors $y_j$ lie in the same vector space (i.e.~the range
%space of the linear operator represented by the multi-vector) which
%may not be the case for the vector blocks $x_j$ of $\tilde{x}$ which
%may lie in distictly different vector spaces $\mathcal{X}_j$.  While
%it may seem that the mathematical differences between a multi-vector
%and a product vector are subtle, they are distictly different from a
%software implication point of view.  Multi-vectors are ment to
%represent tall, thin dense matrices such as for multiple
%right-hand-sides that are passed to a linear solver or for performing
%mulitple linear operator applications (with the same linear operator)
%while product vectors and product vector spaces are ment to represent
%single vector objects which are composed of individual vector blocks
%such as would be used for the composite unknowns in an SFE method or a
%multi-period design problem.  For example, a product vector space
%would be able to create a product multi-vector such as
%
%\[
%\tilde{Y} = {\bmat{c} Y_1 \\ Y_2 \\ \vdots \\ Y_N \emat}
%\]
%
%where each constituent multi-vector $Y_j$ may have a different range
%space but all must have the same domain space obviously.  Such a
%product multi-vector is implemented by
%{}\texttt{Product\-Multi\-Vector}.
%
%Similar generic composition subclasses can also exist for linear
%operators (see TSFExtended).
%
%%
%\subsection{Matlab-like notation and handle classes for linear algebra
%using operator overloading}
%\label{tsfcore:sec:operator_overloading}
%%
%
%Thyra contains abstractions for linear algebra objects.
%Mathematicians use a precise syntax to describe linear algebra
%operations.  Matlab {}\cite{ref:matlab} has established a useful
%convention for mathematical linear algebra syntax using only ASC
%characters.  C++ has operator overloading.  When you put all of this
%together it seems obvious, at first glance, that operator overloading
%in C++ should be used to specify linear algebra operations like
%
%\[
%y = A u + \gamma B^T v + \eta C w
%\]
%
%{}\noindent{}in C++ as
%
%\begin{verbatim}
%  y = A*u + gamma*trans(B)*v + eta*w;
%\end{verbatim}
%
%{}\noindent{}However, providing a near-optimal implementation (i.e.~no
%unnecessary temporaries or multiple memory accesses) of operator
%overloading for linear algebra in C++ is nontrivial.  While this type
%of syntax is desirable, it does not provide any new functionality and
%is only nonessential but convenient functionality and is therefore not
%included in the basic Thyra interfaces.  If such Matlab-like syntax
%is desired, it can be found in TSFExtended through the use of handle
%classes which include overloaded operators.  However, an efficient
%operator overloading mechanism in C++ is hard to implement and is
%difficult for C++ novices to debug through.  Operator overloading
%built on top of Thyra must be bullet proof and provide unmatched
%exception handling so that users must never need to debug through this
%code.
%
%Closely associated with operator overloading is the concept of handle
%classes {}\cite{ref:advanced_c++_coplien}.  Handles assume the same
%type of role as a smart pointers except all of the function forwarding
%(which is performed automatically with the operator function
%{}\texttt{RefCountPtr<>\-::operator->()}) must be performed manually
%in handle class (which must be written an maintained for every function
%on every class by some developer).  Handles make the implementation of
%linear algebra operations with operator overloading much easier.
%Handles are used extensively in TSFExtended.  Since Thyra does not
%implement operator overloading, handles classify as nonessential but
%convenient functionality and are therefore not included in Thyra.

%
\section{Summary}
%

Thyra provides the intersection of all of the functionality required by a
variety of abstract numerical algorithms ranging from iterative linear solvers
all the way up to optimizers.  The foundation of Thyra described here only
covers vector spaces, vectors, multi-vectors and linear operators.  While this
is sufficient for most linear ANA algorithms (i.e. linear equation solvers and
eigen solvers) it is not sufficient for higher-level nonlinear algorithms.
Various levels of extensions to these basic operator/vector interfaces are
described in various related documents.

By adopting Thyra as a standard interface layer, interoperability between
applications, linear algebra libraries and abstract numerical algorithms in
advanced scientific computing environments becomes automatic to a large
extent.

% ---------------------------------------------------------------------- %
% References
%
\clearpage
\bibliographystyle{plain}
\bibliography{references}
\addcontentsline{toc}{section}{References}

% ---------------------------------------------------------------------- %
% Appendices should be stand-alone for SAND reports. If there is only
% one appendix, put \setcounter{secnumdepth}{0} after \appendix
%
\appendix
\input{apdx_ThyraOperatorVectorClassDecl}

\begin{SANDdistribution}
% External
\SANDdistExternal{1}{} Omar Ghattas \\ Carnegie Mellon University\\5000 Forms Ave.\\Pittsburgh, PA 15213
\SANDdistExternal{1}{} Larry Biegler \\ Department Chemeical Engineering\\Carnegie Mellon University\\5000 Forms Ave.\\Pittsburgh, PA 15213
\SANDdistExternal{1}{} Carl Laird \\ Department Chemeical Engineering\\Carnegie Mellon University\\5000 Forms Ave.\\Pittsburgh, PA 15213
\SANDdistExternal{1}{} Matthias Heinkenschloss \\ Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Bill Symes\\Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Tony Padula\\Department of Computational and Applied Mathematics\\MS 134 Rice University\\
6100 S. Main Street\\Houston, TX 77005-1892
\SANDdistExternal{1}{} Mark Gockenbach \\ Department of Mathematical Sciences\\Michigan Technological University\\ 
1400 Townsend Drive\\Houghton, Michigan 49931-1295, U.S.A.
\SANDdistExternal{1}{} George Biros \\ Department of Applied Mechanics and Mechanical Engineering\\University of Pennsylvania\\
220 Towne Building 220 S. 33rd St.\\Philadelphia, PA 19104-6315, USA 
% Sandia Line
\SANDdistInternal{1}{0847}{Bill Camp}{9200}
\SANDdistInternal{1}{0847}{Sudip Dosanjh}{9233}
% 9211
\SANDdistInternal{1}{0847}{Scott Mitchell}{9211}
\SANDdistInternal{1}{1110}{Roscoe Bartlett}{9211}
\SANDdistInternal{1}{1110}{Scott Collis}{9211}
\SANDdistInternal{1}{0847}{Bart van Bloemen Waanders}{9211}
\SANDdistInternal{1}{0847}{Mike Eldred}{9211}
\SANDdistInternal{1}{0819}{Tim Trucano}{9211}
\SANDdistInternal{1}{0847}{Tony Giunta}{9211}
\SANDdistInternal{1}{0947}{Laura Swiler}{9211}
% 9214
\SANDdistInternal{1}{9217}{Mark Adams}{9214}
\SANDdistInternal{1}{1110}{Pavel Bochev}{9214}
\SANDdistInternal{1}{1110}{Todd Coffey}{9214}
\SANDdistInternal{1}{1110}{David Day}{9214}
\SANDdistInternal{1}{1110}{John Delaurentis}{9214}
\SANDdistInternal{1}{1110}{Michael Heroux}{9214}
\SANDdistInternal{1}{1110}{Ulrich Hetmaniuk}{9214}
\SANDdistInternal{1}{9217}{Jonathan Hu}{9214}
\SANDdistInternal{1}{1110}{Richard Lehoucq}{9214}
\SANDdistInternal{1}{1110}{Louis Romero}{9214}
\SANDdistInternal{1}{1110}{David Ropp}{9214}
\SANDdistInternal{1}{1110}{Heidi Thornquist}{9214}
\SANDdistInternal{1}{9217}{Raymond Tuminaro}{9214}
\SANDdistInternal{1}{1110}{James Willenbring}{9214}
\SANDdistInternal{1}{1110}{David Womble}{9214}
% 8962
\SANDdistInternal{1}{9217}{Steve Thomas}{8962}
\SANDdistInternal{1}{9217}{Paul Boggs}{8962}
\SANDdistInternal{1}{9217}{Kevin Long}{8962}
\SANDdistInternal{1}{9217}{Patricia Hough}{8962}
\SANDdistInternal{1}{9217}{Tamara Kolda}{8962}
\SANDdistInternal{1}{9217}{Monica Martinez-Canales}{8962}
\SANDdistInternal{1}{9217}{Pamela Williams}{8962}
\SANDdistInternal{1}{9217}{Victoria Howle}{8962}
% Sandia Misc
\SANDdistInternal{1}{1110}{William Hart}{9215}
\SANDdistInternal{1}{0847}{Steve Wojtkiewicz}{9124}
% Xyce developers
\SANDdistInternal{1}{0316}{Eric Keiter}{9233}
\SANDdistInternal{1}{0316}{Scott Hutchinson}{9233}
% Premo developers
\SANDdistInternal{1}{0316}{Curt Ober}{9233}
\SANDdistInternal{1}{0316}{Tom Smith}{9233}
% Main Sierra developers
\SANDdistInternal{1}{9143}{Carter Edwards}{0827}
\SANDdistInternal{1}{9143}{James Stewart}{0826}
% Main Nevada developers
\SANDdistInternal{1}{0819}{Ricard Drake}{9231}
% NOX/LOCA developers
\SANDdistInternal{1}{0316}{Robert Hoekstra}{9233}
\SANDdistInternal{1}{0316}{Roger Pawlowski}{9233}
\SANDdistInternal{1}{1110}{Eric Phipps}{9233}
\SANDdistInternal{1}{1110}{Andrew Salinger}{9233}
% Other Trilinos developers
\SANDdistInternal{1}{0826}{Alan Williams}{8961}
\SANDdistExternal{1}{}{Kendall Stanley}{}
% Housekeeping copies necessary for every unclassified report:
\SANDdistInternal{1}{9018}{Central Technical Files}{8945-1}
\SANDdistInternal{2}{0899}{Technical Library}{9610}
\SANDdistInternal{2}{0612}{Review \& Approval Desk}{4916}
% If report has a Patent Caution or Patent Interest, add this:
%\SANDdistInternal{3}{0161}{Patent and Licensing Office}{4916}
\end{SANDdistribution}

\end{document}
