\documentclass[pdf,ps2pdf,11pt]{SANDreport}
\usepackage{pslatex}
%Local stuff
\usepackage{graphicx}
\usepackage{latexsym}
%\usepackage{color}
%\usepackage[all]{draftcopy}
\input{rab_commands}

\raggedright

% If you want to relax some of the SAND98-0730 requirements, use the "relax"
% option. It adds spaces and boldface in the table of contents, and does not
% force the page layout sizes.
% e.g. \documentclass[relax,12pt]{SANDreport}
%
% You can also use the "strict" option, which applies even more of the
% SAND98-0730 guidelines. It gets rid of section numbers which are often
% useful; e.g. \documentclass[strict]{SANDreport}

% ---------------------------------------------------------------------------- %
%
% Set the title, author, and date
%

\title{\center
ASC Vertical Integration Milestone
}

\author{
Roscoe Bartlett (Technical PI),
Scott Collis (Management PI),
Todd Coffey,\\
David Day,
Mike Heroux,
Rob Hoekstra,
Russell Hooper,\\
Roger Pawlowski,
Eric Phipps,
Denis Ridzal,
Andrew Salinger,\\
Heidi Thornquist,
Jim Willenbring,
}

\date{}

%Sandia National
%Laboratories\footnote{ Sandia is a multiprogram laboratory operated by Sandia
%Corporation, a Lockheed-Martin Company, for the United States Department of
%Energy under Contract DE-AC04-94AL85000.}, Albuquerque NM 87185 USA


% ---------------------------------------------------------------------------- %
% Set some things we need for SAND reports. These are mandatory
%
\SANDnum{SAND2007-5839}
\SANDprintDate{September 2007}
\SANDauthor{
Roscoe Bartlett (Technical PI),
Scott Collis (Management PI),
Todd Coffey,
David Day,
Mike Heroux,
Rob Hoekstra,
Russell Hooper,
Roger Pawlowski,
Eric Phipps,
Denis Ridzal,
Andy Salinger,
Heidi Thornquist,
Jim Willenbring
}

% ---------------------------------------------------------------------------- %
% Build your markings. See example files and SAND Report Guide
%

\SANDreleaseType{Unlimited Release}
%\SANDreleaseType{Not approved for general release}
%\SANDmarkTopBottomCoverBackTitle{}
%\SANDmarkBottomCover{}
%\SANDmarkTopBottomCoverTitle{}
%\SANDmarkTop{}
%\SANDmarkBottom{}
%\SANDmarkTopBottom{}
%\SANDmarkCover{}
%\SANDmarkCoverTitle{}


% ---------------------------------------------------------------------------- %
%
% Start the document
%

\begin{document}

\maketitle


% ------------------------------------------------------------------------ %
% An Abstract is required for SAND reports
%

%\clearpage

%
\begin{abstract}
%

The FY2007 ASC Level-2 Vertical Integration Milestone effort developed the
vertical integration of many new advanced Trilinos solver packages to build
new predictive solution capabilities.  These were demonstrated on several
relevant problems including QASPR-related semiconductor problems modeled in
Charon and a MEMS design problem modeled in Aria/SIERRA.  All of the objectives of the
milestone have been met and exceeded in some cases.  In addition to the
Trilinos-specific accomplishments and the demonstration calculations, the
milestone work has also helped us realize a new vision for a deeper level of
collaboration between solver developers and application developers which
benefits everyone involved.  The bridge for this deeper collaboration is based
on the foundation of nightly building and testing of the combined development versions
of the application code (e.g.\ Charon) and Trilinos.

% 2007/08/23: rabartl:  We don't need the text below and it makes the abstract
% go past the cover page.  That is what the executive summary is for.
%
%We have reached several important conclusions after completing the milestone
%work.  First, Solving complex numerical problems to the highest quality with
%the greatest efficiency requires the vertical integration of many different
%types of advanced numerical algorithms that can be tailored to the specific
%problem.  Second, nightly building and testing of an application code and
%Trilinos brings algorithm developers and application developers closer
%together -- exchanging ideas and concerns -- and makes Trilinos a more
%customer focused effort while still helping drive publishable numerical
%algorithm solver research and reduces barriers for new algorithms to have
%impact through production application codes.  Several other important
%conculsions are also articulated.

%
\end{abstract}
%

% ------------------------------------------------------------------------ %
% An Acknowledgement section is optional but important, if someone made
% contributions or helped beyond the normal part of a work assignment.
% Use \section* since we don't want it in the table of context
%
%\clearpage
%\section*{Acknowledgment}
%
%
%The format of this report is based on information found
%in~\cite{Sand98-0730}.

% ------------------------------------------------------------------------ %
% The table of contents and list of figures and tables
% Comment out \listoffigures and \listoftables if there are no
% figures or tables. Make sure this starts on an odd numbered page
%
\cleardoublepage   % TOC needs to start on an odd page
\tableofcontents
\listoffigures
\listoftables

% ---------------------------------------------------------------------- %
% An optional preface or Foreword
%\clearpage
%\section{Preface}
%Although muggles usually have only limited experience with
%magic, and many even dispute its existence, it is worthwhile
%to be open minded and explore the possibilities.

% ---------------------------------------------------------------------- %
% An optional executive summary

\clearpage

\subsection*{Summary}

%
%... In some ways, the most important part of the document as I can imagine 
%... that it might be all that some manager read.
%

{}\noindent\textbf{Overview:} The ASC FY2007 ASC Vertical Integration
Milestone has demonstrated a full vertical integration of numerical algorithms
in Trilinos ranging from basic parallel linear algebra all the way
up through transient solvers and simulation-constrained optimization in a plug
an play, high-performance manner.  We are targeting using optimization methods
with Charon to do automatic parameter estimation against data in a fast and
robust way.  This work has provided a significant new capability by
demonstrating the power of giving advanced algorithms better access to
production application codes and by providing the software engineering
infrastructure to maintain the new capabilities in the long term.

{}\noindent\textbf{Milestone Completion:} We have accomplished all of our
promised objectives and have exceeded our mandate in several areas.  This new
capability has been released as part of Trilinos 8.0.

{}\noindent\textbf{Selected Accomplishments:} Some of the more noteworthy
accomplishments achieved during the milestone work include:\\[0.5ex]

\begin{enumerate}

{}\item Implemented full vertical-integration of Trilinos capabilities using
standard Thyra interfaces including: parallel distributed data-structures;
linear-solvers; precondtioners; nonlinear-solvers; eigen-solvers; automatic
differentiation; transient solvers; and optimization solvers.

{}\item Demonstrated these capabilities using the ASC Charon application with
QASPR semiconductor models included by performing:

  \begin{enumerate}
  
  {}\item Transient forward simulation,
  
  {}\item Transient forward sensitivity analysis, and
  
  {}\item Steady-state current-matching parameter estimation optimization.
  
  \end{enumerate}
  
{}\item As additional evidence of vertical-integration and to highlight that
these algorithmic tools are ready and available for a wide range of ASC
applications, we also assembled algorithms and performed:
  
  \begin{enumerate}
  
  {}\item Block eigensolves for a reacting flow problem in Charon that
  utilized at least eight distinct Trilinos packages.
  
  {}\item Design optimization of a MEMS actuator using Aria/SIERRA.
  
  \end{enumerate}
  
{}\item In addition to these demonstrations, this milestone helped to highlight
and address many of the challenges of injecting advanced algorithms into a
production application.

\end{enumerate}

% ---------------------------------------------------------------------- %
% An optional glossary. We don't want it to be numbered
%\clearpage
%\subsection*{Nomenclature}
%\addcontentsline{toc}{section}{Nomenclature}
%\begin{itemize}
%\item[alohomora]
%spell to open locked doors and containers
%\end{itemize}

% ---------------------------------------------------------------------- %
% This is where the body of the report begins; usually with an Introduction
%

\SANDmain % Start the main part of the report

%
\section{Introduction}
%

Many challenges exist in using cutting-edge research-driven numerical
algorithms and solvers to impact challenging production-quality applications.
Even more challenges exist in allowing production-quality applications to help
drive the research of numerical algorithms in a significant way.  Further, the
challenges become more daunting when considering new predictive simulation
tools like invasive uncertainty quantification (UQ), sensitivity analysis, and
optimization methods.  Addressing these challenges requires dedicated and
sustained efforts in mathematical abstraction and design, algorithms design,
application program structuring and flexibility, and ultimately good
object-oriented software engineering.  The FY2007 ASC Level-2 Algorithms
Vertical Integration Milestone has addressed many of these challenges by
demonstrating the vertical integration of many different types of numerical
algorithms in Trilinos {}\cite{ref:trilinos} and assimilating these algorithms with the
application code Charon {}\cite{ref:charon} in a way that can serve as a model for other
algorithm-application collaborations.

On the numerical algorithms side, it is non-trivial to develop and vertically
integrate state-of-the-art massively parallel numerical algorithms ranging all
the way from basic linear algebra data-structures through linear and nonlinear
solvers up to transient solvers and optimization.  Each of these different
numerical algorithm components is developed by a different team of experts to
achieve highest level of quality in the implemented algorithms in a way that a
single team of non-expert developers can not match.  This effort is further
complicated by the stringent parallel scalability requirements that are part
of capability computing {}\cite{book:SC}.

To address the vertical integration problem, a major thrust of this milestone
was to further develop and demonstrate the Thyra interface layer in Trilinos
as a way to seamlessly integrate and plug-and-play different implementations of
various numerical solver components, each developed by different teams of
expert algorithm developers.  In short, the goal of Thyra within Trilinos is
to cleanly support nearly any vertical integration of numerical solvers that
makes sense mathematically in a scalable and maintainable way.

To demonstrate vertical interoperability and integration, we focused primarily on
the Charon {}\cite{ref:charon} application code with an emphasis on semiconductor problems
related to the QASPR {}\cite{ref:QASPR} program.  In particular, we targeted sensitivity
analysis and parameter estimation optimization problems.  As an indication of
the power and generality of these algorithms, we also demonstrated some of the
developed capabilities on reacting flow problems in Charon and on coupled
thermal/electrical/structural problem in Aria/SIERRA.

%  [ToDo: rjhokes: Plese add another sentance or two about about QASPR/Charon above this!]

The bridge between numerical algorithms and application codes is software.
Numerical algorithms must be implemented in software and great effort and care
is required to achieve maximum robustness, speed, and scalability.
Integrating numerical software into application codes is often difficult and
tedious work and keeping the numerical solver software and the application
software up to date with each other is critical to allow for the flow of ideas and
capabilities back and forth between algorithm developers and application
developers.  Good software engineering practices are needed to keep the
software ``bridge'' between algorithms and applications alive and productive
for all involved.

During the course of this milestone work, we have shown how to scalably manage
the vertical integration of advanced numerical algorithms from basic linear
algebra, linear solvers, nonlinear solvers, stability and bifurcation methods,
automatic differentiation, transient solvers, and simulation-constrained
optimization.  We have demonstrated various instances of vertically integrated
solvers with several different problems modeled in production applications.
We have also developed a software integration process and infrastructure
between Charon and Trilinos through which algorithm developers and application
developers can more closely work together and yield faster, more robust, and
better tailored numerical algorithms.  This is done in a way that better meets
the specific needs of important
application customers while at the same time stimulating publishable numerical
algorithm research.

%
\section{Trilinos algorithms and vertical integration with Thyra}
%

A primary goal of this work was to drive the development and vertical
integration of the algorithms in the packages Belos (block linear solvers),
Anasazi (block eigensolvers), Rythmos (time integrators), and MOOCHO
(optimization) in order to implement advanced solver/analysis/optimization
capabilities.  In addition, we incorporated several other Trilinos packages
including Epetra (linear algebra data structure packages), Ifpack (incomplete
factorization preconditioners), ML (multi-level algebraic preconditioners),
Amesos (direct sparse solvers), NOX (nonlinear equation solvers), LOCA
(stability and bifurcation methods), Sacado (automatic differentiation) and
more.

{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[scale=0.87]{VerticalPackageIntegration}
%}
\end{center}
\caption[Eight different levels of vertical integration in modular
transient sensitivity solver and optimizer] {
\label{fig:VerticalPackageIntegration}
Example of eight different levels of vertical integration that exist in a
transient ODE/DAE sensitivity solver in Rythmos with MOOCHO optimization.}
\end{figure}
\esinglespace}

Vertical integration of numerical algorithms refers to the nesting of
numerical solvers within each other to enable the construction of
sophisticated multi-component solver capabilities.  For example, a modularized
ODE/DAE transient sensitivity solver such as is implemented in Rythmos defining
a transient optimization problem to be solved by MOOCHO, shown in
Figure~\ref{fig:VerticalPackageIntegration}, demonstrates at least eight
different levels of vertical algorithm integration.  It is critically
important that these types of modular solvers be constructed in a way that
allows for almost any individual algorithm/solver component to be swapped out
for a version better suited to a given problem.  For example, while an
implicit backward Euler time stepper may be appropriate for one particular
class of problems, a higher-order implicit time stepper, such as a
variable-order variable step size BDF method, may be superior for another
important class of problems.  The same need for flexibility and modularity is
required for the selection of preconditioners, linear solvers, and other
numerical algorithm components.  Without this type of flexibility, application
developers may be justified in writing their own, often suboptimal, algorithms due to
an inability to change an inappropriate component of a more general solver
(there are many examples of this in production codes).  For example, there was
a production circuit simulation application code that was not able to reuse an
existing well known time integration solver due to the inability to redefine
the nonlinear solver used for the time step equation.  

% SSC:  I like this statement, but you should be able to cite particular 
% examples (without mentioning names).

% rabartl: Todd, can you provide some concrete exmaples where you want
% one particular type of integration method in one case, but not another?

Integrating independently developed numerical algorithms and software in an
efficient and manageable way requires the development of standard
object-oriented interfaces.  Typical approaches for combining $N$ different
numerical solver algorithms together may require up to $N^2$ different 1-to-1
specific connections in the worst case.  Standard interfaces break the
non-scalable $N$-to-$N$ dependencies between different numerical software
components into separate scalable 1-to-$N$ dependencies.

% SSC:  you need to define N and M in this context to make this more clear.
% Ross, don't you have a reference (paper or SAND report) that discusses this.  
% If so, you should cite that the include that as part of the milestone evidence.
% even if it was not published this year (we have known to been working on this
% milestone for more than 1 year :)

% rabart:  I don't have a handly written reference to describe this problem,
% only presentations up to this point.

Standard interfaces for these types of numerical algorithms have been developed
and refined in the Trilinos package {}\textit{Thyra}\footnote{The word
{}\textit{Thyra} means ``interface'', or ``grand entrance'' in Greek.}.  Thyra
is comprised of a layered set of abstract C++ interfaces to linear operators
and vectors, preconditioners and linear solvers, an interface to nonlinear
models called the ModelEvaluator, and a nonlinear equation solver interface.
Layered on top of the Thyra interfaces are Rythmos interfaces defining a
number of higher-level abstractions for time stepping and time integration
algorithms.  All of these interfaces are built on the concept of Abstract
Numerical Algorithms (ANA) where only the essential mathematical properties of
the objects are considered without any implementation specific details
{}\cite{ref:rtop_toms}.  This
high-level ANA approach allows a for a level of generality, reuse, and
efficiency that is not possible with other types of approaches.

% SSC:  this is begging for a citation here...

% rabartl: I am not sure what reference I would give here ...


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.85
]{ModelEvaluator}
%}
\end{center}
\caption[Thyra ModelEvaluator and linear solver interfaces]{
\label{fig:ModelEvaluator}
Shows how the Thyra ModelEvaluator and Stratimikos linear solver interfaces
relate to nonlinear abstract numerical algorithms (ANAs) and nonlinear
applications (APPs).  This demonstrates the decoupling and scalability of the
Thyra standard interface approach. }
\end{figure}
\esinglespace}

Of particular significance to this milestone is the use of the Thyra nonlinear
ModelEvaluator interface and supporting software.  Through a single interface,
a variety of nonlinear problems are presented to NOX, LOCA, Rythmos and MOOCHO
using both Charon and Aria/SIERRA as shown in Figure~\ref{fig:ModelEvaluator}.
The {}\textit{Stratimikos} component shown in Figure~\ref{fig:ModelEvaluator}
is a Trilinos package built on top of the Thyra preconditioner and linear solver
interfaces that provides unified parameter-driven access to a great number of
preconditioner and linear solver capabilities in Trilinos.  Let $N$ and $M$ be
the number of nonlinear algorithms and applications, respectively, that one wishes
to use with each other.  Without a standard interface like the Thyra ModelEvaluator,
it would take $N {}\times M$ different 1-to-1 interfaces to link all $M$ applications
and $N$ nonlinear algorithms.  The ModelEvaluator
and Stratimikos approach is a clear demonstration of breaking up these $N$-to-$M$
dependencies which results in scalable 1-to-$N$ and 1-to-$M$ dependencies.  Adding
a new nonlinear ANA solver only requires a single set of Thyra interfaces and
then this solver can be used by the entire set of application codes that
support the needed functionality.  Likewise, an application just needs to
implement the single ModelEvaluator interface, and then it can access all of
the various supported nonlinear solvers.  Finally, a new preconditioner or
linear solver can be wrapped under Stratimikos and then be available to all
applications and nonlinear ANAs that support the ModelEvaluator interface.
This type of reuse and interoperability for massively parallel nonlinear
applications and algorithms to this degree has perhaps never before been achieved and
this type of reuse and interoperability will only increase in the future.

This milestone work clearly highlights the effectiveness of the Thyra
interface layer and ANA approach as demonstrated by the variety of the
different types of vertically integrated solver configurations that were
achieved and the types of numerical problems that were solved.  Specific
examples of different vertical solver integrations and problems solved are
given in Section {}\ref{sec:demonstration}.


%
\section{Charon/QASPR}
%

The Qualification Alternatives to the Sandia Pulsed Reactor (QASPR) program is
focused on future qualification of electrical weapons systems in short pulse
neutron environments (SPNE).  With the shutdown of the SPR III reactor in
2006, full system failure tests in SPNE are no longer possible.  Replacement
of this qualification testing is critical to the future of nuclear weapons
certification.  The QASPR program is targeting this gap with a combination of
testing at alternative test facilities, such as the Annular Core Research
Reactor (ACRR) and the Ion Beam Laboratory (IBL), with high fidelity
predictive computational modeling.  As well as supporting qualification, these
tools will increase the designer's capability to develop robust systems during
the early stages of systems development.

The ASC Charon semiconductor device simulator is a finite element tool capable
of simulating high fidelity models of stockpile devices using large scale ASC
platforms for unprecedented scales and fidelities of transient displacement
damage, due to neutrons, in stockpile devices such as power bipolar junction
transistors.  This capability was developed using predictive fundamental
physics models developed at SNL through experimental and atomistic modeling
(Density Functional Theory and Molecular Dynamics) and massively parallel
algorithmic technology in the ASC Trilinos solver libraries and the ASC Nevada
finite element framework.

A critical aspect of the QASPR problems of interest is the refinement of
physics models for un-irradiated and irradiated devices in comparison to
experimental data.  Two key examples in the current QASPR process include: 1)
calibration of the device doping profiles based on secondary ion mass
spectrometry, which has a substantial absolute error for density
(approximately a factor of two), and electrical characterization of the device;
2) calibration of displacement defect physics parameters, which have an order
of magnitude uncertainty, against transient pulse electrical characterization
experiments.  Currently, these ``calibrations'' are accomplished with
substantial manual effort and resources involving hundreds to thousands of
calculations.  The new algorithmic technologies integrated in Charon show
great promise in their ability to efficiently and robustly solve these
problems with dramatically less manpower and computational resources.

%
\section{Application and Trilinos development nightly integration}
%

Through the course of the milestone work, we found that in order to keep
moving forward and avoid backslides in capability (which happened early on),
we implemented nightly building and testing of the development
versions of Charon and Trilinos.  Every night, we take what is in the Charon
and Trilinos development repositories and build the combined Charon \&
Trilinos application and run a large set of regression tests.  In the time
since we started nightly building and testing, the number of tests in the
Charon test suite has gone up from under 50 to over 100, and {\em 30 of the
new tests are directly related to this milestone work.}

In the execution of this nightly building and testing process, we have learned
many things about how to do continuous integration {}\cite{continuous-integration}
of application and
algorithms (Trilinos) software and we have realized many important unplanned
benefits.  This will allow us to reap many more benefits in the future if this
process is maintained
and extended.  There are both production-related benefits and research-related
benefits that help both the application developers and the algorithm
developers to achieve their goals.  On the research side, this significantly
reduces the overhead required for algorithm developers to try their algorithms
out on production quality problems.  Developing a numerical solver with a
production problem exposes the algorithm developer to a whole host of issues
(e.g.\ poor scaling, ill-conditioning, difficult convergence, etc.) that are
hard to replicate in model problems.  On the production side, constant
integration insures that the application and Trilinos are always up to date
and satisfying the application's requirements.  Therefore, when it is time for
a release, only a final set of acceptance tests are required and then the
codes can be branched and released shortly after.  This helps to reduce a
whole host of risks such as slipped schedules and broken
features\footnote{Also known as regressions}.

% SSC:  this prior paragraph may benefit from a few more concrete examples
% to help bolster the claims.

% rabartl: Okay, here are a few examples ...

We have seen several different scenarios over the years where this nightly
building and testing infrastructure would have facilitated collaboration
between application and algorithm developers for the advantage of both.

For example, suppose an application developer is running a new problem and
discovers some strange behavior from a numerical solver.  The algorithm
developer may look at the results and speculate what the cause of the behavior
might be or if a different variation of the algorithm might help.
However, if the algorithm developer is stuck having to use a released version
of Trilinos, it will be more difficult to make any major changes in order to
investigate the behavior.  Also, there may already be improvements made to the
algorithm in the development branch of Trilinos that may be able to address
the problem.  Without the infrastructure of nightly building and testing, it
may not be cost effective or practical to bring the development versions of
the application and Trilinos up to date in order to try the updated algorithm.
The algorithm and application developers may have to wait until the next major
release of Trilinos before the new algorithms can be tried.  This time delay
works to no one's advantage and can kill the collaboration.  With nightly
building and testing in place, an easy path for collaboration is maintained
where the Trilinos algorithm developer can try their latest and greatest
algorithms on these types of challenging production problems and the
information learned from trying to solve these production problems can feed
back into algorithm development.  To some extent, this back and forth already
happens but without a foundational process in place to streamline it, this
bidirectional flow is greatly restricted.

Another example where nightly building and testing of the development versions
of the application and Trilinos would ease the path for collaboration is when
an application developers wants to try a new capability in Trilinos without a
lot of work\footnote{This example really happened and it was the inability to
readily access the development version of Trilinos within the application
that killed the collaboration}.  When the up-to-date development version of
Trilinos is available from within an application, a new algorithm or
capability from Trilinos can be accessed much more easily.  Typically, even a
small increase in the overhead needed to try out a new Trilinos capability in
an application can be enough to kill a potentially fruitful collaboration
between an application and algorithm developer.  Nightly building and testing
of the development versions of the application and Trilinos removes a
unexciting (and therefore demoralizing) but critical obsticle to collaboration
and impact.

Nightly building and testing of an application code and Trilinos
brings algorithm developers and application developers closer together --
exchanging ideas and concerns -- and refocuses Trilinos developers on customer 
efforts while still helping drive publishable numerical algorithm solver
research and reduces barriers for new algorithms to have impact through
production application codes.

% SSC:  I think that this is very important and should be touted as a major 
% accomplishment of ths milestone!


%
\section{Demonstration solver vertical integrations and calculations}
\label{sec:demonstration}
%

While many different numerical solver configurations were used to solve a
variety of different numerical problems in Charon and Aria during the
milestone work, some of the more noteworthy examples are given below.  For each
example, the list of vertically integrated algorithm packages that were
linked together to solve the problem are given.  Note that the Thyra package
was used in all cases as the standard interface to pull these algorithm
packages together.

%
\subsection{Steady-state semiconductor current-matching parameter
estimation problems}
%

{}\noindent\textit{Vertically integrated packages:} MOOCHO, Stratimikos,
Belos, Ifpack, Thyra, and Epetra

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.80,width=0.50\linewidth
]{multiPointFit}
%}
\end{center}
\caption[Multipoint current-matching parameter estimation solution against experimental data]{
\label{fig:multiPointFit}
This figure illustrates how multi-point optimization can be used to optimize
system parameters so that a {\em curve} of responses can best be matched. In
this case, $12$ steady-state current predictions, running in parallel, were
fit to the experimental data.}
\end{figure}
\esinglespace}

We solved both single-point and multi-point inverse optimization problems for
the QASPR semiconductor model 5614.  Here, we used MOOCHO to solve a
simulation-constrained least-squares optimization problem to minimize the
deviation between the simulated current through the device and the target
current by manipulating the poorly known defect reaction parameters.  We showed
significant improvement in accuracy and speedup over non-invasive block-box
methods.

%[ToDo: rabartl: We have not really compared to the non-invasive
%block-box methods but we could if we wanted too ... Russell may be able to do
%such a comparison for the MOOCHO/Aria problem].

% 2007/08/22: rabartl: Right now, we can't really claim any speedup using
% Belos.  This may be fixed in time for the milestone completion, but for now
% I will ommit this.

%In addition, the forward sensitivity
%method using pseudo-block GMRES in Belos showed superior performance to
%AztecOO (the current production iterative linear solver in Trilinos) [ToDo:
%rabartl: We need to modify the setup of this model and fix some problems in Belos
%to really show this].

% SSC:  you need to justify the assertion that you achieved significant improvements
% rabartl:  I commented this out above.

The multi-point algorithm allows parameters to be matched over the whole
current-voltage curve simultaneously with excellent scalability by using
another dimension of parallelism over the multiple data points.  This required
development in EpetraExt and modifications to the Nevada/Charon code where
multiple instances of the code run simultaneously with partitioned MPI
Communicators, while the linear algebra and optimization algorithms operate on
a global MPI communicator.

%[ToDo: rabartl: give the form of the optimization problem and give the initial
%and final objective function values]

% SSC:  in the description below, more is required regarding not being able to 
% solve this problem for the ``physically'' relevant parameters.  In particular,
% these results may suggest that what s thought to be the relevant parameters 
% are infact not.  Likewise, there could be a bias in the experiemental results
% that is not accounted for.  The main point is that the milestone provides the
% tooles and capabilties to now explore these questions which could not be 
% readily done before.

% rabartl: I agree, and I have added text to make these points more clear ...

As seen in Figure {}\ref{fig:multiPointFit}, we were successful in having the
multi-point algorithm find the optimal parameter value so that a curve of 12
points would best match the experimental data. Since the application for this
problem specification runs well in serial, this was run on 12 processors of
Thunderbrid for near-optimal scalability.  The results shown were computed by
altering the total amount of radiation damage, and then optimally fit using
the voltage at the second contact as the optimization parameter.

Unfortunately, we were not able to match all experimental data to high
precision by just using the most physically relevant parameters that govern
the defect physics as identified by the QASPR modelers.  While we were not
able to provide a definitive proof of the cause, single-point current-matching
numerical experiments suggest that many of these experimental states are
simply not reachable given the other model operating parameters which are
supposed to be known to high precision.  This suggests that either there was
experimental error, or the other operating parameters did not really match the
physical system, or the model was incomplete in some way.  The main point is
that while we were not able to diagnose the cause of the problem, the
milestone has developed some of the tools needed to help answer these
questions.

% 2007/08/23: rabartl: Below, I think that I am making a good point but I am
% not sure that it belongs in the ``demonstation'' section.

One interesting output of this work was the behavior of the optimization
algorithms in MOOCHO and the basic forward Newton solver algorithms.  It turned out
that the radiation defect physics steady-state semiconductor model caused many
convergence challenges for the algorithms.  In some cases, even small
perturbations in the defect reaction parameters would cause the forward
Newton's method to fail to re-converge the state equations and the
optimization algorithms in MOOCHO suffered similar convergence difficulties.
A problem of this type provides an exciting opportunity for further
research into globalization methods for simulation-constrained optimization.
Typically, numerical algorithm researches are resigned to develop their
algorithms on ``model'' problems that they try to make difficult but it is
hard to reproduce the kinds of unexpected challenges that are manifested in
real production-quality applications.  Now that these test
problems are part of the Charon test suite, they can be preserved and will
provide easy access for further algorithm research.  Without nightly testing,
it is our past experience that these types of interesting test problems always
fall away due to code and other changes that break the connection between the
production application and the numerical algorithm software.

% SSC:  This transient forward run is critical to the milestone

%
\subsection{Transient QASPR semiconductor forward simulation}
%

{}\noindent\textit{Vertically integrated packages:} Rythmos, NOX, Stratimikos,
Belos, Ifpack, Thyra, and Epetra

We used a high-order accuracy-controlling implicit BDF integrator algorithm in
Rythmos (along with other mentioned vertically integrated packages) to solve
forward simulation problems for the 2-dimensional prompt neutron physics
QASPR 2n2222 semiconductor model.
%on 1024 nodes of Thunderbird.  
This capability
demonstrates the high accuracy time integration capability for a critical
QASPR problem.  Robust and efficient solution of this transient simulation
allows us to quantify the effects of prompt neutron irradiation for a key
stockpile device in direct support of the QASPR mission.  
%A 1.3 million element
%mesh is used with a total of approximately 60 million unknowns leading to
%the need for massively parallel scalability for all algorithmic capabilities
%being used from Trilinos and the vertical integration effort. 

%[ToDo: tscoffe or etphipps or rjhoeks: a) Expand the description of this
%problem, b) create some placeholder for results in lue of results, c) Actually
%get the results and fill in what this demonstrates!].

% RJH:  these calculations will probably be run by 9/10

% SSC:  this is very important too...

%
\subsection{Transient QASPR semiconductor sensitivities}
%

{}\noindent\textit{Vertically integrated packages:} Rythmos, NOX, Stratimikos,
Belos, Ifpack, Thyra, and Epetra

We used the new forward sensitivity solver in Rythmos to demonstrate the
calculation of transient sensitivities of the electric current in a Charon
simulation of the bipolar junction transistor subject to radiation damage
with respect to 40 model parameters.  The parameters of interest in this 
calculation are physics parameters associated
with damage mechanisms in the device which dramatically impact the transient
electrical performance of the bipolar junction transistor.  As one of the 
devices used in the stockpile, it is critical to characterize its performance.
Without underground testing and now the decommissioning of fast pulse
neutron facilities such as the Sandia Pulsed Reactor (SPR), a combination of
alternate experimental data such as ion beam data and predictive modeling
is critical to the future of weapons systems qualification.  The nominal values
of these parameters have an order of magnitude uncertainty making best fit
plus uncertainty untenable for the customer.  Through optimization and calibration
of the Charon model to experimental data, the uncertainty in these parameters
can be substantially reduced.  This transient sensitivity analysis not only
facilitates gradient based optimization technology but also allows detailed
analysis of the mechanisms and their importance in relation to the critical
device performance metrics guiding future improvements to the model.

{\bsinglespace
\begin{table}
\caption[Defect reaction parameters for transient current sensitivity
analysis]{\label{table:ParameterKey}
Defect reaction parameters for transient current sensitivity analysis of the
2n2222 bipolar junction transistor problem}
\begin{center}
\begin{tabular}{|r|l|c|r|l|c|}
\hline 
\multicolumn{6}{|c|}{Reaction Cross-Section Parameters} \\
\hline
\multicolumn{1}{|c|}{Index} & 
\multicolumn{1}{c|}{Value} & 
\multicolumn{1}{c|}{Reaction} & 
\multicolumn{1}{c|}{Index} & 
\multicolumn{1}{c|}{Value} & 
\multicolumn{1}{c|}{Reaction} \\ 
\hline\hline
1  & 3.0e-16 & $e^- + V^-\rightarrow V^{--}$  & 15 & 1.8e-13 & $h^+ + V^- \rightarrow V^0$     \\
2  & 3.0e-16 & $V^{--} \rightarrow e^- + V^-$ & 16 & 1.8e-13 & $V^0 \rightarrow h^+ + V^-$     \\
3  & 1.8e-14 & $e^- + V^0 \rightarrow V^-$    & 17 & 3.0e-15 & $h^+ + V^0 \rightarrow V^+$     \\
4  & 1.8e-14 & $V^- \rightarrow e^- + V^0$    & 18 & 3.0e-15 & $V^+ \rightarrow h^+ + V^0$     \\ 
5  & 3.0e-14 & $e^- + V^+ \rightarrow V^0$    & 19 & 3.0e-16 & $h^+ + V^+ \rightarrow V^{++}$  \\
6  & 3.0e-14 & $V^0 \rightarrow e^- + V^+$    & 20 & 3.0e-16 & $V^{++} \rightarrow h^+ + V^+$  \\
7  & 3.0e-14 & $e^- + V^{++} \rightarrow V^+$ & 21 & 3.0e-16 & $h^+ + B^- \rightarrow B^0$     \\
8  & 3.0e-14 & $V^+ \rightarrow e^- + V^{++}$ & 22 & 7.5e-14 & $B^0 \rightarrow h^+ + B^-$     \\
9  & 3.0e-16 & $e^- + P^+ \rightarrow P^0$    & 23 & 3.0e-14& $h^+ + PV^- \rightarrow PV^0$   \\
10 & 1.5e-13 & $P^0 \rightarrow e^- + P^+$    & 24 & 3.0e-14 & $PV^0 \rightarrow h^+ + PV^-$   \\
11 & 3.0e-15 & $e^- + PV^0 \rightarrow PV^-$  & 25 & 1.0 & $V^{--} + P^+ \rightarrow PV^-$ \\
12 & 3.0e-15 & $PV^- \rightarrow e^- + PV^0$  & 26 & 1.0 & $V^- + P^0 \rightarrow PV^-$    \\
13 & 3.0e-14 & $h^+ + V^{--} \rightarrow V^-$ & 27 & 1.0 & $V^- + P^+ \rightarrow PV^0$    \\
14 & 3.0e-14 & $V^- \rightarrow h^+ + V^{--}$ & 28 & 1.0 & $V^0 + P^0 \rightarrow PV^0$    \\
\hline
\end{tabular} \\[3ex]
\begin{tabular}{|r|l|c|r|l|c|}
\hline 
\multicolumn{6}{|c|}{Reaction Activation Energy Parameters} \\
\hline
\multicolumn{1}{|c|}{Index} & 
\multicolumn{1}{c|}{Value} & 
\multicolumn{1}{c|}{Reaction} & 
\multicolumn{1}{c|}{Index} & 
\multicolumn{1}{c|}{Value} & 
\multicolumn{1}{c|}{Reaction} \\ 
\hline\hline
29 & 0.09 & $V^{--} \rightarrow e^- + V^-$ & 35 & 1.03 & $V^- \rightarrow h^+ + V^{--}$ \\
30 & 0.40 & $V^- \rightarrow e^- + V^0$    & 36 & 0.72 & $V^0 \rightarrow h^+ + V^-$    \\
31 & 1.07 & $V^0 \rightarrow e^- + V^+$    & 37 & 0.05 & $V^+ \rightarrow h^+ + V^0$    \\
32 & 0.99 & $V^+ \rightarrow e^- + V^{++}$ & 38 & 0.13 & $V^{++} \rightarrow h^+ + V^+$ \\ 
33 & 0.045 & $P^0 \rightarrow e^- + P^+$    & 39 & 0.045 & $B^0 \rightarrow h^+ + B^-$    \\
34 & 0.44 & $PV^- \rightarrow e^- + PV^0$  & 40 & 0.68 & $PV^0 \rightarrow h^+ + PV^-$  \\
\hline
\end{tabular}
\end{center}
\end{table}
\esinglespace}

{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[width=5in]{sensitivities_hist_report}
%}
\end{center}
\caption[Scaled transient current sensitivities at selected times]{
\label{fig:SensitivitesHist}
Scaled transient base current sensitivities at selected times of the 
2n2222 device.
The parameters corresponding to each number are displayed in 
Table~\ref{table:ParameterKey}.  Sensitivities are scaled to $(p/I)(dI/dp)$ where
$p$ is the parameter value, $I$ is the current, and $dI/dp$ is the unscaled
sensitivity.}
\end{figure}
\esinglespace}

{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[width=5in]{sensitivities_full_report_1}
%}
\end{center}
\caption[Transient history of two scaled sensitivities]{
\label{fig:SensitivitesFull}
Transient history of sensitivities 3 and 23 from 
Figure~\ref{fig:SensitivitesHist} (blue curves) and base current (green curves).}

\end{figure}
\esinglespace}

{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[width=5in]{sensitivity_conv}
%}
\end{center}
\caption[Comparison of direct and finite-difference sensitivities]{
\label{fig:SensitivitesFD}
Comparison of direct Rythmos sensitivities (blue curves) with first-order
finite-differences (red stars) for parameter 3 with two time integration error
tolerances, 1e-3 and 1e-5.  Tighter time integration tolerances are required
to get even order-of-magnitude correctness out of finite-difference
approaches.}
\end{figure}
\esinglespace}

The 40 parameters used in the sensitivity analysis are the reaction 
cross-sections and activation energies of the radiation defect reactions
shown in Table~\ref{table:ParameterKey}.  Sensitivities of the base current
at several times after the radiation pulse are shown in 
Figure~\ref{fig:SensitivitesHist}, clearly demonstrating which physics the
current is most sensitive to.  Transients plots of the base current
sensitivity with respect to two of these important parameters are shown in
Figure~\ref{fig:SensitivitesFull}.

The typical approach for obtaining these sensitivities is through 
non-invasive finite-difference methods.  We compared computing 
sensitivities using first-order finite-differencing to the direct method
in Rythmos and found  several dramatic advantages of the Rythmos approach.
First, because perturbing parameters ultimately will cause different time
steps to be taken, it is only possible to compute finite-difference 
sensitivities at selected times by setting breakpoints in the time integrator.
However the Rythmos approach provides full sensitivity values at all time
steps as shown in Figure~\ref{fig:SensitivitesFull}.  Moreover the variation
in step size with respect to parameter perturbation adds significant noise
to the sensitivities computed by finite-differencing, making them quite 
inaccurate and not suitable for gradient-based optimization.  
Figure~\ref{fig:SensitivitesFD} displays a comparison of the direct 
sensitivities to first-order finite-differences and shows that tighter 
time integration tolerances are required to reduce this noise to get even 
order-of-magnitude accuracy from the finite-difference calculation.  
{\bf Finally the
transient sensitivities for all 40 parameters using Rythmos were obtained in 
significantly less computing time, less than 1/5th of the time required by
first-order finite-differencing}.

% [ToDo: rjhoeks: Please add some detail about the nature of these parameters]

% [ToDo: rabartl: We don't have these results yet but this is my number one
% technical goal leading up to the end of the milestone].

% SSC:  this should be dropped now

% rabartl: I have commented this out

% 2007/08/22: rabartl: I removed this based on Scott's comment
%{}\noindent\textbf{Transient parameter-estimation problem with QASPR
%semiconductor model} [MOOCHO, Rythmos, NOX, Belos, Ifpack,
%Epetra]: We used the new forward sensitivity solver in Rythmos to solve
%transient parameter estimation problems using MOOCHO as the optimization
%algorithm [ToDo: rabartl: There is a small chance that we could have this working
%once we have basic forward sensitivities working].

%
\subsection{Block eigen-solves for reacting flow problem}
%

{}\noindent\textit{Vertically integrated packages:} LOCA, NOX, Anasazi,
Stratimikos, Belos, ML, Ifpack, Amesos, Thyra, and Epetra

We successfully demonstrated large-scale eigenvalue calculations using
block eigensolvers on the hydromagnetic Rayleight-Bernard (HRB)
problem.  The HRB problem is important for verification of
magnetohydrodynamics physics due to the existence of analytic
solutions published by Chandresekhar \cite{book:HRB}.  The problem
consists of a fluid sandwiched between upper and lower walls.  The
lower wall is heated and the upper wall is cooled.  As the temperature
gradient between the walls is increased (an increase in the Rayleigh
number), a buoyancy driven instability occurs that transitions the
fluid from a quiescent (no-flow) state to a recirculating (non-zero
flow) state with repeating cells of rotating fluid.  Figure
\ref{fig:hrbFlow} shows the flow solution for the recirculating state.

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.3]{figures/ms_vx.eps}
\includegraphics*[angle=0,scale=0.3]{figures/ms_vy.eps}
\includegraphics*[angle=0,scale=0.3]{figures/ms_pres.eps}
\includegraphics*[angle=0,scale=0.3]{figures/ms_temp.eps}
\includegraphics*[angle=0,scale=0.3]{figures/ms_vectorpotential.eps}
\includegraphics*[angle=0,scale=0.3]{figures/ms_current.eps}
%}
\caption[Solution of the hydromagnetic Rayleigh-Bernard problem]{
\label{fig:hrbFlow}
Plot of the solution for a Rayleigh number of 2100 and magnetic field strength
of 16 on the non-zero flow branch of the pitchfork bifurcation.}
\end{center}
\end{figure}
\esinglespace}
 
The onset of this instability (a pitchfork bifurcation point) can be
located by monitoring the leading eigenvalues during a parameter
continuation.  The instability occurs when the real part of the
leading eigenvalue crosses the imaginary axis (e.g. becomes zero).
Therfore to locate an exchange of stability, we watch for the leading
eigenvalue to switch from a negative value to a positive value as the
parameter continuation is performed. The Rayleigh number (Ra) is the
chosen continuation parameter and the magnetic field strength is fixed
to a constant value.  After the bifurcation, the no-flow solution
becomes unstable. Table \ref{table:hrbEigenvalues} show the leading
two eigenvalues as a function of the Reyleigh number.  
{\bsinglespace
\begin{table}
\caption[Leading eigenvalues as a function of Rayleigh number]{\label{table:hrbEigenvalues}
Leading eigenvalues as a function of Rayleigh number for Hydromagnetic Rayleigh-Bernard problem.}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline 
\multicolumn{1}{|c|}{ } & 
\multicolumn{4}{|c|}{Rayleigh Number} \\
\hline
\multicolumn{1}{|c|}{Index} & 
\multicolumn{1}{c|}{2020} & 
\multicolumn{1}{c|}{2030} & 
\multicolumn{1}{c|}{2040} & 
\multicolumn{1}{c|}{2050} \\ 
\hline\hline
1 & -0.13413 & -0.062685 & 0.0086453 & 0.079866  \\
2 & -0.15978 & -0.086379 & -0.013056 & 0.060184  \\
\hline
\end{tabular}
\end{center}
\end{table}
We observe that the eigenvalues flip sign between 2030 and 2040.
Figure \ref{fig:hrbEigenvalues} shows the computed eigenvectors for
the velocity at a Rayleigh number of 2040, just past the bifurcation
point at 2039.  This figure depicts the perturbation to the base
no-flow solution that forces the transition to the recirculating
state.

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.30]{figures/ms_eigenvalue_vx.eps}
\includegraphics*[angle=0,scale=0.30]{figures/ms_eigenvalue_vy.eps}
%}
\end{center}
\caption[Eigenvalues for the hydromagnetic Rayleigh-Bernard problem]{
\label{fig:hrbEigenvalues}
Plot of the eigenvectors for the x and y velocities.  This perturbation
corresponds exactly to the flow solution above.}
\end{figure}
\esinglespace}

The problem was discretized into 5 million elements leading to a
linear system with 5 million unknowns that was solved using 256
processors on Thunderbird.  We used LOCA/NOX to solve the system of
fully coupled nonlinear equations for a variety of Rayleigh numbers
using arc-length continuation.  At the end of each continuation step,
LOCA calls Anasazi to compute the eigenvalues and eigenvectors.  The
eigenvalue computation used Belos to perform Block and Pseudo-Block
GMRES on the linear systems.  ML supplied the preconditioning for the
linear solves.  ML internally used a 3 level V-cycle, calling IFPACK
with ILU for the smoothers and Amesos (KLU) for the direct solve on
the coarse grid.

The eigenvalue calculation demonstrates a general capability through coupled
Trilinos packages to perform large-scale block eigenvalue calculations.  This
will be a critical ASC capability for performing stability and bifurcation
analysis.

%
\subsection{Design optimization problem with Aria/SIERRA}
%

{}\noindent\textit{Vertically integrated packages:} MOOCHO, Stratimikos,
Belos, Ifpack, Thyra, and Epetra

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.40
]{SiC_dY0.1.eps}
%}
\end{center}
\caption[Final optimization solution for Aria MEMS actuator design problem]{
\label{fig:ariaFinal}
Plot of the final Aria solution showing the deformed beam and Temperature
contours. The optimization algorithm found that an applied voltage of $1.934$
would cause the beam to exactly match the design criterion of having the top
corner of the beam deflect a distance of $0.05$ at steady-state.  }
\end{figure}
\esinglespace}

We have demonstrated the minimally invasive optimization algorithm in MOOCHO
on a MEMS actuator problem in Aria/SIERRA.  In this problem, an applied
voltage across the Silicon Carbide beam causes resistive heating, which in
turn causes thermal expansion, which in turn causes the beam to deflect
upwards. The optimization problem was formulated as follows: find the value of
the applied voltage parameter so that the beam deflection most closely matches
a given design value (e.g. a deflection distance of $0.05$). The proof-of-concept was successful, with the
optimization problem solving to $8$ digits of accuracy (Figure
{}\ref{fig:ariaFinal}). This demonstration also highlights the speed of the
invasive algorithms, as it solved the optimization problem in only twice the
time of solving a single steady-state calculation.  We experimented briefly
with black-box finite-difference optimization methods which are commonly
used to solve simulation-constrained optimization problems.  These methods
are known to be very sensitive to step perturbation sizes and numerical
parameters and we were not able to make any progress in the solution
to even compare performance of these different optimization approaches.

This Aria application demonstrates that the algorithms and software are
general and immediately applicable to ASC applications other than Charon. The
development of the ModelEvaluator interface will pave the way for more
Trilinos capabilities, such as Rythmos, to be assimilated into Aria. Since the
model evaluator was implemented at the Sierra Solution Control level, there is
a now a direct path for all Sierra applications (particularly implicit codes
such as Adagio) access to all Trilinos analysis algorithms.


%
\section{Numerical Issues}
%

In order to be able to solve several of the demonstration calculations
(especially the optimization problems), we had to address various numerical
issues including matrix singularities and scaling.  Without addressing all of
these issues, many of the demonstration problems were essentially unsolvable
with 64 bit floating point numbers.

The first issue that needed to be addressed was that the semiconductor
reaction defect physics model gave a nearly structurally singular Jacobian for
the steady-state model.  A singular Jacobian makes the optimization problems
unsolvable.  In order to address the singularity problem, an automated way of
reformulating the equations involving immobile species was devised.  To
identify the redundant equations, an SVD is performed on the reaction mechanism
incidence matrix.  From this SVD, a new reduced reaction mechanism is produced
which is used to build the Charon input file. 
%[ToDo: rjhoeks or someone else, please make sure that this statement above is accurate].

The other major numerical issue that had to be addressed was the scaling of
all of the quantities.  The typical magnitudes of various quantities seen in
the steady-state single-point current-matching optimization problem are shown
in Table {}\ref{table:SemiconductorMagnitudes}.
%
{\bsinglespace
\begin{table}
\caption[Typical magnitudes of quantities in
semiconductor optimization problem]{
\label{table:SemiconductorMagnitudes}
Typical magnitudes of variables and functions in the semiconductor
optimization problem which span a range of $10^{25}$!}
\begin{center}
\begin{tabular}{|l|c|}
\hline
State Variables &  $10^{0}$ to $10^{8}$ \\
State Constraints & $10^{-4}$ to $10^{10}$ \\
Parameters & $10^{-15}$ to $10^{0}$ \\
Currents & $10^{-8}$ \\
\hline
\end{tabular}
\end{center}
\end{table}
\esinglespace}
%
% rabartl: Note, I got the scaling for the State constraints from
% the row-sum scaling for the 5614-inv problem that I ran in:
%
%   ~/tests/Charon/20070906/5614-inv/test1/test/MoochoJournal.inv-an.out
%
% on gabriel.sandia.gov.
%
% The row-sum scalings were:
%
%   Computed inverse row sum scaling from W that will be used to scale f(...) and its derivatives:
%    min(invRowSums) = 1.25658e-10
%    max(invRowSums) = 89424.5
%    avg(invRowSums) = 717.853
%
% That means the magnitudes of the constraints were 1e-4 to 1e+10!
%
The magnitudes represented in Table {}\ref{table:SemiconductorMagnitudes} span
a range of $10^{25}$!  This range of scalings will break almost any numerical
method implemented with 64 bit float point numbers.

In order to solve the steady-state current-matching parameter-estimation
optimization problems, we had to scale every quantity including state
variables, state constraints, optimization parameters, and currents.  Various
strategies were used to find reasonable scalings for each of the quantities
and in the end we ended up with all variables and functions scaled to a size
of about 1.0.  Even with these scalings in place, some of the intermediate
derivatives were of size $10^{6}$ and the condition number of the state
Jacobian was $10^{5}$.  With all of these quantities scaled, the optimization
algorithms performed reasonably well and were able to invert for the
parameters to a high precision (8 digits of accuracy in current and parameter
matches in many cases).  If even one of to scalings was removed, the
optimization algorithms failed to find the solutions.

Optimization algorithms, more than any other type of algorithm, are more
sensitive to scaling issues because they must make comparisons of quantities
that are completely unrelated.  All-at-once optimization algorithms must
balance feasibility against optimality and any such comparison is very much
affected by the scaling of the various quantities.  For example, the reduced
gradient norm is compared to the state constraint residual norm in several
different places in the algorithm.  Such a comparison is impossible to make
with quantities left in their original scaling.  Even though they are simpler
algorithms, issues of scaling are also critical in several different types of
algorithms for unconstrained optimization and nonlinear equations.  All of
these problems are magnified in constrained optimization algorithms.  The
theory on scaling and its impact on numerical algorithms is not very solid
(see {}\cite{ref:dennis_schnabel_1996}) and scaling remains a necessary, but
poorly understood, black art in numerical computing.

%[ToDo: tscoffe: Write a paragraph describing scaling issues of the residual of the timestep equations and impact on overall performance]


%
\section{Conclusions}
%

There are a number of conclusions that we have drawn as a result of this
milestone work:

\begin{itemize}

{}\item Predictive simulations capable of answering tomorrows questions
mandates moving beyond the basic forward solve and requires the incorporation
of invasive technologies for sensitivities, optimization, and other advanced
numerical algorithms.

{}\item Solving complex numerical problems (such as transient sensitivities)
to the highest quality with the greatest efficiency requires the vertical
integration of many different types of advanced numerical algorithms that can
be tailored to the specific problem.

{}\item The vertical integration of a large number of advanced numerical
algorithms requires the development and adoption of standard interfaces.

{}\item Thyra standard interfaces for linear operators and vectors,
preconditioners and linear solvers, nonlinear models, and nonlinear solvers
have allowed the vertical integration of a large variety of numerical solvers
and access to a variety of nonlinear applications.

{}\item Application codes must present themselves as a ModelEvaluator and then
hand over nearly complete control to the numerical solver(s) in order to take
full advantage of advanced nonlinear numerical algorithms.  Monolithic forward
time stepping application codes require significant nodification to take advantage of these more
sophisticated solution techniques.

{}\item Nightly building and testing of the development versions of the
application and Trilinos:

  \begin{itemize}

  {}\item results in better production capabilities and better research,

  {}\item brings algorithm developers and application developers closer
  together allowing for a better exchange of ideas and concerns,

  {}\item refocuses Trilinos developers on customer efforts,

  {}\item helps drive research-quality algorithm development, and
        
  {}\item reduces barriers for new algorithms to have impact on production
  applications.

  \end{itemize}

{}\item Other application projects and scientific support software projects
should consider adopting the type of continuous integration that is used with
Charon + Trilinos that was developed as part of this milestone work.

\end{itemize}


% ---------------------------------------------------------------------- %
% References
%

\clearpage
% If hyperref is included, then \phantomsection is already defined.
% If not, we need to define it.
\providecommand*{\phantomsection}{}
\phantomsection
\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}
\bibliography{references}

% ---------------------------------------------------------------------- %
% Appendices should be stand-alone for SAND reports. If there is only
% one appendix, put \setcounter{secnumdepth}{0} after \appendix
%
%\appendix
%\input{???}

\begin{SANDdistribution}[NM]
% \SANDdistCRADA	% If this report is about CRADA work
% \SANDdistPatent	% If this report has a Patent Caution or Patent Interest
% \SANDdistLDRD	% If this report is about LDRD work
% External Address Format: {num copies}{Address}
%\SANDdistExternal{}{}
%\bigskip
%% The following MUST BE between the external and internal distributions!
%\SANDdistClassified % If this report is classified
% Internal Address Format: {num copies}{Mail stop}{Name}{Org}
%\SANDdistInternal{}{}{}{}
% Mail Channel Address Format: {num copies}{Mail Channel}{Name}{Org}
%\SANDdistInternalM{}{}{}{}
%\SANDdistInternal{2}{MS 9018}{Central Technical Files}{8944}
%\SANDdistInternal{2}{MS 0899}{Technical Library}{4536}
\end{SANDdistribution}

\end{document}
